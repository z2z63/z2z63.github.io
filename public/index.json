[{"categories":null,"content":"最近两个月也是基本一直在写C++了，尤其是实习以来，从一个linux的C++开发者切换到windows + visual c++，这其中遇到的问题非常多，也让我不断的思考究竟怎样才是最佳实践。 此外，实习期间摸鱼时，也阅读了不少python源码，为了理解python的内存管理系统，还翻了四五遍glibc的wiki，粗略看了malloc源码，也算是学到了不少知识，为了分享这些知识，我决定先将我从各种项目中学习到的C/C++开发应该了解的知识系统总结一下 ","date":"2024-07-20","objectID":"/posts/week6/:0:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#"},{"categories":null,"content":" 前置概念 C/C++是系统开发语言，绝大部分操作系统的系统调用都是以C/C++的API形式提供的 C++不应该被视为一种语言，而是一个松散的语言联邦。可以认为GNU的C++是gnu-cpp语言，而Microsoft的C++是visual-cpp语言。而这些xxx-cpp语言恰好满足了一个名为C++的语言联邦的约定，于是都称为C++ 接上，以上观点的原因是，不同平台的C++开发区别实在是太大了。Windows的C++开发者和Linux的C++开发者表面上都在开发C++，但是他们的考虑到底层的方式，使用的工具，使用工具的方式都是截然不同的。例如同一个printf，linux的C++开发者会想到文件描述符，会想到tty等等，而Windows的C++开发者会想到Win32 API，会想到回车换行符，会想到控制台主机等等 C++开发者在跨平台时，需要能够跨CPU架构、操作系统、libc++实现、编译器 undefined behavior（UB）,即未定义行为，指C++标准明确规定此行为的结果不确定，UB不是未文档的行为 implementation-defined behavior（IB），即实现定义行为，指C++标准规定此类行为的结果应该由C++实现（通常是编译器vendor）规定 UB，IB的行为往往是根据当前架构，当前实现方式中选取的性能最好的一种行为，即C++跨平台时需要考虑避免UB和IB ","date":"2024-07-20","objectID":"/posts/week6/:1:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#前置概念"},{"categories":null,"content":" 工具链为了将源码转变为最终的二进制，需要编译器、汇编器、链接器、调试器共同工作 此外，往往还需要配套的构建工具例如makefile、cmake等，他们共同组成了C++工具链 工具链往往跟平台有关，linux往往使用GCC工具链中的gcc作为编译器，as作为汇编器，ld作为链接器，gdb作为调试器 此外，一套工具链中的工具是相互协作，共同生成二进制。例如gcc会在编译时，将一些信息嵌入ELF某些段中，指示ld如何工作，因此gcc编译的中间产物不能被其他链接器使用，不同平台的汇编代码也不同，例如GCC的汇编器是GAS(GNU Assember)，其语法与visual c++的汇编器MASM不同。因此，生成二进制产物必须由一套工具链的工具相互协作，不能混用工具链 对于传统开源项目，常常使用GNU的autotools，makeilfe作为构建工具。对于现代C++项目，通常使用CMake作为构建工具，CMake在linux平台往往使用makefile完成最终的构建；而windows可以选择microsoft提供的visual c++工具链，并使用Visual Studio进行开发，Visual Studio往往会调用msbuild或nmake完成构建 ","date":"2024-07-20","objectID":"/posts/week6/:2:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#工具链"},{"categories":null,"content":" 编译参数编译参数即传给编译器的参数。广义的编译参数包括任何字面上传递的参数，狭义的编译参数指一些控制编译器行为的标志，而不包括诸如头文件搜索路径，源文件路径等等 以gcc为例，编译参数一般有一下部分 头文件搜索路径 源文件路径 输出产物路径 优化参数 所谓优化，即将一段代码转为效率更高，但是结果等价的代码 优化参数通常为-f开头，用于控制是否开启某项编译优化手段 此外，还提供了-O0，-O1，-O2，-O3方便使用，会分别批量打开对应的优化开关 -O0表示关闭所有开关，而-O3表示开启所有开关 常使用O2而不使用O3，原因如下 在gcc历史上有段时期O3并不稳定 O3的优化结果的等价性更依赖于无UB，大部分开发者无法避免写出无UB的程序，O3优化容易使得这些程序出现错误 O2已经提供了足够使用的优化 O3优化在进行循环展开时，可能导致循环体超过cache line的大小，反而降低速度 O3优化可能利用当前平台特性，可能导致二进制产物无法在其他平台运行 功能参数 警告参数 通常-W开头，用于单独控制是否对某个行为发出警告 如果抑制警告，通常是-Wno开头 -Wall表示开启所有警告，常用于避免潜在的问题 -Werror表示将警告转为错误，在比较严格的场合下用于强制开发者消除所有警告 语言特定参数 诊断参数 静态分析参数 代码生成参数 用于控制输出的二进制产物，例如-fPIC控制生成地址无关代码，常用于生成共享对象 链接器参数 gcc会在内部调用ld，链接器参数会直接传递给ld 汇编器参数 同理，gcc会在内部调用as，链接器参数会直接传递给as 宏定义参数 部分宏定义需要在编译时传入，以控制程序的行为 ","date":"2024-07-20","objectID":"/posts/week6/:3:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#编译参数"},{"categories":null,"content":" 如何编译大部分场合下，编译时需要指定的编译参数如下 头文件搜索路径 库搜索路径 优化参数 调试参数 宏定义参数 对于一个单文件，可以在shell中输入编译命令，快速完成编译 对于C/C++工程，手动输入编译命令非常繁琐，在“古代”的方法是使用shell脚本记录编译的命令，问题如下 大型项目构建时间非常长，仅仅修改一个文件也需要重新完成整个工程的编译 如果需要传入参数以控制编译行为，脚本就会变得越来越复杂 ","date":"2024-07-20","objectID":"/posts/week6/:4:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#如何编译"},{"categories":null,"content":" MakefileMakefile就是为了解决以上问题而出现的，它可以认为是shell脚本的一种封装 Makefile有以下内容： 规则 规则告诉Makefile如何生成target 规则分为显式规则和隐式规则，显式规则组成如下 target 通常是输出产物的路径名，即一个规则会产生文件，使用伪target可以定义不产生文件的规则 prerequisites 执行规则前应当满足的先决条件 recipe 规则如何执行，会交给shell解释执行 变量定义 其他指令 例如include指令可以引入其他Makefile文件 makefile的隐式规则可以节省非常多的代码，例如 aaa.o如果没有对应的规则可以生成，Makefile会自动应用隐式规则，将aaa.c编译得到aaa.o CC为默认的C编译器，CXX为默认的C++编译器 CFLAGS为默认编译时，传递给CC的编译参数，同理CXXFLAGS是默认传递给CXX的编译参数 ","date":"2024-07-20","objectID":"/posts/week6/:5:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#makefile"},{"categories":null,"content":" autotoolsC的一个特点是利用宏定义和条件编译，可以控制参与编译的代码，做到适应各种平台，例如 跨平台软件实现子进程时，利用条件编译可以在不同的平台调用相应的系统调用 c #ifdef LINUX // fork ... #endif #ifdef WIN32 // CreateProcess... #endif 注意一般只有标准库没有提供的功能才有必要使用这种方法，例如读写文件就可以直接使用标准库 实现一个高性能的HTTP服务器时往往使用epoll，但内核版本比较旧的linux系统没有epoll，可以使用其下位替代select c #ifdef HAVE_EPOLL // epoll... #else // select #endif C标准没有规定如何控制符号导出，为了导出动态库，可以在windows平台使用visual c++的扩展__declspec(dllexport)，在linux平台可以使用GNU扩展__attribute__((visibility(\"default\"))) c #ifdef LINUX #define MYEXPORT __attribute__((visibility(\"default\"))) #endif #ifdef WIN32 #define MYEXPORT __declspec(dllexport) #endif 所以一个C/C++项目在build之前往往还有configure的步骤，configure识别当前平台、工具链，并允许设置一些功能开关，供用户裁剪功能，configure的产物是一堆用户定义的宏和变量，用于传入构建系统。autotools完成的就是configrue的工作 autotools非常复杂，基于非常原始的文本替换，而且只能在linux平台使用，并不推荐学习autotools，只需要掌握如何使用autotools的configure即可 autotools给编译者（一般区别于开发者）提供的接口为configure，它是一个在项目根目录的具有执行权限的脚本，一般用法如下 shell CFLAGS=-O2 -g ../configure --prefix=/home/arch/xxx configure提供的开关由开发者定义，需要使用../configure --help查看支持的所有开关 CFLAGS通常作为环境变量传入configure，随后configure将参数嵌入生成的Makefile中 --prefix一般用于指定安装目录，默认安装目录/usr/local需要root权限，也可以手动指定一个无特权目录 autotools虽然本身的概念非常晦涩，从设计上来说也不好用，但许多大型开源项目都使用了autotools，原因如下 大部分使用autotools的项目都是历史悠久的老牌开源项目，当时只有autotools可选 autotools是GNU三板斧之一，GNU认为自由软件构建所需的工具链也得是自由的 ","date":"2024-07-20","objectID":"/posts/week6/:6:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#autotools"},{"categories":null,"content":" 树外构建大部分构建工具都会缓存构建中间产物以加快构建速度，套用本博客的文章《第二周：败者树、范式与反范式》的观点，构建中间产物是cache，它违反了唯一事实原则。其后果是在某些情况下，中间产物可能不是最新的，这时需要强制清空所有构建产物，执行一次干净的构建。因此，构建工具往往提供clean的功能 如果将源文件在文件系统中的分布看作源码树，那么直接在项目根目录进行构建，构建的中间产物就会和源码树混杂在一起，这样的构建被称为树内构建，在clean时，需要深入源码树每个层级，精准删除构建中间产物而不删除源文件。Makefile的clean目标一般是使用find命令实现的 构建的中间产物就会和源码树混杂在一起后，会产生如下问题 使得clean操作变得复杂（甚至部分项目无法保证彻底clean，例如glibc） 开发时大量无关文件和源文件混杂，影响效率 鉴于树内构建的问题，通常使用树外构建，即创建一个目录（通常为build），进入此目录进行构建。构建后，输出的构建中间产物和最终产物都在build目录内，clean时不必担心误删源文件 autotools + Makefile的树外构建流程如下 新建一个目录用于构建并进入该目录 shell mkdir build cd build 完成configure shell ../configure 构建 shell make 未完待续 ","date":"2024-07-20","objectID":"/posts/week6/:7:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#树外构建"},{"categories":null,"content":"git相关文章在各种技术论坛、博客都能找到不少，可以说讲git已经是烂大街的文章了，这篇文章虽然跟git有关，但我希望避开各种无聊而且每篇文章都在谈论的话题，输出一些我从各种角落中积累的知识 Note: 如果想学习git，可以看《pro git》 ","date":"2024-07-14","objectID":"/posts/week5/:0:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#"},{"categories":null,"content":" CI/CD一个大型软件往往都有CI/CD系统，以我在实习中即将参与开发的一个产品来说，该产品（以下简称app）有以下需求 定期发布新版本 每次发布需要在多个平台同步发布，具体而言： Windows, Android, iOS, MacOS，iPad, Android平板，Linux等平台 在官网、Android各厂商的应用商店，app store，各种电脑管家提供的软件下载中心等平台发布 需求完成后需要交给测试同学完成测试，测试同学需要在相应平台安装app进行测试，此时的app是不对外公布的测试版本，在内部某个git分支上构建产生 以上需求需要长期、频繁地构建app，CI/CD系统完成的就是这种重复工作 ","date":"2024-07-14","objectID":"/posts/week5/:1:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#cicd"},{"categories":null,"content":" semverSemantic Versioning，即语义化版本，是软件包的一个约定，semver.org如是说 Given a version number MAJOR.MINOR.PATCH, increment the: MAJOR version when you make incompatible API changes MINOR version when you add functionality in a backward compatible manner PATCH version when you make backward compatible bug fixes 即： 版本号主要由主版本号.次版本号.修订号组成 同一个主版本号内保证不出现不兼容的改动 增加与前版本兼容的功能只需要增加次版本号 紧急bug，安全漏洞的修复可以通过增加修订号快速发布 semver面对的背景如下 软件包存在依赖关系 软件包需要持续迭代，不断增加功能并修复bug 上层软件希望它依赖的软件包是稳定的，不出现dependency break 下层软件希望上层软件包不断更新其依赖，使最新的特性被使用，并结束旧版本的支持 它解决了以下问题 下层软件可以不断迭代而不必担心其更新导致现有项目无法运行 历史遗留系统在部署时不出现dependency break 安全漏洞的修复可以最快地应用于生产环境的项目 semver在许多软件包发布系统中都有应用，例如linux众多发行版的软件源，pypi，npm等；当然也有很多不遵守的例子 linux内核 chromium PotoShop Visual studio matlab 不遵守semver的最直接的原因是，这些软件包并不存在直接的被依赖关系 ","date":"2024-07-14","objectID":"/posts/week5/:2:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#semver"},{"categories":null,"content":" semver的应用一个合格的包管理器往往集成了semver，npm和python都提供了版本标记语法，例如 ~5.0.0表示安装5.0.0并接受补丁 ^5.0.0表示安装5.0.0并接受兼容的功能更新 此外，也有特殊情况不遵守semver，一个合格的包管理器还应当具有锁版本的功能，即同一份配置文件在重新安装依赖时，一定产出一样的依赖以及依赖的依赖，保证依赖不发生任何变动 以cmake的ExternalProject为例，它提供了丰富的功能以完全控制一个第三方依赖 下载软件包 支持http下载、git下载、subversion下载、自定义命令下载 configure 可以在此阶段传入编译参数控制软件包的行为 build 可以自定义编译命令，完全控制构建过程和输出的产物 install 可以自定义安装命令，控制安装的位置 其中使用下载软件包支持下载指定分支、指定标签、指定hash，可以轻松控制软件包的版本。如果使用http下载，通常填入官网提供的release版下载链接，版本号通常在会出现在url中，也能控制软件包的版本 ","date":"2024-07-14","objectID":"/posts/week5/:3:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#semver的应用"},{"categories":null,"content":" semver与CI/CD与git前文提及CI/CD一般是在某个分支上（一般是main或master或release）构建出软件包，开发者只需要提交或合并，使分支发生更新，就能触发CI/CD git的每次提交都会产生hash，一般来说hash是整个仓库唯一的，在某次提交中构建出的软件包，可以以hash作为版本号的一部分 git还能给某次提交打上标签，针对这次提交构建出的软件包，可以将标签名作版本号的一部分。更进一步，实际上可以将版本号作为标签名，当分支上出现新的标签时，会触发CI/CD，并触发后续的发布流程 以上提及的流程是软件开发者只维护最新版本的情况，实际上，同时维护多个版本的情况是非常常见的，尤其是软件包已经作为依赖进入了生产环境 假设python2还没有停止支持，python开发者同时维护python2.x和python3.x，python2.x虽然不会出现功能更新，但仍然接受安全修复。更进一步，假设现在python3.12已经发布，而正在开发的是python3.13，此时python3.12发现一个漏洞需要立刻修复，此时使用一个分支作为CI/CD构建的分支是不够的。常见的做法是，python2.x使用release/2.x作为分支名，而python3.x使用release/3.x作为分支名，而release/目录下的所有分支都能触发CI/CD ","date":"2024-07-14","objectID":"/posts/week5/:4:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#semver与cicd与git"},{"categories":null,"content":" git workflowapp的开发部门有上百名开发者，git仓库每时每刻都有可能发生推送，为了实现百名开发者的协作，app采用了以下流程 release分支作为发布使用，在任何时刻release分支构建出来的软件包都是可以对外公布的包。release分支不接受推送，只接受master分支的合入 master分支拉出其他所有分支，不接受推送，只接受feature系列分支和bugfix分支的合入， feature系列分支具有实现需求的代码，不接受推送，只接受feature_dev系列分支合入。一次版本更新包括多个需求，会产生对应的feature分支 feature_dev系列分支是开发者个人使用的分支。一个需求一般对应一个feature分支，而一个需求往往由几个开发者合作完成，每个开发者分别在自己的feature_dev分支上开发 bugfix系列分支具有修复某个bug或某个安全漏洞的代码，完成修复后合入master 可以看出合并的顺序，或者从开发者敲下一行代码，到最终进入产品的过程如下 flowchart LR feature_dev --合入--\u003e feature feature --合入--\u003e master master --合入--\u003e release release --CI/CD--\u003e发布 buffix --合入--\u003emaster 使用这样一个流程，原因如下 app是一个2C的产品，只维护最新版本 大部分冲突在feature_dev合入feature时解决（一般冲突范围小，而且与同一个需求相关，容易解决），其次由feature合入master分支时解决 线上出现问题时，修复代码可以通过bugfix分支快速进入产品中 合入的过程无法在本地完成，必须在git平台完成，合入需要对应分支的负责人完成codereview并批准 此外，feature_dev合入feature时，由对应的开发者完成本地自测，feature合入master时，由CI/CD系统构建出测试用的app，并交由测试同学完成测试。所有feature分支合入master分支后，需要运行一个完整的全面的测试，视bug数量和影响程度决定是否进入后续的发布流程 ","date":"2024-07-14","objectID":"/posts/week5/:5:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#git-workflow"},{"categories":null,"content":" 常见概念 nightly build 常见于大公司的大型开源项目中，大公司有许多开发者负责项目的开发，每天推送代码后，开发者下班回家，此时基本不会发生推送，CI/CD系统开始运行，从当天最新代码中构建出最新的软件包，得名于一般在每天晚上构建 nightly build因为频繁更新，稳定性欠佳，但因为具有最新的特性，某些情况下可以使用nightly build的软件包以快速得到修复或体验新特性 灰度 新版本的软件包在部分用户完成灰度测试，收集日志和灰度用户的反馈，判断软件包的质量，以决定是否全量发布。如果将产品上线认为是黑，未上线是白，那么仅推送给部分用户就是灰度 灰度用户的比例往往较小，而且灰度用户无感知，因为灰度软件包往往是静默完成的更新 构建号 因为CI/CD重复、频繁的构建，需要一种id来确定软件包来源于哪次构建 CI/CD系统往往需要填写一些secrets，例如访问token，数据库密码等，使用不同的secrets，就能将软件包部署到不同的环境。此外还能填写国家代号、区域代号，实现一份代码构建出不同的软件包给不同国家或区域的用户使用。 因为不同国家的法律要求不同，软件包往往会在某些国家屏蔽部分功能以合规。以app为例，有专门的法务部研究市场所在国家的法律，并将消息同步给开发部门。法务部门不仅仅需要研究哪些功能是不合规的，还需要判断哪些行为具有合规风险 以上原因导致无法通过构建基于的提交的hash来唯一确定软件包来源于哪次构建，所以使用构建号来区分 以windows系统为例，系统版本号中就带有构建号 Version Servicing option Availability date Latest revision date Latest build 22H2 General Availability Channel 2022-10-18 2024-07-09 19045.4651 21H2 General Availability Channel 2021-11-16 2024-07-09 19044.4651 未完待续。。。 ","date":"2024-07-14","objectID":"/posts/week5/:6:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#常见概念"},{"categories":null,"content":" About me无故事王国的居民，即将大四的计算机科学专业学生 ","date":"2024-07-12","objectID":"/about/:1:0","series":null,"tags":null,"title":"About","uri":"/about/#about-me"},{"categories":null,"content":" 兴趣 游戏： ACGN中的G，想成为galgame领域大神 音乐： 日语流行，听音乐时长约等于敲代码时长 书籍：刘慈欣的科幻小说 论坛： v2ex 摸鱼常去 galgame吧：业界要完~ ","date":"2024-07-12","objectID":"/about/:2:0","series":null,"tags":null,"title":"About","uri":"/about/#兴趣"},{"categories":null,"content":" Goals 学习日语，希望能无障碍游玩生肉作品 成为python的contributor ","date":"2024-07-12","objectID":"/about/:3:0","series":null,"tags":null,"title":"About","uri":"/about/#goals"},{"categories":null,"content":" hates 华为：什么遥遥领先 知乎：你乎平均水平真是让我大开眼界 ","date":"2024-07-12","objectID":"/about/:4:0","series":null,"tags":null,"title":"About","uri":"/about/#hates"},{"categories":null,"content":" 开发环境 archlinux jetbrains IDEs vscode terminal chrome ","date":"2024-07-12","objectID":"/about/:5:0","series":null,"tags":null,"title":"About","uri":"/about/#开发环境"},{"categories":null,"content":" 写在前面博客新增了许多功能，包括作者资料，友链，样式优化，社交链接等等，其中Steam社交链接格式不正确，我给博客主题的作者提了一个 pull request，这是我的第一个pr，只修改了一个单词，很幸运地被merge了， 如果你也在使用DoIt主题，那么说不定其中某行代码就是我写的😋 博客也增加了RSS功能，欢迎订阅！ 最近回家后琐事明显增多了，基本没什么产出，就来拷打一下之前遇到的一些东西吧 ","date":"2024-07-01","objectID":"/posts/week3/:1:0","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#写在前面"},{"categories":null,"content":" 小程序大概一个月前帮一位同学做了一个很简单的小程序，只有一个按钮，这其中我遇到了小程序的不少槽点 先简单介绍一下小程序是什么，小程序和web页面很像，但小程序的JS执行线程和渲染线程是分开的，这是最大的区别，也造成了很多麻烦的东西 小程序的逻辑层和渲染层是分开的，逻辑层运行在 JSCore 中，并没有一个完整浏览器对象，因而缺少相关的DOM API和BOM API。这一区别导致了前端开发非常熟悉的一些库，例如 jQuery、 Zepto 等，在小程序中是无法运行的' 官方称将JS线程和渲染线程分开的目地是为了提高页面渲染性能，避免性能不足的移动设备出现卡钝、动画生硬等问题 以下是我的批评 ","date":"2024-07-01","objectID":"/posts/week3/:2:0","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#小程序"},{"categories":null,"content":" 没有完整DOM自绝于npm庞大的生态，而且造成了不必要的麻烦 ","date":"2024-07-01","objectID":"/posts/week3/:2:1","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#没有完整dom"},{"categories":null,"content":" 运行环境环境割裂宣传口径中，小程序的一个优点是不需要让用户安装app，android和ios用户都能使用。然而小程序的运行环境非常割裂 运行环境 逻辑层 渲染层 iOS,iPadOS, MacOS JavaScriptCore WKWebView 安卓 V8 基于 Mobile Chromium 内核的微信自研 XWeb 引擎 windows Chromium 内核 Chromium 内核 小程序开发者工具 NWJS Chrome WebView 可以看到以上平台基本把各种环境来了一个排列组合，然而开发者不一定有这么多设备可以测试。即使有足够多的设备，小程序写好后还需要在不同平台测试，检查平台差异，徒增工作量 WXSS 渲染表现不一致：尽管可以通过开启样式补全来规避大部分的问题，还是建议开发者需要在各端分别检查小程序的真实表现。 ","date":"2024-07-01","objectID":"/posts/week3/:2:2","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#运行环境环境割裂"},{"categories":null,"content":" DOM API混乱以上已经提及DOM不完整，此外因为JS环境割裂，导致不同平台的DOM API不仅仅是不完整的，而且每个平台的DOM API支持情况也不相同 这导致了开发者不确定某个DOM API在其他平台是否可用，最后干脆都不使用了(小程序到底可以使用哪些DOM API，官方并没有文档说明) 最坑的情况是，在小程序开发者工具中可用，但在真机不可用（因为小程序开发者工具的JS环境跟真机也不相同） 以上似乎还是比较合理的，但实际使用下来就会发现小程序非常坑的一点 我开发的小程序是对接阿里云的某个API，涉及加密，URL参数处理等。加密直接从网上找了一个函数实现，剩下的字符串处理被小程序坑了两次 atob，btoaatob和btoa这两个函数是DOM API提供的将base64和二进制数据相互转换的配套函数 我使用的场合很简单，只需要将一个普通的字符串使用base64编码即可，这种情况下应该使用atob 小程序并没有atob，但讽刺的是它有btoa。发现这一事实后我相当的愤怒，因为atob和btoa 只是简单的字符串处理函数而已，小程序的JS环境对这两个配套的函数，居然能作出只支持其中一个的行为。此外， 即使JS环境就是这么随意，小程序官方也完全可以提供一个JS实现的btoa，并在小程序执行前动态绑定到DOM上，避免给开发者造成 不必要的麻烦 有人可能会说，既然btoa只是一个简单的字符串处理函数，为什么开发者不能自己造一个轮子呢？ 因为base64编码是一种标准，涉及诸多细节，例如查码表，位数补齐等等，所以实现一个符合标准的btoa是一个简单但琐碎的工作，这种工作一般是由标准库完成，而不是由开发者完成 URLSearchParamsURLSearchParams表示url的查询参数，我使用这个函数将参数组装成查询字符串，简单来说，有一些参数 JS const params = { a: 1, b: \"aaa\" } 组装成a=1\u0026b=aaa的格式，看起来很简单，但查询字符串需要符合URL标准，即只能使用URL安全的字符，也就是某些URL不安全的字符需要转义，所以这也是一个简单但琐碎的工作 毫不意外地，小程序没有提供这个API，于是我在确认查询参数中不存在URL不安全字符后，造了一个非常简陋的轮子 甚至我找到一篇问答抱怨URLSearchParams的支持情况，其中的部分回答 都快2024了还不支持……………….. 懂不懂就说背锅，这么基础的东西都不支持 以上原因，导致一个非常简单的需求，我都花了几小时实现，开发体验极差。简单的字符串处理函数都不支持，我开发后的感想就是，小程序官方无作为。。。 ","date":"2024-07-01","objectID":"/posts/week3/:2:3","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#dom-api混乱"},{"categories":null,"content":" DOM API混乱以上已经提及DOM不完整，此外因为JS环境割裂，导致不同平台的DOM API不仅仅是不完整的，而且每个平台的DOM API支持情况也不相同 这导致了开发者不确定某个DOM API在其他平台是否可用，最后干脆都不使用了(小程序到底可以使用哪些DOM API，官方并没有文档说明) 最坑的情况是，在小程序开发者工具中可用，但在真机不可用（因为小程序开发者工具的JS环境跟真机也不相同） 以上似乎还是比较合理的，但实际使用下来就会发现小程序非常坑的一点 我开发的小程序是对接阿里云的某个API，涉及加密，URL参数处理等。加密直接从网上找了一个函数实现，剩下的字符串处理被小程序坑了两次 atob，btoaatob和btoa这两个函数是DOM API提供的将base64和二进制数据相互转换的配套函数 我使用的场合很简单，只需要将一个普通的字符串使用base64编码即可，这种情况下应该使用atob 小程序并没有atob，但讽刺的是它有btoa。发现这一事实后我相当的愤怒，因为atob和btoa 只是简单的字符串处理函数而已，小程序的JS环境对这两个配套的函数，居然能作出只支持其中一个的行为。此外， 即使JS环境就是这么随意，小程序官方也完全可以提供一个JS实现的btoa，并在小程序执行前动态绑定到DOM上，避免给开发者造成 不必要的麻烦 有人可能会说，既然btoa只是一个简单的字符串处理函数，为什么开发者不能自己造一个轮子呢？ 因为base64编码是一种标准，涉及诸多细节，例如查码表，位数补齐等等，所以实现一个符合标准的btoa是一个简单但琐碎的工作，这种工作一般是由标准库完成，而不是由开发者完成 URLSearchParamsURLSearchParams表示url的查询参数，我使用这个函数将参数组装成查询字符串，简单来说，有一些参数 JS const params = { a: 1, b: \"aaa\" } 组装成a=1\u0026b=aaa的格式，看起来很简单，但查询字符串需要符合URL标准，即只能使用URL安全的字符，也就是某些URL不安全的字符需要转义，所以这也是一个简单但琐碎的工作 毫不意外地，小程序没有提供这个API，于是我在确认查询参数中不存在URL不安全字符后，造了一个非常简陋的轮子 甚至我找到一篇问答抱怨URLSearchParams的支持情况，其中的部分回答 都快2024了还不支持……………….. 懂不懂就说背锅，这么基础的东西都不支持 以上原因，导致一个非常简单的需求，我都花了几小时实现，开发体验极差。简单的字符串处理函数都不支持，我开发后的感想就是，小程序官方无作为。。。 ","date":"2024-07-01","objectID":"/posts/week3/:2:3","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#atobbtoa"},{"categories":null,"content":" DOM API混乱以上已经提及DOM不完整，此外因为JS环境割裂，导致不同平台的DOM API不仅仅是不完整的，而且每个平台的DOM API支持情况也不相同 这导致了开发者不确定某个DOM API在其他平台是否可用，最后干脆都不使用了(小程序到底可以使用哪些DOM API，官方并没有文档说明) 最坑的情况是，在小程序开发者工具中可用，但在真机不可用（因为小程序开发者工具的JS环境跟真机也不相同） 以上似乎还是比较合理的，但实际使用下来就会发现小程序非常坑的一点 我开发的小程序是对接阿里云的某个API，涉及加密，URL参数处理等。加密直接从网上找了一个函数实现，剩下的字符串处理被小程序坑了两次 atob，btoaatob和btoa这两个函数是DOM API提供的将base64和二进制数据相互转换的配套函数 我使用的场合很简单，只需要将一个普通的字符串使用base64编码即可，这种情况下应该使用atob 小程序并没有atob，但讽刺的是它有btoa。发现这一事实后我相当的愤怒，因为atob和btoa 只是简单的字符串处理函数而已，小程序的JS环境对这两个配套的函数，居然能作出只支持其中一个的行为。此外， 即使JS环境就是这么随意，小程序官方也完全可以提供一个JS实现的btoa，并在小程序执行前动态绑定到DOM上，避免给开发者造成 不必要的麻烦 有人可能会说，既然btoa只是一个简单的字符串处理函数，为什么开发者不能自己造一个轮子呢？ 因为base64编码是一种标准，涉及诸多细节，例如查码表，位数补齐等等，所以实现一个符合标准的btoa是一个简单但琐碎的工作，这种工作一般是由标准库完成，而不是由开发者完成 URLSearchParamsURLSearchParams表示url的查询参数，我使用这个函数将参数组装成查询字符串，简单来说，有一些参数 JS const params = { a: 1, b: \"aaa\" } 组装成a=1\u0026b=aaa的格式，看起来很简单，但查询字符串需要符合URL标准，即只能使用URL安全的字符，也就是某些URL不安全的字符需要转义，所以这也是一个简单但琐碎的工作 毫不意外地，小程序没有提供这个API，于是我在确认查询参数中不存在URL不安全字符后，造了一个非常简陋的轮子 甚至我找到一篇问答抱怨URLSearchParams的支持情况，其中的部分回答 都快2024了还不支持……………….. 懂不懂就说背锅，这么基础的东西都不支持 以上原因，导致一个非常简单的需求，我都花了几小时实现，开发体验极差。简单的字符串处理函数都不支持，我开发后的感想就是，小程序官方无作为。。。 ","date":"2024-07-01","objectID":"/posts/week3/:2:3","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#urlsearchparams"},{"categories":null,"content":" 质疑我对小程序的质疑如下 如果它真的是一个先进的技术，为什么我至今没看到国外有使用？ 很多APP都有小程序，他们提供的平台能力也不一样（例如微信小程序和支付宝小程序），为微信开发的小程序没法在支付宝使用 接上，为了解决小程序的“跨平台”问题（跨平台这个词真是讽刺），有uniapp这样解决方案，但uniapp本身就是一个不逊于小程序的大坑 小程序由一家商业公司维护，而web有W3C维护标准，一群巨头浏览器厂商竞争，我为什么要开发小程序而不开发web？ chrome没有将渲染和JS执行分成两个线程，但chrome在移动设备上的表现也不低于小程序，将渲染和JS执行分开是否有必要？ ","date":"2024-07-01","objectID":"/posts/week3/:2:4","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#质疑"},{"categories":null,"content":" webview前文拷打的小程序，我认为它出现的一个原因是android的webview非常割裂，新机型和老机型的webview版本相差太多，以至于微信选择了另一条与web标准并立的方式，让许多老机型也能 正常使用web 私以为，webview割裂的一个原因是，国内android无法使用google框架，所以也无法使用google play这个在安卓生态中占据统治地位的应用商店， 所以系统自带的webview只能依靠国产安卓vendor提供更新 然而很多老机型，国产android厂商很久，或者根本不推送更新了，也就导致老机型的webview永远停留在了一个很旧的版本，这样的机型早已被日新月异的Web标准抛弃 此外，国内很多移动互联网用户并没有经历桌面互联网时代，而微信占据了国内移动互联网的绝大部分流量，自然有能力另起一套方案与占据了互联网大部分入口流量的google竞争， 可以顺理成章地得出，小程序只是微信为了圈住流量，将微信成为流量入口的一个工具而已。 ","date":"2024-07-01","objectID":"/posts/week3/:2:5","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#webview"},{"categories":null,"content":" polyfill前文提及小程序的DOM API不完整，实际上小程序对ECMA Script标准的支持也不完整，对于这种情况，可以使用一种被成为pollyfill的技术，即使用已有的东西去模拟出缺失的东西 微信小程序内置了core.js，但因为时间有限我并没有搞明白怎么使用。相反，我发现有一个开源项目polyfill.io，只需要引入它的一个JS文件，它的服务器会自动根据UA判断出缺失的功能， 并只发送能够polyfill这些缺失的功能的JS脚本 在这篇文章写下的几天前，polyfill.io被发现向千万个站点返回了恶意JS脚本，现在其仓库polyfillpolyfill/polyfill-service 已经被github封禁，polyfill.io也无法访问 这个现实非常可怕，因为我曾经也尝试过使用polyfill.io（虽然最终并没有使用），也让我产生另一个对小程序官方不作为的批评：小程序官方不提供足够的polyfill，导致开发者寻求第三方解决方案，但第三方不一定是安全的 实际上，以上提到的很多问题也许都能通过脚手架或框架避免，但我的观点仍然同polyfill，小程序不提供足够的能力，而将工作交给开发者，这造成了以下问题 个人开发者：花费精力寻找并对比合适的脚手架 企业：花费精力确认脚手架的安全性，稳定性 ","date":"2024-07-01","objectID":"/posts/week3/:2:6","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#polyfill"},{"categories":null,"content":" Friends Nelson Boss - 「🌊一直游到海水變藍」 ","date":"2024-07-01","objectID":"/friends/:0:0","series":null,"tags":null,"title":"Friends","uri":"/friends/#friends"},{"categories":null,"content":" 欢迎交换友链 mailto: virtualfuture@gmail.com 下方gittalk评论 ","date":"2024-07-01","objectID":"/friends/:0:0","series":null,"tags":null,"title":"Friends","uri":"/friends/#欢迎交换友链"},{"categories":null,"content":"新内容的博客主题并不明显，基本是最近学习到的知识，平日突然浮现在头脑中的随想，或者很久以前遇到过的一些事情 ","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#"},{"categories":null,"content":" 归并排序与败者树上篇文章提到的归并排序，经过两次重构已经很完善了，最终的结果是一个归并排序类ExternalMergeSorter，通过一个头文件引入external_merge_sort.h, 非常优雅地隔离了归并排序的细节，只需要给sorter提供记录，然后指示sorter开始排序，最后依次从sorter中取出记录，取出的记录已经是有序的了 ","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#归并排序与败者树"},{"categories":null,"content":" IO关于IO的方式也考虑了很多，mmap，read， fread，std::fstrean都能实现需要的功能，最终选择了std::fstream mmap 效率很高，读入文件时，相比read少了一次内核数据复制 read时： 外存中的文件 –\u003e 内核维护的缓冲区 –\u003e 进程维护的缓冲区 mmap时： 外存中的文件 –\u003e 内核分配给进程的页 mmap分配的页是惰性分配的，mmap调用返回时，分配的页仍然是用户地址空间非法的页，进程第一次访问时，陷入内核态（因为访问了非法的页），然后内核完成页的分配，并填入正确的数据 此外，mmap分配的页也会正常的换出换入内存，实际内存使用量不会很高 Q：为什么read读取文件时有内核维护的缓冲区和进程维护的缓冲区？ A: 内核维护的缓冲区是对进程隐藏的，进程无法访问（在进程的地址空间中不存在），这是为了防止恶意进程破坏操作系统 部署数据库的服务器可能会关闭内存交换功能，此时操作系统不会将近期不使用的页换出内存 不过缺点也很明显，需要手动维护读写指针，而且如果设置了每次mmap的页（不是操作系统的页）的大小，还需要再实现大文件分页，包括不满一页，刚好满一页，满n页不满n+1页各种corner case，并需要给corner case写测试，非常繁琐 read read和mmap都是linux的系统调用，使用read时操作系统会帮我们维护读写指针，但仍然需要自己处理分页 fread libc提供的IO函数，内部会自动维护缓冲，读写指针，如果设置了缓冲区大小，也相当于有了分页的功能 std::fstream libc++的IO函数，fread已经能满足要求了，但使用std::fstream是一种\"when in cpp do as the cpper do\"的做法 ","date":"2024-06-25","objectID":"/posts/week2/:1:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#io"},{"categories":null,"content":" k路归并排序归并排序处理大规模数据时，会形成多个文件，假设为k个，最终将k个已排序块合并的过程，就是k路归并排序 k路归并时，每次取出k个已排序块中最小的记录，如何确定哪个记录是最小的，可以简单的遍历k个记录，找出其中最小的一个，也可以使用胜者树、败者树加快归并的过程 遍历k个记录，可以被称为暴力查找，时间复杂度是$$O(k)$$ 而胜者树、败者树的时间复杂度为$$O(\\log k)$$ k值一般不会很大，经典值有8，16。虽然k很小，但因为取出每条记录都需要经过归并，此处的算法优化效果是非常可观的，我测试的情况是64M规模排序，使用暴力查找耗时5min，使用败者树耗时大约5s ","date":"2024-06-25","objectID":"/posts/week2/:2:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#k路归并排序"},{"categories":null,"content":" 胜者树胜者树的思想是，假设有八个选手A，B，C，D，E，F，G，H参与比赛，他们两两配对并参与比赛，比赛的胜者参与下一轮比赛，只需要三轮比赛就能比出冠军 text 第三轮比赛的胜者 A 第二轮比赛的胜者 A H 第一轮比赛的胜者 A D E H 参赛选手 A B C D E F G H 八个选手中A胜出，胜者树记录了A通过比赛不断“上升”的过程 现在假设因为某种原因，原来的冠军A被替换成A1，而A1的排名未知，需要重新确定冠军 A1与B比赛，如果A1胜，则A1作为胜者进入下一轮比赛，如果B胜，则B作为胜者进入下一轮 设A与B比赛的胜者为X1(X1 = A1 | B)， X1与D比赛， 产生的胜者X2进入下一轮 X2与H比赛，产生的胜者即为冠军 胜者树的算法思想是动态规划，八个选手比赛的过程中，有很多重复的子问题，例如，A的排名需要重新确定时，C和D的胜负关系是不会改变的，所以C和D没必要再比赛，同理E和H也没必要再比赛，胜者树这样的数据结构在归并过程中维护了最优子结构，避免了重复完成子问题 ","date":"2024-06-25","objectID":"/posts/week2/:3:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#胜者树"},{"categories":null,"content":" 败者树将胜者树中的节点的值换成这轮比赛中的败者，其他不变，就形成了败者树 败者树的一个缺点就是不直观，因为节点记录了败者，但参赛的仍然是胜者，事实上，在构建败者树的过程中仍然需要构建胜者树。 败者树相比胜者树的优点是，重新确定冠军时，当前参赛选手需要和上次当轮比赛的败者比赛（例如第一轮比赛中，X1需要和D比赛），胜者树需要从兄弟节点获取败者，而败者树可以直接从父节点获取败者 败者树的另一个理解是，败者树的节点中存储的是左右子树两胜者中比赛产生的次胜者，而优胜者进入下一轮比赛。例如败者树中存储了D的节点，D来源于第一轮比赛中A和D比赛，其中A是优胜者，D是次胜者 text 冠军 A 第三轮比赛的败者 H 第二轮比赛的败者 D E 第一轮比赛的败者 B C F G 参赛选手 A B C D E F G H 此外败者树的根节点记录的是败者，所以还需要额外记录一个冠军 ","date":"2024-06-25","objectID":"/posts/week2/:4:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#败者树"},{"categories":null,"content":" 实现我使用堆模拟了败者树，败者树也是一种二叉树，堆模拟二叉树的优点如下 内存碎片小 节点在内存中是紧邻的，能充分利用高速缓存的性能，cache友好 此外，堆模拟的二叉树中访问父节点，兄弟节点也非常简单，可以使用位运算 假设堆的大小为16，第一个元素不使用，模拟的二叉树如下 text 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 其中的数组表示节点的编号，或节点在堆中的索引 假设当前节点为x，其父节点为x \u003e\u003e 1，兄弟节点为 x ^ 1，左子节点为x \u003c\u003c 1，右子节点为(x \u003c\u003c 1) + 1 其中第一个未使用的元素在败者树中刚好用来存储冠军，非常巧妙 堆模拟败者树有两个坑点： 分清节点编号和选手编号（在这篇文章中我特意使用字母ABC表示选手编号，而使用数字123表示节点编号，但实现时，使用的都是数字类型） 堆模拟的败者树消除了败者树的优势：直接从父节点获取败者，因为堆访问兄弟节点非常方便，而且没有额外的空间开销。此外败者树非常不直观，如果使用堆模拟，可以考虑胜者树 ","date":"2024-06-25","objectID":"/posts/week2/:5:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#实现"},{"categories":null,"content":" corner case外部归并排序中产生多少个辅助排序文件，一般是不可控制的，选手数量往往不是2的幂 此时增加若干个哑节点(dumb node)，使选手数量达到2的幂，哑节点参与比赛一定败北 最终实现见external_merge_sort.h，在木兰宽松许可证下开源 ","date":"2024-06-25","objectID":"/posts/week2/:5:1","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#corner-case"},{"categories":null,"content":" exit在对比fread，fwrite和std::fstream时，看到有篇回答提及，如果程序异常退出，std::fstream可能来不及把缓冲区的内容落盘 cpp #include \u003cstdlib.h\u003e #include \u003cfstream\u003e using std::ofstream; int main() { ofstream ofs(\"hello.txt\"); ofs \u003c\u003c \"Hello world\\n\"; exit(0); } 这里又涉及一个问题，std::fstream需要手动关闭吗？ ","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#exit"},{"categories":null,"content":" fstream自动关闭答案是可以不手动关闭，因为fstream会在析构时自动关闭。见cppreference对basic_fstream的析构函数的说明 destructs the basic_fstream and the associated buffer, closes the file 然后来翻源码证实一下 首先看一下cppreference对fstream，ifstream，ofstream的说明 basic_istream最终实例化为ifstream，basic_ostream最终实例化为ofstream，basic_iostream最终实例化为fstream，所以fstream相当于ifstream和ofstream的父类 以ofstream举例，它的析构函数在glibc的头文件fstream中 cpp /** * @brief The destructor does nothing. * * The file is closed by the filebuf object, not the formatting * stream. */ ~basic_ofstream() { } 看来关闭文件的工作是交给filebuf完成的，此处的filebuf指的是basic_ofstream的成员变量_M_filebuf 实现如下 cpp /** * @brief The destructor closes the file first. */ virtual ~basic_filebuf() { __try { this-\u003eclose(); } __catch(...) { } } 那么自动关闭和手动关闭的区别在哪里呢？ ofstream的close方法实现如下 cpp /** * @brief Close the file. * * Calls @c std::basic_filebuf::close(). If that function * fails, @c failbit is set in the stream's error state. */ void close() { if (!_M_filebuf.close()) this-\u003esetstate(ios_base::failbit); } 它也是调用了filebuf的close方法，除了错误处理有所不同，其他完全一样 初学时总被反复提醒ofstream打开了一定要关闭，但实践不一定需要完全遵循，举几个例子 一个很短的函数内打开ofstream，可以不关闭，函数退出时自动关闭 一个很长的函数内打开ofstream，为了尽快释放资源可以手动关闭，也可以利用对象离开作用域立刻销毁的特性，额外创建一个作用域，让ofstream提前销毁，这也是更符合C++的RAII的做法 cpp { std::ofstream file(\"output.txt\"); // 写入文件 } // 此处已经关闭 这个特性在其他语言中很少出现，因为C++无GC，对象销毁时机是完全确定的，而GC语言即使提供了析构函数，因为无法确定对象销毁时机，实现某些对销毁时机非常敏感的特性（例如RAII的锁）时，会出现很多无法预料的情况 libc在进程退出和exit时会自动将所有FILE缓冲区残留的数据落盘，并释放缓冲区 linux在进程exit系统调用时会自动关闭进程未关闭的文件，并释放进程的内存 ","date":"2024-06-25","objectID":"/posts/week2/:1:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#fstream自动关闭"},{"categories":null,"content":" 无法自动关闭的特殊情况fstream的关闭依赖于其析构函数的调用，只需要绕过析构函数即可，绕过方法其一就是exit函数 前文提及libc的exit函数会关闭所有打开的FILE，关闭的过程包括缓冲区残留的数据落盘和释放缓冲区，但exit函数不会关闭ofstream，因为ofstream自己维护了一个缓冲区，而没有使用FILE对象的缓冲区 首先确定一点，ofstream会自动分配缓冲区，也可以由用户手动设置缓冲区 ofstream的open方法实现如下 cpp template\u003ctypename _CharT, typename _Traits\u003e typename basic_filebuf\u003c_CharT, _Traits\u003e::__filebuf_type* basic_filebuf\u003c_CharT, _Traits\u003e:: open(const char* __s, ios_base::openmode __mode) { __filebuf_type *__ret = 0; if (!this-\u003eis_open()) { _M_file.open(__s, __mode); if (this-\u003eis_open()) { _M_allocate_internal_buffer(); // 省略... } } return __ret; } _M_allocate_internal_buffer函数完成了缓冲区的自动分配，实现如下 cpp template\u003ctypename _CharT, typename _Traits\u003e void basic_filebuf\u003c_CharT, _Traits\u003e:: _M_allocate_internal_buffer() { // Allocate internal buffer only if one doesn't already exist // (either allocated or provided by the user via setbuf). if (!_M_buf_allocated \u0026\u0026 !_M_buf) { _M_buf = new char_type[_M_buf_size]; _M_buf_allocated = true; } } 使用默认内存分配器申请了一块内存用于缓冲区，可以看到并没有把这块内存交给FILE管理 libc和libc++的实现都会随着版本迭代而变化，具体实现一般都对用户隐藏，而只暴露必要的接口，libc和libc++需要保持彼此独立所以也不能使用对方的非公开API 至此已经能回答之前的问题，为什么fstream在调用exit后数据没有落盘？因为数据残留在fstream内部维护的缓冲区中，没有同步到外存，而exit不负责为fstream清理残局 ","date":"2024-06-25","objectID":"/posts/week2/:2:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#无法自动关闭的特殊情况"},{"categories":null,"content":" 范式与反范式","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#范式与反范式"},{"categories":null,"content":" 分层纵观整个计算机体系，分层的思想从底层到上层都在不断的使用。有句名言：计算机中的一切问题都能使用分层解决 分层解决实际问题的例子 计算机网络仅仅使用五层就实现了世界上规模最大最复杂的网络 通过增加域名这一层，使得32bit的ip拥有了树状结构，符合人类社会的组织规律（国家区域顶级域名，用途特定域名gov,edu等），使得负载均衡，代理等灵活的技术成为可能 分层的工作是，使用当前层提供的原语，屏蔽当前层的细节，向上层提供更简单更强大的原语 以上是教科书内容，分层思想很伟大，但在实践中有时会违背分层的思想。分层是范式，所以理所当然有其反范式，例如NAT NAT实现了网络地址的转换，它维护一个外网端口号：内网端口号+内网ip的映射，有关NAT的批评其一就是它违反了计算机网络中分层的思想，因为NAT工作在网络层，而它会修改端口号，而端口号属于传输层。即NAT修改了上层报文内容 这体现了分层往往存在的问题：分层尝试屏蔽底层细节，但无法完全屏蔽。所以计算机科学从业者就需要对整个计算机体系的每一层具有足够的了解，才能解决复杂的问题。例子 即使使用C写操作系统，也不得不写汇编指令，因为C没有提供在C层面调用某些汇编指令的能力 跨平台尝试抹平平台差异，但也会限制平台原生能力的使用，所以跨平台往往还需要写平台原生插件 linux的VFS向上层提供了一致的文件模型，屏蔽了底层资源、文件系统、硬件等差异，但数据库开发中还是需要考虑计算机的存储设备的硬件情况，例如磁盘读写时间包括了寻道时间，旋转延迟， 传输时间。而其中寻道时间和旋转延迟占了大部分时间，所以数据库会在内存中分块缓存修改后的文件内容，积累一段时间后再写回。数据库使用的IO策略立足于存储设备硬件现实 此外，分层也无法解决全部的问题，分层体系中，往往能找出一些上层重复实现底层功能的例子 例如 操作系统提供了IO缓冲，而libc还要在实现一遍 操作系统提供了LRU的页置换策略，而数据库还需要再实现一遍。数据库有时候甚至需要绕过操作系统这一层(前文提及“部署数据库的服务器可能会关闭内存交换功能”) libc提供了内置的内存分配器，而postgresql也实现了自己的内存分配器 libc提供了许多标准库中的函数，例如字符串处理函数，memcpy等，这些在postgresql中也有重复实现 对这一现实，我的理解如下 操作系统访问外存速度很慢，所以操作系统尝试缓冲IO，但进程进行系统调用的过程也很慢，所以libc提供IO缓冲，减少系统调用的次数，提高性能 libc的内存分配器和memcpy，考虑的是通用场景，而特定场景下的性能可能不如数据库的实现。例如内存分配器的一个功能是尽可能减少内存碎片，而每次需要分配的内存有多大是由用户随意决定的。如果数据库完全掌握内存使用情况，就能使用针对数据库场景优化的内存分配器，减少内存碎片 LRU置换策略，理由同上。数据库能针对各种算子专门优化，而操作系统无法知道进程何时需要访问页面，只能基于局部性原理进行假设 libc提供的字符串处理函数安全性不够，实际上很多大型项目都会重新造一遍字符串处理函数，为了解决诸如缓冲区溢出，零结尾等问题 ","date":"2024-06-25","objectID":"/posts/week2/:1:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#分层"},{"categories":null,"content":" 关系型数据库六范式关系型数据库的六范式的作用是减小数据冗余，消除插入异常，删除异常等，但在实践中，往往不会完全遵循六范式，因为划分实体和关联的工作非常复杂，只有领域专家才有可能做到。一般往往只遵循到第三范式 此外，关系型数据库的范式会使越拆越小，在查询时需要做大量的连接操作，连接操作可以使用索引，使用归并连接，使用哈希等方式加快连接速度，但对时间复杂度的减小效果有限，数据量极大时仍然非常耗时。大数据和NoSQL就完全违反了关系型数据库的范式，但换来了非常快的查询速度 ","date":"2024-06-25","objectID":"/posts/week2/:2:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#关系型数据库六范式"},{"categories":null,"content":" 唯一事实原则如果一个人有很多钟，反而无法确定时间，因为不同钟显示的时间不一样。在工程实践中为了避免这种问题，往往遵循single source of truth，即唯一事实原则，例如 将一些参数提升为配置，其他要使用参数的地方只能引用参数，不能内联 JS的ORM框架prisma使用prisma.schema作为唯一事实，并使用这一事实同步数据库和生成的类型 然而唯一事实原则也有其反范式，而且使用非常广泛，即cache 此处cache指CPU提供的高速缓存，它和内存共同维护了一个数据的两个副本，非常明显的反范式，后果就是需要额外维护cache和内存的一致性 cache有脏数据，而内存中的数据是干净的：需要将脏数据写回，而且需要选择写回时机 内存中有脏数据，而cache中的数据是干净的，需要同步到cache 此外cache的存在对DMA非常不友好，让DMA变得更加复杂了，因为DMA能在不经过CPU的情况下读写内存 ","date":"2024-06-25","objectID":"/posts/week2/:3:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#唯一事实原则"},{"categories":null,"content":" buffer vs cache最近突发奇想，使用另一个角度理解缓冲与缓存 首先，我认为缓存的译名不准确，因为缓存的“缓”，在字典中是“慢”的意思，而缓存明显是用来加快速度用的，参考cache的台湾译名“快取” 有两个系统A和B，它们通过接口相连，然而A和B的速度是不匹配的（A速度远大于B）。基于以上事实，才有必要使用buffer或cache，这也是现实中非常常见的情况 两个速度不匹配的系统为了能够一起工作，必定还有其他条件，否则认为这两个系统不应该相互连接 如果两个系统不应该连接，此时有两种方案改进 使用性能更好的B1， 提高系统整体性能 使用性能低但更便宜的A1，降低系统的造价 ","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#buffer-vs-cache"},{"categories":null,"content":" 附加条件：A猝发生产而B持续消费此时使用buffer，即缓冲 网络流量往往是猝发的，而操作系统或用户程序无法保证立马响应，所以网卡往往有缓冲区 用户读写文件的操作往往是猝发的（例如一个文本编辑器，用户随时按下按键输入字符），libc维护缓冲区，延迟写入外存，提高IO性能 操作系统为外设IO提供缓冲，因为外设产生数据是猝发的 在加入少量的酸或碱时，溶液的PH值发生突变（扩散作用很快），而缓冲液可以在这个情况下减小溶液PH值变化速度和范围（化学反应速度比扩散作用慢）。缓冲剂往往远多于酸或碱的量（使用滴管加入的）。如果酸或碱的量太多，缓冲液的效果就不好 ","date":"2024-06-25","objectID":"/posts/week2/:1:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#附加条件a猝发生产而b持续消费"},{"categories":null,"content":" 附件条件：A反复消费相同数据此时使用cache，即快取 许多包管理器都有cache的功能，因为用户往往重复下载相同的软件包 CPU有cache，因为程序往往在一段时间内重复访问一块区域的内存，具有时间局部性和空间局部性 浏览器会缓存部分文件，因为用户每次访问页面，都需要下载相同内容的文件 为了加快访问速度，网站可以把静态资源放到CDN ","date":"2024-06-25","objectID":"/posts/week2/:2:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#附件条件a反复消费相同数据"},{"categories":null,"content":"最近关于博客的内容考虑了很多，怎样让博客的内容更有价值、怎样输出内容等等。也考虑了未来如果内容做好了，可以开始做SEO等等。因为我认为博客还是一种比较轻松的阅读内容，如果选择输出干货，一来读者不一定了解这方面的知识，二来读者如果非常了解这方面的知识，这篇文章也没有价值；如果想加深对某领域的了解，完全可以看一些经典的书籍，他们的内容比博客好多了，于是我决定改变博客的内容。希望我的博客是启发性的，读者看完后能够对某个小领域有个大致的理解，或者看完后产生兴趣，去阅读更专业的书籍、文档等等。换而言之以后的文章相比深度更倾向广度，比起话题更像随谈。另外我能力也不足以输出深度足够的文章。 ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#"},{"categories":null,"content":" 外部归并排序最近打数据库比赛，我负责的一道题是归并连接 需要使用归并排序算法，准确的说是external merge sort，即在内存有限的情况下，利用外存辅助排序，其核心思想是一种经典的算法：分治法（分而治之，divide-and-conquer） 假设内存只能使用1G（大致范围，不考虑细枝末节），而需要排序10G的记录，归并排序的步骤是 将10G内存分十次读取到内存，在内存中完成1G记录的排序（可以使用常见的排序算法，例如快速排序），排序结果写入总共10个文件 将10个文件分别读取一块到内存（假设读取100M，总共使用1000M，没有超过1G限制） 从每块的第一个记录中选择最小的一个，取出，输出（每块中最小的记录肯定是第一个，因为块内已经排好序了） 重复3，如果某块使用完，就从对应文件读取下一块 10个文件的内容全部使用完毕，完成排序 算法不难理解，然而实现起来就会遇到各种各样的问题， 如果有10.1G的记录，按照上述办法，就会有一个0.1G的文件 如果一块大小是80M，该文件的最后一块就是64M 如果记录只有900M，算法也应该能正常处理，而且最好不使用外存（但在数据库场合下，前一个算子执行时输出多少记录是不可能预先知道的，例如select算子，可以携带where语句的条件，实际输出的记录数量只能确定范围而无法具体知道其数量） 文件应该保存在哪里（放在tmpfs就不满足要求了，因为tmpfs就是使用内存实现的） 文件IO怎么做（直接用read，write系统调用？使用带缓冲的libc？使用mmap？） 于是实现这样一个外部归并排序，从最开始的查找资料，理解算法，到选择实现路径，再到动手实现、抽象，重构，分离，加上各种错误处理，考虑各种corner case，已经非常复杂了 另外再考虑使用google test写测试，怎样才能写出一个好的测试，把问题都找出来（自己写测试找bug比写了一堆代码，提测时才发现问题快多了！） 再考虑借鉴一下现成的算法实现，有例如stxxl这样非常全面系统的大数据处理库，也有github上十几颗星星，一两个文件的实现，还有使用其他语言实现的，等等。怎样保证正确的同时控制复杂度，可以看出从理论到实践的差距非常大，实践的内容已经远超理论的内容了，而我理论的内容也只是了解了部分，只能说希望未来的我能轻松做到吧… ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#外部归并排序"},{"categories":null,"content":" object header所谓object header就是一个对象的头部，在许多高级语言中对象都有object header。从理论上也能推导出一定需要一个额外的区域保存一些信息，不一定叫做object header，也可以是object footer 面向对象的一个特点是多态，多态可以理解为子类对象能够完美的嵌入到需要父类的地方，而如何知道该调用父类方法还是子类方法，只能在运行时确定，所以OOP一定要把类型信息带入运行时，这也是OOP的一个overhead（开销） 然而cpp比较特殊，虽然它也是OOP语言，但cpp的大部分（？）对象都是没有object header的，可以做一个简单的实验验证一下 我的猜测是，cpp首先favour zero cost abstraction(青睐零开销抽象)，让每个对象仅仅因为OOP的需要就带上一个绝大多数场合下都不会使用的object header，是不可接受的 其次，cpp相比其他传统OOP语言，有很多不同的地方 cpp的对象和原始类型不存在鸿沟，反而是可以密切配合的，对象可以轻易取其地址，malloc和new的区别也仅仅是new相比malloc多做了类的构造函数，而传统OOP语言，对象和原始对象存在鸿沟，互操作时需要包装类，例如java需要使用繁琐的wrapper box，而JS会自动完成原始类型和对象的转换 cpp的对象和原始类型可以随意放在堆上或者栈上，而传统OOP则将对象放在堆上而原始类型放在栈上 cpp的多态必须使用指针，并且必须有虚拟类 结合以上原因，我猜测也许虚拟类的子类的对象会有类似object header的东西，否则从理论上推导，cpp就无法完成多态了 ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#object-header"},{"categories":null,"content":" runtime上文出现的两个运行时，分别使用了两个不同的含义。 含义一：程序的时态 程序的时态，可以包括开发时，编译时，链接时，装载时，运行时等等，这也是从字面意义上理解runtime 含义二：runtime system的缩写 runtime system提供了程序运行的环境。就算是汇编语言也需要相应的环境才能运行，C的运行时提供以下运行时支持 栈 在操作系统启动时就已经准备好了，因为操作系统主要是C编写的，也需要栈的环境 libc 包含C标准定义的函数，有与操作系统交互的函数，也有字符串处理函数 dynamic linker 动态链接器用于将多个目标文件中的代码段，数据段等链接起来，于是在运行时能够调用其他目标文件中的函数，linker完成了elf装载完成后bootstrap的过程，bootstrap先于__start函数的执行，而__start函数先于main函数的执行 多线程支持 例如线程私有变量，线程安全版本的函数，多线程环境下的exit 内存分配系统 C标准中提供的malloc系列函数，提供了内置的内存分配系统，用于管理堆区 IO缓冲 libc在操作系统IO操作原语基础上，提供了带缓冲的IO，例如fread,fwrite等等，并提供了三种缓冲选项（无缓冲，行缓冲，全缓冲），用于在大部分场合下，提高应用程序IO速度，并减小开发者心智负担 NOTE: 如果对以上内容感兴趣，参见《程序员的自我修养——链接、装载与库》 ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#runtime"},{"categories":null,"content":" exec的极限在给上文提及的external merge sort写测试的时候，我最开始使用了非常烂的参数，导致测试程序在一个目录下大量的创建了辅助排序用的文件，它们使用mkstemp创建，模板为aux_sort_fileXXXXXX，mkstemp会自动将末尾的X替换成随机的字母，并创建、打开该文件，这样就不必考虑为文件起一个不会重复的名字 为了删除这些文件，我最开始使用的命令是rm aux*，然而shell报错\"Too many arugments\" 然后我使用的命令是fd 'aux*' --exec rm {}，fd是find的加强版，这个命令相当于find . -name 'aux*' -exec rm {} \\; 那么\"Too many arugments\"是为什么呢？ Linux系统许多地方都是有限制的，例如hostname（主机名）长度不能超过某个值，路径长度不能超过某个值等等，这是因为动态长度的东西很难处理，内核实现中为了简单，往往会规定一个limit，并定义超过limit后的行为（一声不吭？报错？自动截断？） 决定\"Too many arugments\"的limit是ARG_MAX，即命令行的最长参数长度，因为rm aux*中的*是shell的wildcard（通配符）, shell将aux*替换成所有文件名开头为aux的文件，然后执行命令（内核不会特殊对待*，*是shell层面的feature），当文件特别多时（当时也许有几千或几万个文件），就有可能触发limit ARG_MAX起作用的范围是exec系统调用，libc提供的exec系列函数（包括execl,execlp,execle等等）只是exec系统调用的封装，ARG_MAX限制了exec能传入的参数的长度。而shell本质上只是exec系统调用的一个封装，自然也会受到ARG_MAX的限制（参考一些简易shell的实现，只涉及管道，fork，exec） linux是类unix系统，在unix发展历史上，因为过多vendor(厂商)分别开发和维护自己的unix系统，导致unix分裂，于是若干大头（IEEE，美国政府等）牵头指定了若干标准，有POSIX和Single Unix Specification，它们对以上提及的各种limit都有详细的定义，提倡unix系统提供的limit应该至少大于某个值，即标准规定的至少应该满足的值 此外，POSIX和Signle Unix Specification有若干版本，以及各自的扩展，例如XSI就是POSIX.1的扩展。unix是使用C开发的，C在历史上也有分裂的时期，于是人们也成立ISO/IEC制定了C的标准，这些标准是语言层面的，不会单独为Unix考虑，更多地考虑中立，但也影响了Unix，例如long应该有多长，INT最大值是多少等等 举一些例子说明ISO C, POSIX, Signle Unix Specification如何相互影响 ISO C定义了FILENAME_MAX，但随后POSIX定义了NAME_MAX和PATH_MAX作为FILENAME_MAX更好的替代 read系统调用原来的接口是 c int read(int fd, char* buf, unsigned nbytes); ISO C要求泛型数据应该使用void*，于是char* buf被改成了void* buf POSIX.1 引入了size_t表示数据的大小，于是unsigned bytes变成了size_t nbytes 此外POSIX.1还引入了ssize_t作为size_t的有符号版本，以支持负数，read的返回值类型也被改成ssize_t 最终的版本 c ssize_t read(int fd, void* buf, size_t nbytes); 为了使自己的程序能够在迁移到POSIX兼容机上，以上标准提供了一系列的机制以供开发POSIX兼容的程序 limit分为编译时limit，运行时limit，编译时limit是编译时常量，可以在编译时期通过引入诸如\u003climit.h\u003e获取，运行时limit可以由诸如配置文件，命令行，系统调用等方式动态的改变，需要在运行时动态获取 涉及的函数有sysconf, pathconf, fpathconf 不同系统对POSIX的支持程度不一样，POSIX提供一系列Feature test macros供开发者检测POSIX特性的支持，并对不同的支持情况作出反应（使用#ifdef条件编译），这种方法只能处理编译时limit ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#exec的极限"},{"categories":null,"content":" 标准与扩展Unix，C/C++，Web都是多家vendor，一个标准。vendor往往为了自己的利益，或者自己的需要，提供超过标准要求的功能，并推进这些功能加入标准 这一方面是因为标准往往为了中立而非常谨慎，甚至有时候可以说是不作为，导致标准提供的功能不足以覆盖部分需求，另一方面，编译器的vendor往往也是操作系统的vendor，例如Microsft的Windows和Visual c++，Apple的iOS,MacOS和clang，以及GNU与Linux。造操作系统是一个非常艰巨的任务，vendor往往也会造自己的编译器以满足开发操作系统的需求 举一个我打数据库比赛时遇到的情况，我希望对记录进行排序，记录为一块内存，大小在运行时获得，比较函数取出记录中的属性（基址+偏移，数据类型长度）然后比较属性大小，要使用哪个属性参与比较，也是运行时动态取得的 ，考虑cpp提供的std::sort，它的数据长度依赖于类型，而类型是编译常量，所以无法做到。考虑来自C的std::qsort，它的原型如下 c void qsort(void base, size_t nmemb, size_t size,int (*compar)(const void , const void )) 因为比较函数compar是函数指针，无法使用lambda函数捕获外部变量，也就是说每次sql执行时，compar函数行为都是一样的，这肯定不能满足需求，不能实现比较任意属性 我最终使用的是qsort_r c void qsort_r(void base, size_t nmemb, size_t size,int (*compar)(const void, const void , void *),void *arg); 这是glibc提供的C标准的GNU扩展，也就是说只有glibc才有，换而言之只能在linux使用（关于OS, libc以后有机会单独讲） 这个函数传入一个额外的void *arg，然后它将arg作为第三个参数传入compar，就能实现动态的比较属性 如何使用qsort_r？ 因为qsort_r是GNU扩展，man手册如是描述 Feature Test Macro Requirements for glibc (see feature_test_macros(7)): qsort_r(): _GNU_SOURCE 要使用qsort_r，首先要定义_GNU_SOURCE，然后引入声明了qsort_r的头文件\u003cstdlib.h\u003e 然后查看gcc预定义的宏 text ➜ bin git:(p6-merge-join) ✗ echo | g++ -dM -E -x c++ - | grep _GNU_SOURCE #define _GNU_SOURCE 1 可以看到我的gcc已经定义了，也就是默认启动了GNU扩展，所以直接引入\u003cstdlib.h\u003e即可，无需额外操作 然而其他版本的gcc也许没有预先定义，最优解法是在编译时通过命令行参数定义 以上例子可以看出标准往往是保守的，从Visual C++的各种_s版本函数可以也看出来这点 Visual C++的_s系列函数，例如scanf_s，strcpy_s,sprintf，是标准库对应函数的安全版本(security)，主要解决了buffer overflow问题，这些函数是visual c++的独占特性（或windows的独占特性），但是作为C标准的扩展进入了C标准，开发者可以在只引入标准库提供的头文件的情况下使用他们，在将别人的程序迁移至其他平台时造成了不少的麻烦！ NOTE: 如果对以上内容感兴趣，参见APUE(《Unix环境高级编程》) ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#标准与扩展"},{"categories":null,"content":"最近发现身边有些同学并不知道在我看来入门级别的浏览器小技巧，所以专门写一篇文章介绍和总结一下我使用的浏览器小技巧 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#"},{"categories":null,"content":" Ctrl+F 搜索Ctrl+F弹出的搜索框会自动聚焦，我的常用流程是 鼠标选中文本 Ctrl + C复制文本 Ctrl + F 唤起搜索框 Ctrl + V (不需要鼠标点击搜索框，因为自动focus) enter 下一项，shift + enter 前一项 这样的流程在第一次选中文本后就不再需要鼠标，非常快捷 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#ctrlf-搜索"},{"categories":null,"content":" 超链接点击检索信息时遇到的超链接往往希望在另一个tab页中打开，然而有些页面的超链接由于没有设置target=\"_blank\"，点击后会在当前tab页打开，导致无法同时查看两个页面 可以按住Ctrl然后点击超链接，不论超链接如何设置target属性，都会在新tab页中打开 相对的还有按住Shift然后点击超链接和按住Alt点击超链接，分别是在新窗口打开页面和下载页面 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#超链接点击"},{"categories":null,"content":" Tab页切换实际上绝大部分带tab的应用程序，都可以使用Ctrl+Tab切换tab页，而且长按和短按有不同的效果 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#tab页切换"},{"categories":null,"content":" 快速进入常用网站chrome的搜索栏会记忆访问的网站，在地址栏输入链接的部分，可以补全，相当于缩写网站链接，非常实用的功能 例如最近打数据库比赛，输入仓库名的开头三个字符就能快速访问仓库 这个功能也能在收藏的网站中搜索，例如收藏了xv6实验的网站后就能快速补全 搜索bookmark是根据收藏时给bookmark起的名字搜索的，默认的bookmark名是网站的标题，所以中文也能搜索 因为地址栏的补全实在太强大， 需要有意识的维护常用缩写，包括 常用网站主动使用缩写，增加缩写使用频率 不常用的网站不使用缩写，不在地址栏输入google search的关键词 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#快速进入常用网站"},{"categories":null,"content":" 快速导航至浏览器功能Ctrl + H(History)打开历史页面，可以快速找到之前关闭的页面 Ctrl + Shit + N打开无痕模式，因为无痕模式相当于使用另一个Profile，不会使用已经有的cookie，而且浏览器扩展默认设置为禁止在无痕模式下工作，可以满足以下需求 不想被网站跟踪 查看未登录时网页的情况 一个站点登录两个帐号 快速临时禁用浏览器扩展，排除扩展引起的问题 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#快速导航至浏览器功能"},{"categories":null,"content":" 缩放网页字体太小，或者留白太多时，可以使用缩进增强视觉体验 快捷键Ctrl + 滚轮 大部分网站都能在应用110%或125%的缩放时仍然保持良好观感，同时由于增加了字体大小，可以有效避免字体和按钮边缘毛刺、割裂的情况 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#缩放"},{"categories":null,"content":" 地址栏显示的内容很重要","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#地址栏显示的内容很重要"},{"categories":null,"content":" 反映资源id地址栏显示的当前url，可以反映出资源id 例如github的仓库名由两个部分组成，分别是用户名和仓库名，分别唯一标识了不同的实体 又例如bilibili的视频链接格式/video/BVxxxxx，说明了视频由BV号唯一标识 有些资源id不会直接显示给用户，但有可能出现在url中 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:1:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#反映资源id"},{"categories":null,"content":" 文章段落定位url末尾可以接上诸如#abce这样的部分，它被称为hash，HTTP协议会忽略#之后的所有内容，但这样的内容可以被浏览器用于打开页面后滚动至对应的段落，原理是#后接的是页面元素的id，然后浏览器在页面中找到具有这个id值的页面元素，然后滚动使其进入视口并位于顶部 在大部分具有传统的文章概念的页面中，鼠标悬停标题可以看到一个小图标，点击这个小图标就能定位到这个元素，此时地址栏显示的url的末尾也出现了hash 例如github 又例如python包常用的文档托管网站readthedocs.io 知道了段落定位的原理后，可以自己根据页面元素id生成带hash的url，不仅仅可以在不支持段落定位的网站使用，还可以定位段落以外的页面元素 为什么说文章段落这个词汇，是因为web页面虽然已经非常复杂多彩，但仍然保留着Document这样的概念，从HTML语义化标签和HTML元素的布局模式也可以看出这一点。\u003carticle\u003e，\u003cheader\u003e,\u003caside\u003e等语义化标签强化Document和视觉中心的存在；默认布局模式下元素从左向右排列，如果横向空间不够就换行，详情请参见《CSS: The Definitive Guide: Web Layout and Presentation》（CSS权威指南第五版） ","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#文章段落定位"},{"categories":null,"content":" 避免被追踪众所周知在京东淘宝并夕夕这样的网站点击复制分享链接后，复制的链接特别长，后面有一堆?a=b\u0026c=d等参数，事实上这些参数都是url parameters，删掉他们也能正常打开页面，不删掉他们反而会被跟踪，当分享给朋友，朋友再点开链接时，服务提供方可以认为你跟这个朋友有相似的爱好，这样的信息可以用于基于协同过滤的推荐系统实现，原理可以参考推荐系统简单介绍这篇文章 此外，链接很短也不代表是安全的，因为可能是使用了短链，短链可以30x重定向或者由JS操作window.location跳转到一个很长的链接 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:3:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#避免被追踪"},{"categories":null,"content":" 前往任何页面！用户在页面中导航有两种方式，一个是手动输入url，另一个是通过与页面的超链接、按钮等元素，在网站的引导下前往页面，这种引导可以是内容服务提供方简化用户导航过程，帮助其快速找到想要的内容，也可以是充满了内容服务提供方利益诉求的“诱导” 以著名的深度学习平台anaconda为例 用户为了使用anaconda而打开它的官网时，被一个显著的 Sign in 按钮吸引，而旁边就是 Free Download 然后来到下载页面，页面显示提供邮箱，除此之外并没有找到其他跟下载有关的按钮或者超链接 在输入了自己的邮箱地址后，anaconda公司会将真正的下载地址发送到邮箱中 然而只需要仔细观察，就能发现刚刚引导用户登录的页面是https://www.anaconda.com/download，而邮箱中的链接是https://www.anaconda.com/download/success 由于刚刚的流程并没有注册和登录，所以anaconda网站无法知道访问者是谁，这样的链接很难让人不怀疑是不是没有登录墙保护，Ctrl+Shift+N进入无痕模式，尝试直接输入/download/success访问，居然也能成功 可见这样的页面组织只是为了收集使用者信息，方便anaconda公司宣传产品，所以刻意阻止用户直接下载anaconda而离开页面 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:4:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#前往任何页面"},{"categories":null,"content":" 根据域名快速判断内容可信度当使用搜索引擎进行信息检索时，需要在搜索引擎提供的一系列结果中筛选。除了网页标题，域名也是判断内容可信度的一个非常重要的依据 点名批评百度，不仅仅广告排第一位而且不显示域名，极力误导小白用户，破坏简中互联网 例如一个小白用户下载steam的流程：打开百度搜索steam 然而点击第一个超链接 而如果能提前知道这个网站域名是game.pengchengxinxi.cn，就能快速判断出不是steam ","date":"2024-06-07","objectID":"/posts/browser_tricks/:5:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#根据域名快速判断内容可信度"},{"categories":null,"content":" 进阶使用浏览器不使用dev tool一定是不完整的，dev tool功能非常强大，由浏览器厂商开发，是消费者与商业公司制衡的一个非常有利的工具。它也让前端毫无秘密。任何在前端限制用户使用的页面都在dev tool下暴露原型，其公司的姿态可见一斑 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#进阶使用"},{"categories":null,"content":" 长截图长截图从技术原理上来说比截图复杂得多，甚至有些从原理上是无法长截图的，比如自绘UI，而只能从某些角度近似的实现长截图的功能 浏览器也是非常经典的自绘UI，而它提供了一个很方便的长截图功能 首先打开dev tool，找到相应元素，右键捕获截图即可 寻找元素的技巧如下 语义化标签，例如github的仓库主页，有main标签可以快速定位 需要长截图是因为一个元素的高度大于视口高度，找到这样的元素即可 不断寻找父元素直到其内容覆盖整个屏幕 某些页面布局很难甚至无法找到这样的元素 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:1:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#长截图"},{"categories":null,"content":" 我就要复制！","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#我就要复制"},{"categories":null,"content":" 解法1: 打开dev tools复制简单的场合下，仅仅是监听事件然后阻止了复制事件的默认行为，在dev tools中复制即可，因为JS无法控制dev tools ","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:1","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#解法1-打开dev-tools复制"},{"categories":null,"content":" 解法2: 禁用JS前文提及阻止复制是JS实现的，所以只要打开dev tools禁止页面加载JS脚本，然后刷新页面即可 在不考虑各种浏览器扩展，油猴脚本的情况下，可以简单的使用JS的DOM接口实现 原理是找到包含文本的HTML元素，访问其innerText属性即可这个元素渲染出的的文本 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:2","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#解法2-禁用js"},{"categories":null,"content":" 解法3: innerText 由于这样的元素中的文本被HTML标签分隔，需要依次选中每段文本然后复制，非常麻烦 可以使用HTML元素的innerText属性，它表示该元素内渲染的文本 要访问innerText属性，必须先获得这个元素的引用，将其保存在JS的变量中，此处不需要使用xpath或CSS selector等选择器，直接使用dev tool提供的快捷功能获取其引用 dev tools将这个元素绑定到temp1变量上，然后访问其innerText属性即可 此处获取到的文本是转义过的，而我们明显不想复制\\n，使用console.log打印出来即可 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:3","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#解法3-innertext"},{"categories":null,"content":" 清除cookie众所周知bing的中国特供版有些功能并没有，而大陆用户能访问的“国内版”和“国际版”，实际上都是中国特供版，而不是真正的国际版。 绕过区域限制中的一个步骤就是清除cookie，即使没有登录，网站也可以设置cookie用于追踪用户。只要第一次在大陆网络环境访问bing，被设置了相应cookie，即使下次通过国际网络访问，也会因为之前设置的cookie而被认为是大陆用户 解决方案就是打开dev tool，依次点击Application - Cookies - https://xxx.com，逐个删除cookie即可 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:3:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#清除cookie"},{"categories":null,"content":"这篇文章讨论了哈希函数的安全问题和python的哈希实现 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:0:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#"},{"categories":null,"content":" Hash DOS所谓Hash DOS即利用hash碰撞增加服务器负担、使其无法响应正常用户的请求的情况，以下说明为什么可以利用哈希碰撞发起DOS攻击 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:0:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#hash-dos"},{"categories":null,"content":" 哈希碰撞不可避免哈希是一种摘要算法而非加密算法，它将任意长度的比特序列映射成一个固定长度的比特序列，根据抽屉原理/鸽笼原理：“n+1个苹果放到n个抽屉中，至少有一个抽屉里放了两个及两个以上的苹果”，哈希函数将具有无穷种情况的任意长度比特序列映射到有穷种情况的固定长度比特序列，所以必定存在一些比特序列，他们经过哈希运算后得到的值相等，即哈希碰撞 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:1:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#哈希碰撞不可避免"},{"categories":null,"content":" 哈希碰撞容易发生假设哈希表中有365个桶，那么往其中插入23个随机的数据，发生哈希碰撞的概率有多少? 实际上，概率高达50% ！将随机数据换成每个人的生日，这就是生日悖论 这说明，哈希碰撞发生的概率远超我们的预期 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:2:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#哈希碰撞容易发生"},{"categories":null,"content":" hash DOS的原理以上说明了哈希碰撞容易发生，但这并不能解释为什么哈希碰撞能用于发起DOS攻击 哈希表在理想状况下，插入、查找、删除都是在常数时间内完成（时间复杂度O(1)），在最坏的情况下，时间复杂度是O(n)。大部分时候我们都认为哈希表的时间复杂度就是O(1)， 因此将哈希表用于系统关键处用于提高性能，然而由于哈希碰撞的不可预测性，哈希表的时间复杂度实际上是在O(1) ~ O(n)中摇摆，这就为系统关键处带来了不确定性。 设想现在系统关键处的哈希表由于发生了大量哈希碰撞，性能急剧下降，那么整个系统的性能也会急剧下降 假设有一个服务器维护一个哈希表，键是用户名字符串，值是用户的各种信息组成的对象，这个哈希表有一百万个桶，攻击者如果想要通过蛮力使哈希表性能恶化，鉴于一百万的量级，可能需要发起非常多操作才能达到预期。然而假设攻击者知道了服务器使用的哈希函数，例如服务器使用了一个不安全的哈希函数 c long hash(char* username){ long hash = 0; for (int i = 0; username[i] != '\\0'; i++) { hash += username[i]; } return hash; } 这样的哈希函数可以轻松构造出哈希值相同的不同字符串，例如\"zhansan\"和\"zhansbl\"。于是攻击者精心构造了一千个这样的字符串然后发起了一百次操作，每次操作服务器就会遇到这一千个发生碰撞的键值对，逐个比较时间复杂度为O(n)，n为碰撞规模，精心构造的字符串极大地放大了每次操作的效果 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:3:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#hash-dos的原理"},{"categories":null,"content":"rime是一个开源、高度可定制、多平台支持的输入法框架，然而在配置fctix5-rime的配色方案时我又踩了坑，记录一下解决方案 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#"},{"categories":null,"content":" fctix5不支持rime配色网上许多rime教程都是用的鼠须管或者小狼毫，分别是rime的macOS和windows发行版，中州韵很少遇到，此外即使遇到了中州韵，往往也是用的ibus， 然而在2024年的今天，fctix5明显是一个更优的选择 fctix5和ibus的一个不同点就是，配色方案不是rime的，而是fctix5的，另外在fctix5是主题（theme）而不是rime的配色方案（color style），所以网上抄的各种配色方案都不会生效，例如我抄了一个仿微信输入法的配色方案，然后试了无数次都无法生效！ ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#fctix5不支持rime配色"},{"categories":null,"content":" 正确的做法首先参考arch wiki，在github我找到了一个看起来不错的仿macOS的主题 使用步骤见此仓库的README，将主题文件复制到~/.local/share/fcitx5/themes下即可 然后打开KDE的system setting KDE会自动识别~/.local/share/fcitx5/themes下的所有主题文件，并显示在多选框中 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#正确的做法"},{"categories":null,"content":" 主题微调使用前文提及的仿macOS主题时又遇到一个问题，候选词间距太大了，然而只要查看过~/.local/share/fcitx5/themes的主题文件，能够很清楚的知道主题是怎么指定的。 不同主题在以其名字命名的目录下，这个目录下有一个文件theme.conf，它是ini格式的配置文件，可读性较好，而且我找到的主题还贴心的给每个配置加上了中文注释。于是 我修改了一下内容 ini [InputPanel/Background/Margin] # 左侧边距 Left=10 # 右侧边距 Right=10 # 顶部边距 Top=8 # 底部边距 Bottom=8 [InputPanel/Highlight] # 背景图片 Image=highlight.svg [InputPanel/Highlight/Margin] # 高亮区域左边距 Left=10 # 高亮区域右边距 Right=10 # 高亮区域上边距 Top=8 # 高亮区域下边距 Bottom=8 [InputPanel/TextMargin] # 候选字对左边距 Left=10 # 候选字对右边距 Right=10 # 候选字向上边距 Top=8 # 候选字向下边距 Bottom=8 就达到了我想要的效果 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#主题微调"},{"categories":null,"content":" 效果展示 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#效果展示"},{"categories":null,"content":" Tipsrime的配置逻辑是，用户修改xxx.custom.yaml文件用于覆盖或重写rime的默认配置文件xxx.yaml，所以当不确定xxx.custom.yaml中的xxx是什么时，可以查看 /usr/share/rime-data/有哪些文件，假设有一个文件名字为abc.yaml，那么能够覆盖它的文件名为abc.custom.yaml rime的windows发行版名字为小狼毫，对应的配置文件为squirrel.yaml，macOS发行版为鼠须管，对应配置文件为weasel.yaml，linux发行版名字为中州韵,然而比较坑的是，我并没有发现中州韵对应的配置文件名，相反，在我的fcitx5-rime上对应的配置文件为fcitx5.yaml 我的fcitx5-rime在用户配置错误时，不会报错，而是直接完全使用rime的默认配置，使人不知所措，此外官网上提及的日志文件/tmp/xxx，我并没有找到 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#tips"},{"categories":null,"content":" 我的rime配置使用了很长时间，自认为还是比较好用，不过在中文模式下输入中文标点符号这点还是比较不方便 default.custom.yaml yaml patch: \"switcher/option_list_separator\": '|~ \"switcher/caption\": \"[方案列表]\" \"switcher/hotkeys\": - Control+grave \"switcher/save_options\": \"schema_list\": - schema: double_pinyin_flypy # - schema: luna_pinyin \"key_binder/bindings\": - {when: always, accept: Control+space, toggle: ascii_mode} - {when: has_menu, accept: minus, send: Page_Up} - {when: has_menu, accept: equal, send: Page_Down} 主要配置了唯一一个输入法即小鹤双拼（朋友评价为防止别人用我电脑…），ctrl+空格 切换中英文（不知道为什么还是能通过shift切换中英文）， 加减号翻页 double_pinyin_flypy.custom.yaml yaml patch: schema/name: 小鹤双拼 switches: - name: ascii_mode reset: 1 states: [中文, 西文] - name: full_shape reset: 0 states: [半角, 全角] - name: simplification reset: 1 states: [繁体, 简体] - name: ascii_punct reset: 0 states: [ \".,\", \"。，\" ] engine/processors: - ascii_composer # - recognizer - key_binder - speller - punctuator - selector - navigator - express_editor 配置了默认使用英文输入法，半角简体，这里配置非常简单，主要目地是覆盖默认的大量配置 可以看出即使rime被称为最强输入法，但我几乎没有定制它的功能… ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#我的rime配置"},{"categories":null,"content":"这是APUE（Advanced Programming in the UNIX Environment，UINX环境高级编程）阅读笔记系列文章 首先参考一个简单的类UINX操作系统实现——xv6，了解操作系统是如何组织文件资源的 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#"},{"categories":null,"content":" xv6的File IO实现","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#xv6的file-io实现"},{"categories":null,"content":" File是操作系统管理的底层资源在xv6中，file结构体是对管道，inode（表示常规文件），设备的抽象。xv6没有内核内存分配器，只是静态分配了一个固定大小的file数组，用于存放内核打开的所有file ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#file是操作系统管理的底层资源"},{"categories":null,"content":" file descriptor是File的引用file descriptor(简称fd)在xv6中，是通过PCB（进程控制块）中的一个固定大小的数组存储的，这表明了两点： fd是process local的，表示进程对内核资源的引用 一个进程能够打开的文件是有最大数量限制的 fd和windows的handler很相似，它是为了避免直接使用指针引用内核数据，优点如下 避免内核数据结构暴露在进程中 如果直接将file结构体的指针交给进程使用，进程就能知道file的内存地址，虽然进程一般无法读写这块地址，但不代表这是足够安全的 防止恶意进程提供错误指针误导内核 假设进程提供的指针是非法指针，并不指向file结构体，这种情况在xv6中能够通过判断指针是否在数组中越界来确定 然而，如果进程提供的指针指向其他进程打开的文件，就有机会滥用其他进程的资源 换而言之，指针是全局的，而fd是process local的 向进程屏蔽file结构体的实现细节 众所周知随着内核版本的迭代，内核使用的某些数据结构会发生改变，例如添加新功能，需要在原有的结构体上添加新的字段 这样的细节对进程是无用的，还会导致编译后的二进制依赖于某个特定版本的内核实现 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:2:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#file-descriptor是file的引用"},{"categories":null,"content":" stdin, stdout, stderror只是约定通常一个程序开始运行时，已经有三个文件打开了：0，1，2，分别表示stdin, stdout, stderror 在xv6的实现中，内核并没有对0,1,2特殊处理，因为它只是shell的约定。xv6在用户态下提供了一个shell程序，片段如下 c if(open(\"console\", O_RDWR) \u003c 0){ mknod(\"console\", CONSOLE, 0); open(\"console\", O_RDWR); } dup(0); // stdout dup(0); // stderr 可以看出shell打开了终端设备文件，并通过dup使得0，1，2指向同一个终端设备文件。而在shell中运行的程序fork自shell程序，所以继承了shell程序的0，1，2文件描述符 换而言之，一个程序运行时，0，1，2不一定是已经打开的文件！！！ ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#stdin-stdout-stderror只是约定"},{"categories":null,"content":" 文件打开，关闭","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#文件打开关闭"},{"categories":null,"content":" openopen函数打开一个文件，返回fd c int open (const char *__file, int __oflag, ...) 参数名 说明 __file 文件路径 __oflag 打开方式，通过比特掩码传递flags mode 只有在创建文件时才会使用，用于设置创建的文件的权限，类型为mode_t 返回 文件描述符，-1表示打开失败，并设置erron，其他情况返回文件描述符 返回的fd总是未使用的fd中最小的一个，利用这个特性可以重定向标准输入，标准输出，标准错误 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#open"},{"categories":null,"content":" oflag常用oflag 宏 说明 O_RDONLY 只读 O_WRONLY 只写 O_RDWD 可读可写 O_EXEC 执行 O_APPNED 写入内容附加到末尾 O_CLOEXEC 执行exec系列函数时自动关闭，防止子进程继承到父进程的该文件 O_CREATE 如果文件不存在，自动创建 O_EXCL 和O_CREATE配合使用，如果文件存在，则返回错误 O_TRUNC 如果文件能够以可读方式打开，则将文件大小设置为0 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:1","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#oflag"},{"categories":null,"content":" close c int close (int __fd) 进程结束时，操作系统会自动关闭进程打开的文件，所以在一些场合下，可以不调用close关闭文件 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:2:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#close"},{"categories":null,"content":" creat vs open考虑creat函数 c int creat (const char *__file, mode_t __mode) 相比open，只能创建文件 打开文件时，如果需要自动创建文件，有两种方式 使用open带O_CREATE 使用open带O_CREATE|O_EXCL判断文件是否存在，如果不存在则使用creat创建。之后再打开文件 这两种方式的不同在于，在并发环境下，先判断一个条件是否成立再执行某个操作，这样的流程是线程不安全的，有可能在判断条件成立后，内核剥夺CPU，重新被调度时条件已经不成立。 使用open带O_CREATE，判断文件是否存在和创建文件两个步骤是原子操作，保证不会出现竞态条件 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#creat-vs-open"},{"categories":null,"content":" 文件操作xv6实现中，file字段有一个属性，用于记录文件偏移 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#文件操作"},{"categories":null,"content":" read c ssize_t read (int __fd, void *__buf, size_t __nbytes) 参数 说明 fd 必须是可读的文件描述符，可以是常规文件，终端设备，网络套接字等 __buf 进程准备的缓冲数组，内核会将读取到的文件内容存放到这里 __nbytes 进程期望一次最多读取的字节数量 返回 实际读取的字节数，-1表示遇到错误，0表示遇到EOF 如果实际读取的字节数小于__nbytes,表明发生了如下情况 如果读取常规文件，则表示读取__nbytes个字节时遇到了EOF 如果从终端设备中读取，通常一次读取一行，返回这一行的字节数 如果从网络套接字中读取，网络缓冲可能导致小于__nbytes个字节读取 如果从管道中读取，而管道中剩余字节数小于__nbytes etc… 读取后，文件偏移向前移动实际读取的字节数 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#read"},{"categories":null,"content":" write c ssize_t write (int __fd, const void *__buf, size_t __n) 参数 说明 fd 同read __buf 进程准备的缓冲数组，内核会读取这个缓冲数组中的字节并写入文件 __nbytes 进程期望一次最多写入的字节数量 返回 大部分情况下等于__nbytes 如果返回值不等于__nbytes，表明错误发生，可能是磁盘已满，或者用户磁盘使用超过配额 读取后，文件偏移向前移动实际写入的字节数 为了提高IO性能，内核不会立刻将数据写入磁盘，而是先写入内存中的IO缓冲区，随后（保证一定时间内）写入磁盘 如果打开文件时使用了O_SYNC，会阻塞直到数据落盘 如果打开文件时使用了O_APPEND，会先将文件偏移移动到文件末尾，再写入 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:2:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#write"},{"categories":null,"content":" lseeklseek函数用于修改文件偏移 c __off_t lseek (int __fd, __off_t __offset, int __whence) 参数 说明 __fd 文件描述符 __offset 新的文件偏移 __whence 宏，表示相对位置 返回 lseek调用后的文件偏移 __whence使用的宏 SEEK_SET，相对文件开头寻址 SEEK_CUR，相对当前位置寻址 SEEK_END，相对文件末尾寻址 lseek中的l表示long integer，在引入__off_t前，lseek返回类型是long off_t是有符号数，在极特殊情况下可能是负数，而返回-1又代表错误，所以应该使用==-1判断是否出现错误而不是\u003c0 不是所有类型的文件都能使用lseek，对管道，套接字，FIFO使用lseek会返回-1表示错误 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#lseek"},{"categories":null,"content":" lseek常见用法 判断文件是否可寻址 c if (lseek(fd, 0 ,SEEK_CUR) != -1) { // ... } 获取当前文件偏移 c off_t pos = lseek(fd, 0 ,SEEK_CUR); 获取文件大小 c off_t size = lseek(fd, 0 ,SEEK_END); lseek只修改文件偏移，不会产生IO操作，可以使用lseek获取大文件的大小 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:1","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#lseek常见用法"},{"categories":null,"content":" 文件打洞lseek允许将文件偏移设置到EOF之后，随后调用write，就能在文件中间打一个洞 文件打洞后，空洞范围内使用read读取到的值是0（'\\0'），空洞不会增加文件大小，部分文件系统不会存储空洞中重复的数据 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:2","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#文件打洞"},{"categories":null,"content":" dup系列函数dup系列函数用于实现file对象的共享，也就是两个fd指向同一个资源，因此，也会共享file对象的属性，比如file标志位，文件偏移等等 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:4:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dup系列函数"},{"categories":null,"content":" dup c int dup (int __fd) 参数 说明 __fd 文件描述符 返回 一个新的文件描述符，和__fd指向相同的资源 dup返回的fd总是未使用的fd中最小的一个 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:4:1","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dup"},{"categories":null,"content":" dup2 c int dup2 (int __fd, int __fd2) 参数 说明 __fd 文件描述符 __fd2 期望dup文件描述符的位置 如果__fd2是已经打开的文件描述符，则自动关闭，然后再执行dup操作 如果__fd == __fd2，则直接返回__fd 如果__fd2未使用，则dup2执行完毕后，__fd2的FD_CLOEXEC标志位被清除，方便与fork配合实现管道通信 dup2 vs close-open重定向标准输入，也就是在0处打开其他文件，有两种做法 1. c close(0); open(\"path/to/file\", O_RDONLY); c int fd = open(\"path/to/file\", O_RDONLY); dup2(fd, 0); 区别是，使用dup2可以明显地表达意图，可读性更好 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:4:2","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dup2"},{"categories":null,"content":" dup2 c int dup2 (int __fd, int __fd2) 参数 说明 __fd 文件描述符 __fd2 期望dup文件描述符的位置 如果__fd2是已经打开的文件描述符，则自动关闭，然后再执行dup操作 如果__fd == __fd2，则直接返回__fd 如果__fd2未使用，则dup2执行完毕后，__fd2的FD_CLOEXEC标志位被清除，方便与fork配合实现管道通信 dup2 vs close-open重定向标准输入，也就是在0处打开其他文件，有两种做法 1. c close(0); open(\"path/to/file\", O_RDONLY); c int fd = open(\"path/to/file\", O_RDONLY); dup2(fd, 0); 区别是，使用dup2可以明显地表达意图，可读性更好 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:4:2","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dup2-vs-close-open"},{"categories":null,"content":" sync系列函数","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:5:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#sync系列函数"},{"categories":null,"content":" fcntl函数","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:6:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#fcntl函数"},{"categories":null,"content":" ioctl函数","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:7:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#ioctl函数"},{"categories":null,"content":" /dev下的文件","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dev下的文件"},{"categories":null,"content":" /dev/fd/*","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#devfd"},{"categories":null,"content":" /dev/std**系列文件","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:2:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#devstd系列文件"},{"categories":null,"content":"许多新语言(2000之后发明的语言)大多有一个偏好：类型后置 rust: rust let x : i32 = 1; go: go var a []string kotlin: kotlin var language : String = \"French\" TypeScript: TS let x : number = 1; 在我看来，有以下几个原因 ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:0:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#"},{"categories":null,"content":" 动态类型不可取说到动态类型不得不提JS和python，从它们的发展过程来看动态类型存在很多问题 ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:0:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#动态类型不可取"},{"categories":null,"content":" JSECMAscript规定它是动态类型，弱类型的语言，使得JS非常灵活，但也带来很多问题。不提ES2015之前的JS，JS写下一个变量不知道它的类型，它的类型可以在运行时随意改变，甚至ECMAscript规定JS可以自动转型，例如 JS 1 + \"1\" JS发现类型不匹配后，会自动将1转型以执行+运算符 html \u003cdiv id=\"myoutput1\"\u003e\u003c/div\u003e \u003cdiv id=\"myoutput2\"\u003e\u003c/div\u003e \u003cscript\u003e(()=\u003e{ document.querySelector(\"#myoutput1\").innerText = 1 + \"1\" document.querySelector(\"#myoutput2\").innerText = 1 - \"1\" })(); \u003c/script\u003e 在线HTML执行后输出为 text 11 0 这样灵活的JS为前端工程化带来了很大的麻烦，于是microsoft提出了Typescript，实现了静态类型约束。不过TS也带来了一些新的问题，比如经常被调侃为做‘类型体操’ ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:1:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#js"},{"categories":null,"content":" pythonpython和JS的定位都是脚本语言，自然也是动态类型的语言，不过相比JS，python是强类型的，不会自动转型。不过pyton同样因为过于灵活，开发大型项目时力不从心。大型项目更需要的是严谨刻板，茴香豆的茴即使有四种写法，也会规定只能使用一种。 从python3.5开始，逐渐引入了type hint。有了type hint，不仅language server能从其中受益，开发者也能使用像pyright, mypy这类静态类检查器来检查代码中潜在的错误，不过python引入type hint是渐进的，目前（python3.12）type hint虽然支持了许多功能，但仍然有很多第三方库没有提供type hint或者没有提供完整的type hint，此外python的静态类型检查器也并不完善，有些时候还是只增加许多琐碎的代码来通过静态类型检查，或者在某处禁用静态类型检查 ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:2:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#python"},{"categories":null,"content":" 静态类型的痛从JS和python的发展历程可以看出动态类型的问题很严重，虽然天生泛型，但是一门面向工业面向生产的语言，必须选择静态类型，不过静态类型也有一些问题 语言更繁琐 需要实现泛型 从JS和python所处的年代，那时选择动态类型是很合理的，被C++折磨太多，突然抛弃类型就会非常轻松。 对于静态类型带来的疼痛，新语言往往使用了对应的’止痛药‘：省略类型 所谓类型推导，也就是编译器提供了强大的类型推导能力，能够在很多时候省略掉类型声明，减少静态类型带来的疼痛，例如rust在大部分时候都不需要声明类型，编译器会自动根据右值推导，例如根据数值范围推导是i32还是i64，根据函数返回类型推导， 甚至还能根据return语句自动推导函数返回类型。这反映出编译技术的不断进步，给开发者带来了不少便利，开发者再也不需要像以前使用C/C++时到处写类型了 于是类型在大部分时候可以省略，一个变量的声明中类型成了可选，如果不写类型，怎么知道这个语句到底是声明还是赋值呢？ 有两种方案 类型前置，使用auto，var等在省略类型时占位 C++11后可以使用auto让编译器推导类型，java也可以使用var省略类型 另外，同样是新语言的dart采用了var 类型后置，使用let，var等标志变量声明 TS，rust，kotlin都采用这种方式省略类型 那么为什么选择类型后置呢，大概是为了整齐，众所周知C++有这种风格 C++ int a = 1; std::string s = \"xxxx\"; 这是为了避免类型名称长度不一致，长短交错，增加阅读难度 如果使用类型后置 rust let url :String = \"https://google.com\"; let res :Response = reqwest::get(url).await?; let body :String = res.text().await?; // 以上类型都可以省略 更加整齐 此外还有一个因素，如果使用IDE的virtual text功能，可以在let url = \"https://google.com\"的url | =光标所在的位置增加一个虚拟文本，标注出类型，就能避免大量省略类型造成类型不清晰 ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:0:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#静态类型的痛"},{"categories":null,"content":"所谓空安全，也就是null safety，它是部分现代语言具有的新特性，如dart和kotlin，既然它是现代语言才具备的特性，说明之前的语言往往没有，例如java ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#"},{"categories":null,"content":" java的空值不安全众所周知，java只有原始类型和引用类型，而所有引用类型都是Object类的子类或Object类它自己，而java的空值不安全，也就出现在引用类型上。 java的引用类型本质上就是指针，而作为深受C++影响的语言，它的引用类型也继承了C++的指针的问题——空指针问题 在java中定义的任何一个类，都是Obecjt的子类，任何一个类的对象，都可以为空，也就是为null，也就是说，引用类型包含了null! 所谓‘包含’，这又涉及一个概念，可以把一个类型看作一个集合，而这个类型的任何一个值看作这个集合中的一个元素，例如： int类型表示集合 $\\Set{ x | x \\in Z \\land -2^{31} \\le x \\le 2^{31} - 1 } $ ，即所有int值的集合 float类型表示的集合比较复杂，首先float是离散的，能表示的值范围有限而且精度有限，而且不是等间距的，还包括了IEEE定义的inf，-inf，以及NaN Object类型表示的集合更复杂，但可以任何是程序运行过程中可能创建的所有Obejct对象以及它的子类的对象 而null值可以作为任意引用类型的对象的值，这在数学上造成了一个漏洞，造成了以下问题 null值属于什么类型？ 因为null可以作为任意引用类型的对象的值，所以null是任何引用类型的一个实例或它的子类的实例，但很明显这样的值是不能存在的 在类中定义的方法和属性，在类的实例（对象）上不一定可用 java的Object对象有一个方法toString()，然而你不能在null上调用这种方法，否则会抛出异常，严格来说，在使用toString()前应该先判断这个对象是否为null 这样的漏洞都可以使用引用类型来解释，因为引用类型的所有值都代表对某个对象的引用，所以这个值可以为空，表示没有引用任何对象 ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#java的空值不安全"},{"categories":null,"content":" C++的空值安全？C++的空值安全比较复杂，分为指针和引用两种类型 指针很明显空值不安全，java的空值不安全本质上还是指针的空值不安全 引用最大的优点就是，不存在空引用，也就是说，它缓解了C++的空指针问题，在合适的场合使用引用代替指针，可以减少空指针出现的情况 ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#c的空值安全"},{"categories":null,"content":" python的空值安全python相比java和JS，有一个很明显的特点：一切皆对象，也就是说，python中的所有值都是对象，也就是object类的实例，自然None也是object的实例 然而，None是NoneType类的直接对象，也就是说，任何NoneType类以外的对象，都不可能为None，这么看来，python的空值设计比较合理 graph TD object --\u003e NoneType --唯一实例--\u003e None object --\u003e str object --\u003e int object --\u003e ... 但问题在于，python是动态类型语言，也就是说变量运行时类型可以随意改变，在使用type hint之前，python并不能从空值安全的设计中受益 如果使用type hint，并引入严格的静态类型检查，python就是空值安全的。 假设你需要使用一个字符串变量，并且它可能为None，就应该写成 python x : str | None = \"....\" 如果你需要使用字符串的strip方法： python x.strip() 这样的写法并不会通过诸如mypy这样的静态类型检查器，需要使用’type guard’保证x的类型为str而不是str | None python assert x is not None x.strip() # 或 assert isinstance(x, str) x.strip() # 或 if isinstance(x, str): x.strip() 假设你需要使用一个字符串，而且它不可能为空，应该写成 python x : str = \"....\" 尝试给它赋值None，可以运行但是无法通过静态类型检查 python x : str = None # mypy报错 # 或 x : str = \"....\" x = None # mypy报错 ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#python的空值安全"},{"categories":null,"content":" dart的类型安全dart3.0引入了一个新特性：空值安全 dart也是一切皆对象，而dart只有两类类型，一个是Null类，一个是Object类。从语言的底层设计就能看出dart对空值的态度 如果一个变量不能为空 dart String x = \"....\" // 不能为空的变量必须在声明时赋初值，如果是类的属性，则必须在构造函数中赋值 如果可能为空 dart String? x; // 可空的变量，默认初值为null String?不是任何传统的类型，而是两种类型的组合，类似python的str | None，如果使用前文提及的集合的观点，这种类型属于String类型和Null类型的集合并集，只不过dart并没有提供使用class关键字定义这个类的语法能力 此外dart是静态类型的语言，还拥有强大的类型推断能力(type inference)，又提供了null相关的语法糖，能够避免写下很多琐碎的类型断言（例如python的assert x is not None） null相关语法糖使用了 !和?，并和dart其他特性配合，组合出非常多的使用方式，例如在级联操作符中使用，在pattern中使用等等，例如 null-aware dart String? notAString = null; print(notAString?.length); 如果notAString为null，不报错，表达式返回null null-aware短路 dart showGizmo(Thing? thing) { print(thing?.doohickey.gizmo); } 如果thing为null，不会评估表达式后面的部分，直接返回，避免写下thing?.doohickey?.gizmo这样繁琐的表达式 null-aware与下标运算符 dart receiver?[index]; null-aware与级联运算符 dart receiver?..method(); null assert dart String toString() { if (code == 200) return 'OK'; return 'ERROR $code ${error!.toUpperCase()}'; } 一旦error的运行时类型为null，就会出现转型错误（cast error），抛出运行时异常 与pattern配合 dart String? maybeString = 'nullable with base type String'; switch (maybeString) { case var s?: // 's' has type non-nullable String here. } dart List\u003cString?\u003e row = ['user', null]; switch (row) { case ['user', var name!]: // ... // 'name' is a non-nullable string here. } dart (int?, int?) position = (2, 3); var (x!, y!) = position; dart的null safety有一个特点：一个变量，只要编译器确定了它不为空，那么它永远不可能为null，这种特性被称为sound null safety ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#dart的类型安全"},{"categories":null,"content":"这篇文章描述了如何在KDE桌面环境使用一个名为pano的音频可视化widget 效果图 ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:0:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#"},{"categories":null,"content":" KDE如何安装widget占坑 ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:0:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#kde如何安装widget"},{"categories":null,"content":" 如何安装panopano仓库见https://github.com/rbn42/panon，仓库已经两年没有更新了，在比较新的系统上可能会出现一些问题，所以必须手动修改部分源码再重新编译 ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:0:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#如何安装pano"},{"categories":null,"content":" 安装依赖 shell sudo pacman -S qt5-websockets \\ python-docopt python-numpy python-pyaudio python-cffi python-websockets 其他发行版见README ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:1:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#安装依赖"},{"categories":null,"content":" 解决一个bug因为python的collection.Iterable在3.10弃用，移动到了collection.abc.Iterable，导致pano在python系统解释器版本比较高的情况下会出现无法显示音频的情况， 详见https://github.com/rbn42/panon/pull/108#issuecomment-1568908093 先拉取pano源码 shell git clone https://github.com/rbn42/panon.git cd panon git submodule update --init 然后修改./third_party/SoundCard/soundcard/pulseaudio.py，将所有使用到collection.Iterable的部分换成collection.abc.Iterable diff -import collections +import collections.abc - if isinstance(self.channels, collections.Iterable): + if isinstance(self.channels, collections.abc.Iterable): - if isinstance(self.channels, collections.Iterable): + if isinstance(self.channels, collections.abc.Iterable): 然后构建widget shell # Build translations (optional) mkdir build cd build cmake ../translations make install DESTDIR=../plasmoid/contents/locale cd .. # To install kpackagetool5 -t Plasma/Applet --install plasmoid ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:2:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#解决一个bug"},{"categories":null,"content":" 安装后的设置将pano放到任务栏后，需要设置采集音频的来源 对于比较新的linux，基本使用pulseaudio提供音频服务，pulseaudio有很多前端可以快速的配置一些音频的选项，这里使用pavucontrol shell sudo pacman -S pavucontrol pavucontrol提供一个简单的GUI前端，打开application launcher搜索pulseaudio，设置ALSA plugin-in的采集来源，如果设置为麦克风，则pano会显示麦克风录音的音频， 然而正常情况下应该是采集耳机中播放的音乐的音频然后可视化 pano默认的特效有点丑，可以选择其他的特效，最终就能达到上述的效果 ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:3:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#安装后的设置"},{"categories":null,"content":"这篇文章是数据库系统原理课程的任务“阅读postgresql源码“的报告 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#"},{"categories":null,"content":" 如何编译首先声明一点，网上大部分的教程都不太合理，因为对环境的影响太大，权限约束不够严格 作为开源自由软件，pg使用GNU工具链编译，包括autoconf,makefile，gcc等 进入pg项目，在build目录下编译 shell mkdir build \u0026\u0026 cd build # 完成configure，指定-g编译参数,禁用优化，指定安装路径 ../configure --enable-debug CFLAGS=\"O0\" --prefix=/home/arch/src/postgres/build # 路径需要使用build目录的绝对路径 # 编译安装 make \u0026\u0026 make install 安装到build目录是比较合理的！因为默认的安装位置/usr/local需要root权限才能写入，没必要给root权限，也完全没必要安装到这个地方 执行完之后，可能需要设置LD_LIBRARY_PATH环境变量 shell set LD_LIBRARY_PATH=/home/arch/src/postgres/build/lib # 指定build/lib目录，同样需要绝对路径 LD_LIBRARY_PATH告诉linux在哪里找动态链接库，以上方式设置后，只在当前终端生效。没有必要写入~/.bashrc 可以使用ldd命令查看一个可执行需要加载哪些动态库 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#如何编译"},{"categories":null,"content":" 调试的方法首先，在使用configure时，指定参数--enable-debug，以-g选项编译pg make命令生成的可执行有多个，需要确定调试的可执行，以及它的入口函数main所在的位置 启动pg后，通过ps aux | grep postgres可以看到，pg有多个进程协作 text ➜ postgres git:(master) ✗ ps aux | grep postgres arch 140029 0.0 0.1 205168 21652 ? Ss 22:04 0:00 /home/arch/src/postgres/build/bin/postgres -D data arch 140202 0.0 0.0 205316 8276 ? Ss 22:05 0:00 postgres: checkpointer arch 140203 0.0 0.0 205300 7764 ? Ss 22:05 0:00 postgres: background writer arch 140225 0.0 0.0 205336 10588 ? Ss 22:05 0:00 postgres: walwriter arch 140226 0.0 0.0 206844 8156 ? Ss 22:05 0:00 postgres: autovacuum launcher arch 140227 0.0 0.0 206788 7644 ? Ss 22:05 0:00 postgres: logical replication launcher arch 140264 0.0 0.0 207788 11612 ? Ss 22:06 0:00 postgres: arch test [local] idle 可以看出， arch test [local] idle是pg为处理客户端的连接而创建的进程，所以可以知道一条sql语句执行的全部流程都在这个进程中完成。 在linux上，进程是通过fork系统调用创建的。gdb对fork有一个限制，fork执行结束后，有一个父进程和子进程，然而gdb只能跟踪一个进程。 gdb默认跟踪父进程，导致无法进入子进程调试，可以通过set follow-fork-mod child改变这种行为。 然而，这种方式我在使用时发现会导致gdb立刻退出，而pg进程还在后台运行 于是，我尝试使用gdb的attach功能调试 arch test [local] idle进程 首先，要让gdb能够attach上pg的进程，需要修改ptrace的安全策略 shel sudo bash -c 'echo 0 \u003e /proc/sys/kernel/yama/ptrace_scope' 然后，在arch test [local] idle进程执行的代码中打上断点，attach上这个进程，成功进入这个进程开始调试 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#调试的方法"},{"categories":null,"content":" pg的其他特性","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#pg的其他特性"},{"categories":null,"content":" 内存管理常规的程序使用C标准库提供的malloc和free函数管理内存，如下 c OBJ* o = malloc(sizeof(OBJ)); // ... 一些操作 free(o); 这种方式的缺点有 需要跟踪大量小对象的生存期，心智负担大，不仅容易忘记释放内存，还降低了性能 必须保持申请的内存的引用，否则将永远无法回收内存 pg使用MemoryContext管理内存，所有需要在一定时间后才能释放对象的都使用MemoryContext机制。它的优点是 能够满足大量小块内存的情况，又能一次性释放，不必跟踪每一个对象的生存期 不必保持申请的内存的引用 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#内存管理"},{"categories":null,"content":" pg使用的数据结构pg在对sql语句处理的各个阶段都需要存储一些数据，使用的是一种被称为List的数据结构，然而这个称呼实际上不准确，是历史遗留的称呼，因为pg最开始有一部分是用Lisp语言写的，那时使用的是Lisp的cons-cell list，相当于链表 在使用C重写原来的Lisp部分时，由于性能问题，在经过多次重构后，最终使用了动态数组实现了这种可以动态增长的线性表结构，而List这种称呼就遗留了下来 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:2:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#pg使用的数据结构"},{"categories":null,"content":" 一条sql语句执行的全过程单条SQL语句在exec_simple_query函数完成执行的过程，见src/backend/tcop/postgres.c graph LR A[客户端/应用程序] --SQL语句--\u003e B[解析器] B --查询树--\u003e C[重写器] C --重写后的查询树--\u003e D[规划器] D --执行计划--\u003e E[执行器] E --执行结果--\u003e F[客户端/应用程序] 或者 graph LR A[客户端/应用程序] --原始字符串--\u003e B subgraph 核心 B[\"解析（parse）\"] --\u003e C[\"`prepared statement`\"] C --\u003e D[\"bind（绑定）\"] D --\u003e E[\"`portal`\"] E --\u003e F[执行] end F --结果--\u003e G[客户端/应用程序] ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#一条sql语句执行的全过程"},{"categories":null,"content":" 解析解析有三个过程，词法解析，语法解析，分析 解析由pg_parse_query函数完成，见src/backend/tcop/postgres.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#解析"},{"categories":null,"content":" 词法解析flex完成词法解析，只需要定义TOKEN(词法单元)，flex会自动生成C代码完成词法解析的任务。词法解析完成后，词法信息存储在词法树中，并准备传递给语法解析器 flex可以快速定义一个词法解析器，可以使用表则表达式，还能指定匹配优先级 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:1","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#词法解析"},{"categories":null,"content":" 语法解析bison完成语法解析，通过定义生成式，可以精确的描述各种复杂的语法结构（更多语法解析的知识参见编译原理） bison非常灵活，可以将语法定义和动作结合在一起，并支持多种描述语法的方式，例如上下文无关文法（Context-Free Grammar，CFG），扩展巴克斯范式（Extended Backus-Naur Form，EBNF）等 bison将定义语法的源文件转换成C代码，编译后可以得到一个语法解析器。 最终，pg通过调用flex和bison，得到了一个解析树（Parse Tree），这样的结构方便后续对它进行操作。任何错误的SQL语法都会在语法解析阶段被检测并处理 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:2","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#语法解析"},{"categories":null,"content":" 分析检查SQL语句中是否出现了非语法错误，例如试图查询一个不存在的表，或者不存在的字段，这个过程将解析树转换成查询树(Query Tree) 查询树由Query结构体表示(见src/include/nodes/parsenodes.h)，它包括了一次查询的所有信息，例如语句类型，from子句的列表， group by子句的列表，是否有with语句等等 分析由parse_analyze_fixedparams函数完成，见src/backend/parser/analyze.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:3","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#分析"},{"categories":null,"content":" 重写根据预先制定的规则对查询树进行重写 同一个目地的查询，它的关系代数表达式有很多种，然而他们的执行效率是不同的，执行效率高的关系代数表达式具有某些特征。 重写的规则就是执行效率高的关系代数表达式的特征 Postgres支持视图(View)，任何对视图的查询都会在这个阶段被重写成对基表(Base Table)的查询 工具类的语句不会被重写 常见的重写规则有 视图展开（View Expansion） 谓词下推（Predicate Pushdown） 连接消除（Join Elimination） 常量折叠（Constant Folding） 子查询优化（Subquery Optimization） 列裁剪（Column Pruning） 重写由pg_rewrite_query函数完成，见src/backend/tcop/postgres.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:2:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#重写"},{"categories":null,"content":" 规划规划查询器会根据已有的信息估计每条路径的成本，选择成本最低的路径，生成执行计划 例如一个SELECT语句，有两条路径可以到达相同的目标，一是全表扫描，二是利用索引。这时规划查询器会估计每个路径的成本 索引并不是在任何情况下都能加快查询，在查询结果在全表中占比较大时，使用索引的成本更高，因为对于每条记录，利用索引都需要多次IO 规划由pg_plan_query函数完成，见src/backend/tcop/postgres.c 其中，查找所有路径由subquery_planner函数完成，见src/backend/optimizer/plan/planner.c subquery_planner返回了一个PlannerInfo结构体，它表示了规划路径时生成的所有信息 随后，get_cheapest_fractional_path从其中选择出成本最低的路径，见src/backend/optimizer/plan/planner.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:3:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#规划"},{"categories":null,"content":" 执行器执行器拿到执行计划后，构造一个对象，叫做portal，它表示了一次准备好了的执行。对于SELECT语句，它相当于一个打开的游标 准备portal的过程包括 根据查询计划构造portal，由PortalDefineQuery完成 开启portal，由PortalStart完成 设置返回结果的格式，由PortalSetResultFormat完成 打开并设置接受结果的通道 随后，调用PortalRun函数完成最终的执行，见src/backend/tcop/pquery.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:4:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#执行器"},{"categories":null,"content":" 连接管理pg是一个支持多种操作系统的软件，不同操作系统的对异步IO的支持程度不同，在较新的linux上，它会使用epoll机制 linux的IO机制主要的进化过程如下 graph LR A[常规阻塞IO] --\u003e B[select] B --\u003e C[poll] C --\u003e D[epoll] epoll是一个现代的异步IO机制，它是高性能服务器必不可少的一部分 简单来说，epoll机制有三个主要的函数 c int epoll_create (int __size); // 创建epoll对象，返回一个文件描述符指向epoll实例 // 对监听的文件描述符集合进行操作，可以增加，修改，删除 int epoll_ctl (int __epfd, int __op, int __fd, struct epoll_event *__event); // 调用时阻塞直到监听的文件描述符集合中有事件发生，返回发生事件的文件描述符集合 extern int epoll_wait (int __epfd, struct epoll_event *__events,int __maxevents, int __timeout) pg主进程启动时，会创建一系列的辅助进程，包括后台写进程，压缩进程等等，随后它会创建一个epoll实例，然后进入循环，不断等待epoll事件发生、 处理事件、继续等待 当pg从epoll_wait中返回时，它会处理发生的所有事件，如果是客户端的连接，它会通过BackendStartup函数创建一个进程处理客户端的请求 采用这样的模型，在没有客户端连接时，pg主进程长时间阻塞，几乎不占用CPU，在高负载时，epoll_wait一次能返回多个事件，性能也非常好 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#连接管理"},{"categories":null,"content":" 总结","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#总结"},{"categories":null,"content":" C的缺点在pg这个项目中可以看出很多C的缺点，然而有些缺点是编译型语言的，所以这里只列出了相比C++，以及Rust的缺点 抽象程度不及C++，虽然C也有一定的抽象，但是还是不能屏蔽足够的细节，在一个有140万行源码的项目中体现非常明显 缺少命名空间机制，在一个140万行源码中的项目考虑一个不会重复的函数难度还是有点高的，其次导致了标识符的名字普遍非常长 异常处理机制太过原始，使用sigsetjmp和siglongjmp，本质上只是全局goto，不易调试和理解 语言没有常见数据结构的标准库，导致开发一个大型项目的一个必不可少的工作就是重新造轮子 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#c的缺点"},{"categories":null,"content":" 读后感 text ➜ postgres git:(master) ✗ fd -e c -e h | xargs wc -l | tail -n 1 1562969 total PostgreSQL源码非常大，有150万行，本次课程任务也只是看到了其中冰山一角中的一角，许多内容由于能力有限精力有限，并没有深入研究。 它向我们展示了一个关系型数据库理论的丰富和深厚，以及一个大型开源项目的复杂性，这对我今后的学习和工作都有很大的帮助。 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:2:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#读后感"},{"categories":null,"content":"这篇文章是完成docker的get started guide后的总结，见https://docs.docker.com/get-started/ ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#"},{"categories":null,"content":" 前置概念","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#前置概念"},{"categories":null,"content":" docker架构docker采用server-client架构，docker deamon（即dockerd）完成构建容器，运行容器等工作，docker client与docker deamon通过REST API或UNIX socket或网卡通信 docker client可以是 名为docker的cli（命令行接口） docker compose(也是cli) docker desktop（GUI） etc… ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#docker架构"},{"categories":null,"content":" image与containerimage和container的关系类似于类与对象，image可以从docker hub中下载，container是一个image的实例 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#image与container"},{"categories":null,"content":" docker的进程模型在启动容器时，会提供一个命令用于启动主进程，docker的默认一个容器只做一件事而且做到最好，所以一个容器一般只运行一个进程，docker的进程调度器也对此做过针对优化 主进程退出时，docker也会自动停止镜像 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:3:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#docker的进程模型"},{"categories":null,"content":" 安装首先用包管理器安装docker bash sudo pacma -S docker 然后启动dockerd bash sudo systemctl enable docker sudo systemctl start docker 可能出现非root用户无法运行dokcer的情况，可以将当前用户加入docker用户组 注意这实际上是不够安全的，可能会增加一个攻击面 bash sudo gpasswd -a ${USER} docker ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#安装"},{"categories":null,"content":" 使用docker有许多子命令，可以输入docker --help查询所有子命令 子命令也可以通过--help参数查询使用方法，例如docker image --help ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#使用"},{"categories":null,"content":" 工作流1——使用docker hub提供的镜像","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#工作流1使用docker-hub提供的镜像"},{"categories":null,"content":" 启动容器以ubuntu镜像为例 拉取一个镜像到本地 shell docker pull ubuntu 创建一个ubuntu的容器 shell docker create ubuntu docker会随机给这个容器随机生成一个名字，也可以指定名字 shell docker create --name mycontainer ubuntu 创建后，启动容器 shell docker start mycontainer docker提供了一个更简单的命令run来简化这个流程 shell docker run ubuntu # 同样可以通过--name指定容器名 run命令会自动拉取镜像（如果本地没有），创建容器，启动容器 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:1","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#启动容器"},{"categories":null,"content":" 查看容器状态启动ubutnu容器后，可以通过ps查看容器状态 shell docker ps 然而发现并没有结果，这是因为ps只输出运行中的容器 查看全部容器 shell docker ps -a 发现刚刚启动的容器的状态是Exited，这是dokcer的进程模型导致的，因为ubuntu容器的启动命令是/bin/bash，bash默认读取标准输入，而没有提供标准输入，所以bash读取到EOF后退出，主进程退出后容器也自动停止了 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#查看容器状态"},{"categories":null,"content":" 交互式操作前文提及，因为没有提供标准输入，ubutnu镜像立刻退出了，为了避免这种情况，或能够进入ubutnu容器的终端，可以提供标准输入 shell docker run -it ubuntu 进入ubuntu容器的终端后，按下Ctrl+D，bash退出，ubutnu容器也会被停止 -it参数中，-i表示即使没有连接到标准输入也不关闭，-t表示分配一个tty，有了-t，就能将当前终端连接到容器内bash的标准输入、标准输出、标准错误，有了-i，就能在退出容器后（标准输入deattach）后，再次启动（start命令）ubuntu容器后，容器不立刻退出（因为标准输入没有关闭，不会读取到EOF，只是在read系统调用上阻塞） ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:3","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#交互式操作"},{"categories":null,"content":" execexec命令可以在一个运行中的容器内执行命令 先创造出一个运行中的ubutnu容器 text docker run -it --name mycontainer ubuntu # 在容器的bash中按下Ctrl+D或exit docker start mycontainer 再使用exec shell docker exec -it mycontainer bash 又进入了bash，然而这个bash实际上是新开的bash进程，在容器内输入top，可以看到有两个bash，其中一个是通过run创建的，另一个是通过exec创建的 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:4","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#exec"},{"categories":null,"content":" attach如上，为了避免再创建一个bash进程，可以将当前终端的标准输入，标准输出，标准错误连接到容器内 shell docker attach mycontainer 在容器内执行top，发现只有一个bash进程 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:5","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#attach"},{"categories":null,"content":" 管理容器停止容器 shell docker stop mycontainer 删除容器 shell docker rm mycontainer ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:6","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#管理容器"},{"categories":null,"content":" 工作流2——通过镜像协同工作创建一个镜像后，可以分享给其他人，从而解决环境搭建、统一环境等问题 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#工作流2通过镜像协同工作"},{"categories":null,"content":" 创建镜像一个Dockerfile的示例 Dockerfile FROM node:18-alpine WORKDIR /app COPY . . RUN yarn install --production CMD [\"node\", \"src/index.js\"] EXPOSE 3000 随后通过当前目录下的Dockerfile的内容创建镜像 shell docker build -t myimage ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:1","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#创建镜像"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push \u003cmyname\u003e/\u003cmyimage\u003e 其他人可以得到你创建的容器 shell docker pull \u003cmyname\u003e/\u003cmyimage\u003e 或 shell docker run \u003cmyname\u003e/\u003cmyimage\u003e 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#分享给其他人"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push / 其他人可以得到你创建的容器 shell docker pull / 或 shell docker run / 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#使用docker-hub"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push / 其他人可以得到你创建的容器 shell docker pull / 或 shell docker run / 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#发送镜像文件"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push / 其他人可以得到你创建的容器 shell docker pull / 或 shell docker run / 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#第三方镜像托管服务"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push / 其他人可以得到你创建的容器 shell docker pull / 或 shell docker run / 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#私有镜像仓库"},{"categories":null,"content":" docker的其他功能","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#docker的其他功能"},{"categories":null,"content":" 数据持久化","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#数据持久化"},{"categories":null,"content":" volume","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:1","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#volume"},{"categories":null,"content":" bind","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#bind"},{"categories":null,"content":" dokcer的网络","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#dokcer的网络"},{"categories":null,"content":" 端口映射","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:1","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#端口映射"},{"categories":null,"content":" docker compose假设需要搭建一个前后端分离的web服务，前端页面由机器上已经安装好的nginx分发，后端服务使用docker部署，此外还需要一个mysql容器提供数据库服务。这需要多个容器协作。前文提到，一个容器只做一件事并做到最好，当需要多个容器协作时，使用docker-cli管理的难度就变大了，docker compose就是为了解决这种问题而出现的 docker compose需要额外安装 shell sudo pacman -S docker-compose dokcer compose使用compose.yaml文件描述每个容器的配置以及他们之间的依赖关系等等 一个compose.yaml实例 yaml services: app: image: node:18-alpine command: sh -c \"yarn install \u0026\u0026 yarn run dev\" ports: - 127.0.0.1:3000:3000 working_dir: /app volumes: - ./:/app environment: MYSQL_HOST: mysql MYSQL_USER: root MYSQL_PASSWORD: secret MYSQL_DB: todos mysql: image: mysql:8.0 volumes: - todo-mysql-data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: secret MYSQL_DATABASE: todos volumes: todo-mysql-data: ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#docker-compose"},{"categories":null,"content":" 一点技巧","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#一点技巧"},{"categories":null,"content":" 关于参数不同的命令行工具都有不同的传参风格，其中docker的参数只能在固定位置，例如dokcer run -it ubuntu的-it不能放到ubuntu后面 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#关于参数"},{"categories":null,"content":"主力使用Linux一段时间后，系统占用的空间总会越来越多。虽然linux的包复用率非常高，甚至有些时候更新，包的大小还会负增长，但这无法阻止用户数据的增长，所以清理 也主要是清理用户数据 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#"},{"categories":null,"content":" 查看磁盘使用率 shell df -h ","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#查看磁盘使用率"},{"categories":null,"content":" 清理包管理器的缓存pacman会自动缓存下载过的软件包，以支持快速重新安装，以及恢复到以前的版本 这样的设计大部分情况都是合理的，而缺点就是 一个软件包，安装了一份，又保留了一份安装包， pacman不会自动删除以前的包 所以archlinux wiki建议定期手动删除包缓存 shell sudo pacman -Sc ","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#清理包管理器的缓存"},{"categories":null,"content":" 清理开发环境的缓存","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#清理开发环境的缓存"},{"categories":null,"content":" jetbrains IDEjetbrains全家桶长期使用会产生不少缓存，可以使用jetbrains toolbox一键清除 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:1:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#jetbrains-ide"},{"categories":null,"content":" VScodeVScode的扩展可以把二进制也打包进去，导致有的扩展并不小，可以选择卸载短期不会使用的扩展 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:2:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#vscode"},{"categories":null,"content":" Python","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#python"},{"categories":null,"content":" anaconda 删除虚拟环境查看conda虚拟环境 shell conda env list 鉴于某些不留requirements.txt的项目的环境真不好装，可以先生成requirements.txt再删除，日后也能恢复 shell conda list -e \u003e requirements.txt 删除某个虚拟环境 shell conda remove --name xxx --all 删除conda缓存conda下载包后会保存tar或zst，下次安装时就不需要重复下载 删除conda包缓存 shell conda clean --all ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#anaconda"},{"categories":null,"content":" anaconda 删除虚拟环境查看conda虚拟环境 shell conda env list 鉴于某些不留requirements.txt的项目的环境真不好装，可以先生成requirements.txt再删除，日后也能恢复 shell conda list -e \u003e requirements.txt 删除某个虚拟环境 shell conda remove --name xxx --all 删除conda缓存conda下载包后会保存tar或zst，下次安装时就不需要重复下载 删除conda包缓存 shell conda clean --all ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#删除虚拟环境"},{"categories":null,"content":" anaconda 删除虚拟环境查看conda虚拟环境 shell conda env list 鉴于某些不留requirements.txt的项目的环境真不好装，可以先生成requirements.txt再删除，日后也能恢复 shell conda list -e \u003e requirements.txt 删除某个虚拟环境 shell conda remove --name xxx --all 删除conda缓存conda下载包后会保存tar或zst，下次安装时就不需要重复下载 删除conda包缓存 shell conda clean --all ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#删除conda缓存"},{"categories":null,"content":" pip缓存pip也会缓存下载过的包，可以手动删除 shell pip cache remove '*' 一般只有简单的项目或者系统解释器会使用pip，删除pip缓存时也要注意环境 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:2","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#pip缓存"},{"categories":null,"content":" 数据文件搞爬虫或者机器学习，经常会生成一些数据文件，有各种训练用的数据或者检查点 另外有些库自带下载数据集的功能，不指定路径就默认在用户的家，然而这些数据集可能之后都不会使用了 不需要的数据可以直接删除，需要的数据，可以选择压缩（对已经压缩过的数据格式，再压缩几乎不会减小大小，然而将零碎文件打包确实能减少大小） ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:3","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#数据文件"},{"categories":null,"content":" Java","date":"2023-12-15","objectID":"/posts/linux-space-release/:4:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#java"},{"categories":null,"content":" maven缓存maven也会缓存下载过的包，如果使用不同版本的JDK，最后缓存的包可能会占据一些空间 shell rm -r ~/.m2/repository 删除缓存后，下次运行maven时会重新下载依赖 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:4:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#maven缓存"},{"categories":null,"content":" gradle缓存gradle作为android官方指定构建工具，它的缓存可能比maven还要多 shell rm -r ~/.gradle/caches/ ","date":"2023-12-15","objectID":"/posts/linux-space-release/:4:2","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#gradle缓存"},{"categories":null,"content":" C/C++","date":"2023-12-15","objectID":"/posts/linux-space-release/:5:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#cc"},{"categories":null,"content":" 编译产物不管是使用autoconf + make还是cmake，最终的构建命令基本都是make 一个大型或者中型项目编译产物可能不小，为了加快构建速度make往往会缓存许多构建中间产物 进入构建目录执行 shell make clean ","date":"2023-12-15","objectID":"/posts/linux-space-release/:5:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#编译产物"},{"categories":null,"content":" 本地安装的软件C/C++的依赖确实很难搞，有些时候会在/usr/local下安装一些软件作为项目的依赖 这些软件往往是下载源码，编译安装的，进入对应的构建目录 shell make uninstall 然而，软件的作者可能没有写uninstall目标，甚至源码目录都被删掉了，这种时候只能手动卸载了 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:5:2","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#本地安装的软件"},{"categories":null,"content":" JS","date":"2023-12-15","objectID":"/posts/linux-space-release/:6:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#js"},{"categories":null,"content":" npmnpm利用包缓存实现自我修复的功能，因此不建议直接清除缓存，相反，npm提供了验证并压缩缓存的方法 text du -h --max-depth=0 ~/.npm npm cache verify du -h --max-depth=0 ~/.npm ","date":"2023-12-15","objectID":"/posts/linux-space-release/:6:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#npm"},{"categories":null,"content":" dockerdocker的镜像也会占用不少的空间而且平时很难注意到 查看容器 shell docker ps -a 删除容器 shell docker rm \u003ccontainer-name\u003e 查看本地的镜像 shell docker image list 删除本地的镜像 shell docker image rm \u003cimage-id\u003e ","date":"2023-12-15","objectID":"/posts/linux-space-release/:7:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#docker"},{"categories":null,"content":" 数据库数据库也属于一种死角了。爬取了一些数据，或者从网络下载并导入了一些数据，就会导致数据库占用增大很多 可以选择删除不需要的表，或者不需要的数据库 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:8:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#数据库"},{"categories":null,"content":" 普通软件","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#普通软件"},{"categories":null,"content":" 微信微信在linux并没有一个完美的解决方案，我曾经使用过运行在wine中的微信，时间一长，微信就会不知廉耻的膨胀到几十G，这其中很多是收到的文件 最好的方法是打开微信，删除指定聊天的数据 然而或许我们不需要直接使用微信这样的毒瘤软件，可以选择将微信的消息转发到telegram，telegram不会自动下载文件，文件能在服务器上保存很久， 使用3个月后telegram的占用也只有600M，完爆微信 如何部署微信转发telegrame见https://www.v2ex.com/t/908436 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:1:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#微信"},{"categories":null,"content":" 短期不需要的软件可以查看安装的AUR中的包，删除最近不会使用的（需要的时候总会想起来安装的） ","date":"2023-12-15","objectID":"/posts/linux-space-release/:2:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#短期不需要的软件"},{"categories":null,"content":" chrome网站可以使用localStorage，某些时候可能一个网站就会占用几百M的空间，根据我的实践，占用空间巨大的往往是不太需要的 进入chrome://settings/content/all，点击按照存储的数据大小排序 选择近期不需要的删除 注意也会删除cookie，导致登录的网站退出登录，而且某些网站删除缓存数据后下次进入还会重新生成，导致加载速度变慢 作为一个每天都使用的软件，chrome的缓存不应该删除太多，否则会降低网页加载速度 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#chrome"},{"categories":null,"content":" 一点技巧","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#一点技巧"},{"categories":null,"content":" Download目录Download目录全是用户数据，可以按照大小排序，然后删除比较大，又不需要的 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:1:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#download目录"},{"categories":null,"content":" 仓库盘很多没有的文件并不是没有价值，可以买一块机械硬盘当作仓库盘，全部扔里面 我曾经在国内国外众多网盘中挑选了很久，最终选择了机械硬盘，因此我并不推荐使用网盘作为第一备份措施 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:2:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#仓库盘"},{"categories":null,"content":" 打包与压缩根据文件系统的知识，磁盘是按块管理的，这就导致不可避免的出现存储空间的浪费，对于大量的小文件，这样的浪费更加明显 仓库盘中的文件就满足这种特征，可以打包然后压缩，减少存储占用 打包会减少很多因为按块管理造成的浪费，压缩的效果不确定，因为对文本文件，压缩效果显著，而对已经压缩过的文件，压缩后几乎不会减小大小 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#打包与压缩"},{"categories":null,"content":" 删除孤儿包 shell sudo pacman -Rns $(pacman -Qtdq) 大部分时候都没有孤儿包，偶尔删除一下即可 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:4:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#删除孤儿包"},{"categories":null,"content":" 关于缓存根据cache的定义，它的作用是加快存取速度，从前面提到的很多软件的缓存可以看出它的使用场景 在实践中cache（缓存）和buffer（缓冲）往往是混用的，缓冲的目地是缓解通过接口相连的两个系统之间速度不对等情况，实践中缓冲往往也能发挥缓存的作用 缓存删除后不可避免会造成速度变慢，一个软件正常运行中也会自动产生缓存，那么为什么要删除缓存呢？ 在我看来，可以套用操作系统的知识解释 在计算机中的缓存往往有两个限制，一个是失效时间，一个是缓存容量 例如TLB，绝大部分替换策略都会导致一个TLB表项无法永远保留在TLB中，而TLB作为硬件实现也一定是固定容量而且容量有限 然而，在软件层面的缓存就不太一样了，软件管理缓存，主要是通过指定缓存容量和缓存失效时间，策略大概有 放仍不管，仍其增长 提供管理缓存的接口供用户使用，但不主动操作缓存，将管理缓存的部分工作交给用户 通过定时任务或者后台进程定期清理 这三种方式都能找到对应的软件，很遗憾的是，采用第三种方式的软件很少，这也就导致了用户必须承担管理缓存的工作，否则他就需要承担购买更多存储器的工作 缓存替换策略完成的工作是保证在缓存中的是最常用的，而用户定期清理缓存与缓存替换策略完成的工作类似，在定期的删除中，那些低频使用或者短期内高频使用的缓存最终都被删除了 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#关于缓存"},{"categories":null,"content":"最近在阅读coreutils，发现很多有意思的部分，比如哈希表的链表实现 ","date":"2023-10-14","objectID":"/posts/coreutils_hash/:0:0","series":null,"tags":["C/C++"],"title":"coreutils之hash table","uri":"/posts/coreutils_hash/#"},{"categories":null,"content":" 字符串哈希函数coreutils中内置了对字符串的哈希函数 c size_t hash_string (const char *string, size_t n_buckets) { size_t value = 0; unsigned char ch; for (; (ch = *string); string++) value = (value * 31 + ch) % n_buckets; return value; } 用法为 c char* str = \"a demo string\"; size_t hash_code = hash_string(str, 100); 可以看出计算哈希的部分就是 c for (; (ch = *string); string++) value = (value * 31 + ch) % n_buckets; 一个好的哈希函数，应该做到把输入数据均匀的映射到哈希表的所有槽，也就是每个槽的概率应该是接近的。 还可以说，一个好的哈希函数应该充分受到输入数据的每一位的影响，最好的情况就是，当输入数据的其中一位发生改变，计算出的哈希码中多位发生改变 31这个数字非常巧妙，因为 $$ 31 = 32 - 1 = 2^0 + 2^1 + 2^2 + 2^3 + 2^4 $$ 而计算机是二进制的，也就是说a * pow(2, x)等于a \u003c\u003c x 假设value==19，那么value * 31可以表示为 text 10011 10011 10011 10011 10011 —————————— 1001001101 可以看出value * 31每一位都会受到value中每一位的影响，value中任意一位发生变动，value * 31每一位也必须重新计算。然后value * 31 + ch会添加上ch造成的影响，(value * 31 + ch) % n_buckets约束结果的范围 取余操作肯定影响了哈希码的随机性，假设n_buckets==8，value * 31 + ch就只会保留低三位，大大降低了哈希码的随机性. 我的理解是，当哈希表长度小时，每个槽插入数据的概率也会增加。例如哈希表长为10，那么哈希表中每个槽的插入数据概率为$\\frac{1}{10}$，当插入两个数据时碰撞的概率为$\\frac{10}{10\\times10}=\\frac{1}{10}$，当哈希表长为11时， 插入两个数据碰撞的概率为$\\frac{11}{11\\times11}=\\frac{1}{11}$，当然当插入数据越多时，两者差距会越来越大。所以哈希表规模较小时碰撞本来就是很容易发生的。而我们关注的也只是规模较大时哈希表的性能，规模较小时哈希表和其他查询结构也没有明显优势 ","date":"2023-10-14","objectID":"/posts/coreutils_hash/:1:0","series":null,"tags":["C/C++"],"title":"coreutils之hash table","uri":"/posts/coreutils_hash/#字符串哈希函数"},{"categories":null,"content":"为了完成课程的任务，折腾了很久终于搞好了VMware。 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:0:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#"},{"categories":null,"content":" 安装VMwareVMware分为个人使用免费的player和商用付费的workstation，archlinux可以在aur中找到vmware并安装。 非archlinux可以在官网找到安装包 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:0:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#安装vmware"},{"categories":null,"content":" 配置VMware安装后还需要配置很多东西才能使用 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:0:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#配置vmware"},{"categories":null,"content":" 安装linux-headersarchlinux的更新是滚动更新，而更新了linux内核后需要重启才能完全生效。所以就会出现pacman能够查到已经安装了linux-headers包，但是仍然无法使用VMware的情况 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:1:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#安装linux-headers"},{"categories":null,"content":" 加载内核模块需要加载vmw_vmci和vmmon这两个模块 bash sudo modprobe -a vmw_vmci vmmon 然而很有可能无法加载，输出为找不到模块，这是因为对于比较新的内核，需要自己编译这两个模块 找到这个仓库，拉下来，根据INSTALL中的方法，首先根据workstation的版本，切换到对应分支 bash git clone https://github.com/mkubecek/vmware-host-modules cd vmware-host-modules git checkout workstation-17.0.2 然后开始编译，编译完成后安装 bash make sudo make install 然后重新加载模块 bash sudo modprobe -a vmw_vmci vmmon ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:2:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#加载内核模块"},{"categories":null,"content":" 设置网络执行 bash sudo systemctl start vmware-networks.service 有可能会失败，根据systemctl的日志，需要先配置网络 aur中的VMware workstation包将vmware-netcfg软链接到/usr/bin所以可以直接使用 bash sudo vmware-netcfg 在弹出的界面中配置网络 设置开机自启，再重启 bash sudo systemctl enable vmware-networks.service reboot 至此就完成了最基础的设置，已经可以在VMware虚拟机中连接网络了 参考： https://communities.vmware.com/t5/Workstation-2023-Tech-Preview/Linux-Kernel-6-5-rc-vmmon-compile-fails/td-p/2981003 https://github.com/mkubecek/vmware-host-modules/issues/11 https://aur.archlinux.org/packages/vmware-workstation https://segmentfault.com/a/1190000042268631 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:3:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#设置网络"},{"categories":null,"content":"IDEA更新后以前的项目不知道为什么不能直接运行了，新建项目后也不会自动创建运行配置了，为了解决这个问题踩了不少坑 声明一下所说的运行配置是指Run/Debug Configuration ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:0:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#"},{"categories":null,"content":" java项目的构建众所周知java一般是用maven或者gradle构建的，他们都能做到管理依赖、管理构建任务、编译等过程。 在idea的运行配置中，也可以选择gradle和maven，然后如果你选择了它们作为运行配置，多半会看到这个界面 然而一般来说希望看到的应该是这个 实际上，maven和gradle作为构建工具，命令行调用时可以传入不同参数作为task，构建工具不负责运行 ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:0:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#java项目的构建"},{"categories":null,"content":" 如何设置idea的运行配置首先我们要清楚idea支持三种方式 IDEA Build maven gradle 和idea定位相同的eclipse也有eclipse build，不推荐使用IDE特有的方式构建，因为他们往往是跟IDE绑定的，无法直接在命令行使用，不如专业的构建工具成熟 一个新的IDEA项目，需要首先指定java SDK版本 在设置中找到Project Structure，配置SDK 点击File-settings，找到Build,Execution, Deployment - Build Tools - Gradle 把Build and run using和Run test using改成IntelliJ IDEA 使用maven可以跳过这一步 创建一个’Run/Debug Configuration’，选择JDK、main方法入口，保存 到这一步已经能够实现这样的效果 ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:0:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#如何设置idea的运行配置"},{"categories":null,"content":" Tips在使用第三方库的时候又踩了一个坑，整理一下java项目使用第三方库的流程 在maven中心仓库上搜索想要的包 指定版本后，直接复制配置，粘贴到pom.xml或build.gradle即可 pom.xml或build.gradle改变后，IDEA会重新同步它们的更新，然后可以看到新加入的包出现在文件管理器的’External Libraries’中 至此就可以根据包名使用了。然而比较坑的一点就是包在maven中心仓库的坐标并不总是他们的包名，需要确定包名 按理来说，直接找到包的文档网站，能够看到一些代码片段有这样的语句 java import com.squareup.okhttp.OkHttpClient; 然而实际上，文档中的代码片段几乎不会有这样的语句 ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:0:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#tips"},{"categories":null,"content":" 如何确定包名首先已经知道了这个包的俗称，根据俗称可以在maven中心仓库搜索得到这个包的坐标，然后就能下载到这个包的jar文件。 根据jar的规范，解压jar包后，在META-INF/MANIFEST.MF中有这个jar包的元数据。例如okhttp包，META-INF/MANIFEST.MF内容为 text Manifest-Version: 1.0 Automatic-Module-Name: okhttp3 可以知道包名为okhttp3，而不是com.squareup.okhttp！ ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:1:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#如何确定包名"},{"categories":null,"content":"之前安装archlinux，随便配置的中文字体，显示中文时总有一些奇奇怪怪的字形，最近翻了archlinux的文档，把字体配置搞清楚了 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#"},{"categories":null,"content":" 字体是什么简单来说，字体告诉屏幕如何显示一个字，字体常见的格式有Bitmap和Outline，大致区别就是Bitmap直接指定了每一个像素，有点类似于字模，而Outline指定的是字的轮廓，至于具体怎么显示还需要根据屏幕分辨率，字号等信息来计算。很明显，Outline格式是更加现代的格式，所以此文就忽略Bitmap Outline格式有以下几种格式 PostScript fonts，由adobe发明 TrueType，由Apple和Microsoft发明，扩展名是ttf OpenType，由Microsoft发明，相当于TrueType的进阶版，扩展名是otf或ttf 实际使用中，TrueType是最常见的 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体是什么"},{"categories":null,"content":" 字体如何安装只需要把字体文件放到指定目录下，就完成了安装。 指定目录有哪些，可以查看/etc/fonts/fonts.conf 例如 xml \u003c!-- Font directory list --\u003e \u003cdir\u003e/usr/share/fonts\u003c/dir\u003e \u003cdir\u003e/usr/local/share/fonts\u003c/dir\u003e \u003cdir prefix=\"xdg\"\u003efonts\u003c/dir\u003e \u003c!-- the following element will be removed in the future --\u003e \u003cdir\u003e~/.fonts\u003c/dir\u003e 可见指定路径为/usr/share/fonts, /usr/local/share/fonts，$HOME/.local/share/fonts。不同的路径有不同的作用范围 安装字体后，为了快速生效，可以使用fc-cache --force强制刷新字体缓存 更好的办法是使用包管理器安装字体 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体如何安装"},{"categories":null,"content":" 字体模块字体模块分为匹配模块和配置模块 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体模块"},{"categories":null,"content":" 字体配置模块字体配置模块简单来说就是一堆xml文件，遵循特定的语法。 可以配置字体目录，字体配置的目录，字体缓存的目录，还能配置一些特殊的操作，例如 xml \u003c!-- Accept alternate 'system ui' spelling, replacing it with 'system-ui' --\u003e \u003cmatch target=\"pattern\"\u003e \u003ctest qual=\"any\" name=\"family\"\u003e \u003cstring\u003esystem ui\u003c/string\u003e \u003c/test\u003e \u003cedit name=\"family\" mode=\"assign\" binding=\"same\"\u003e \u003cstring\u003esystem-ui\u003c/string\u003e \u003c/edit\u003e \u003c/match\u003e \u003c!-- Load local system customization file --\u003e \u003cinclude ignore_missing=\"yes\"\u003econf.d\u003c/include\u003e \u003c!-- Font cache directory list --\u003e \u003ccachedir\u003e/var/cache/fontconfig\u003c/cachedir\u003e \u003ccachedir prefix=\"xdg\"\u003efontconfig\u003c/cachedir\u003e ","date":"2023-09-18","objectID":"/posts/linux-font/:1:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体配置模块"},{"categories":null,"content":" 字体匹配模块字体有很多属性，例如family，familylang，weight，spacing等等。字体匹配做的就是： 当请求一个字体时，计算请求的字体和所有已有字体的距离，返回距离最小的字体。 距离就是根据属性计算得出的。这样可以保证请求一个字体时，不管计算机上有没有这个字体，都能返回一个字体。 当计算机上有多个满足请求partten的字体时，仍然只有一个字体返回，这就可能导致返回的字体不是用户希望的字体。 例如，Noto Sans CJK有中文，日文，韩文。当请求Noto Sans CJK时，以下四个字体都满足请求pattern（假设locale设置为en_US） Noto Sans CJK SC Noto Sans CJK TC Noto Sans CJK JP Noto Sans CJK KR 然而因为Noto Sans CJK JP的地区代号JP在CN之前，导致某些字体使用Noto Sans CJK JP渲染。例如下图的关和门都使用了Noto Sans CJK JP字体 这种情况可以通过设置字体优先级解决,在~/.config/fontconfig/conf.d/perfer.conf写入 xml \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE fontconfig SYSTEM \"fonts.dtd\"\u003e \u003cfontconfig\u003e \u003calias\u003e \u003cfamily\u003esans-serif\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003calias\u003e \u003cfamily\u003emonospace\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans Mono CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003c/fontconfig\u003e 然后刷新字体缓存即可生效 需要注意的是，由于linux字体的配置是分布在不同地方的，配置可能有重复的情况发生。 例如假设我希望使用JetBrains Mono作为等宽字体，修改~/.config/fontconfig/conf.d/perfer.conf为 xml \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE fontconfig SYSTEM \"fonts.dtd\"\u003e \u003cfontconfig\u003e \u003calias\u003e \u003cfamily\u003esans-serif\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003calias\u003e \u003cfamily\u003emonospace\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eJetBrains Mono\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003c/fontconfig\u003e 并没有生效，因为在~/.config/fontconfig/fonts.conf中有这么一段 xml \u003calias\u003e \u003cfamily\u003esans-serif\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003calias\u003e \u003cfamily\u003emonospace\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans Mono CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e 所以修改linux配置文件时，应该遵循一个原则，就是先从/etc下的配置文件寻找。因为/etc下的配置文件是第一个被加载的， 这些配置文件做的事往往有 完成一些默认配置 include更多的配置文件 规定用户配置文件应该放在哪里 /etc下的配置文件的重要性非常高。因为在网上查阅有关配置文件的资料时，往往受限于版本、发行版的不同、软件来源等方式，网上的资料不一定管用。而/etc不仅仅是软件的配置文件，还能在一定程度上充当软件的说明书，它的作用有点类似于gcc的头文件，是编译器最高优先级的接口定义文档。 ","date":"2023-09-18","objectID":"/posts/linux-font/:1:1","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体匹配模块"},{"categories":null,"content":" 关于字体在字体非常多的属性中，有几个属性是最突出的 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#关于字体"},{"categories":null,"content":" 衬线与非衬线衬线就是serif，非衬线就是sans serif，衬线是字形笔画的起始段与末端的装饰细节部分。 从最近十几年来各大互联网公司的logo演变可以看出来，非衬线越来越受欢迎。推荐正文部分使用非衬线字体，能够缓解视觉压力 ","date":"2023-09-18","objectID":"/posts/linux-font/:1:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#衬线与非衬线"},{"categories":null,"content":" 等宽与比例所谓等宽，也就是每一个字符的宽度相等，在视觉上每一行能够对齐，这是一种编程友好字体，几乎所有IDE都默认使用等宽字体（如果有IDE默认使用非等宽字体，赶紧抛弃它吧！） 等宽字体往往指的是英文ASCII字符等宽，还有一种字体能够做到中文字符和英文等宽，这种字体在中英文混合排版的时候非常方便 ","date":"2023-09-18","objectID":"/posts/linux-font/:2:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#等宽与比例"},{"categories":null,"content":" CJKCJK就是Chinese Japan Korea的缩写，表示中日韩文字。作为一个archlinux中国用户，即使locale设置为en_US，也不可避免的要使用CJK字体 ","date":"2023-09-18","objectID":"/posts/linux-font/:3:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#cjk"},{"categories":null,"content":" Emoji众所周知，Unicode字符集是包括emoji的。网上下载的字体文件是一系列Unicode字符的字形的集合，也就是说，一个普通的字体很有可能是没有emoji的。linux在font fallback后会发现没有字体能够显示这个emoji，于是就是显示成一个方框。需要显示emoji只需要安装emoji字体即可 ","date":"2023-09-18","objectID":"/posts/linux-font/:4:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#emoji"},{"categories":null,"content":" Patched fontPatched font即为打了补丁的字体，有一些TUI(Textual User Interface)可能需要这些字体，用于显示一些特殊的符号 ","date":"2023-09-18","objectID":"/posts/linux-font/:5:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#patched-font"},{"categories":null,"content":" 小技巧","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#小技巧"},{"categories":null,"content":" 解决WPS Office打开文档时字体显示过粗 可以鼠标选中显示异常的字体，发现字体是微软雅黑，我的电脑上没有安装微软雅黑，所以fallback到了其他字体，然而使用其他字体显示微软雅黑多少有点瑕疵。例如字体加粗部分就会显得非常粗 解决办法有两个 如果安装了双系统，可以挂载windows分区，然后把windows的C:\\Windows\\Fonts\\目录软链接到/usr/share/fonts/WindowsFonts/ 安装windows字体 因为windows字体非常多，可能导致一句中文使用了不同字体渲染，非常丑，可以指定字体优先级来避免 office中文用户常常会有使用了各种字体的office文档，每个都下载不仅占用空间，而且往往只能知道字体的中文名而不知道它的英文名，不方便从AUR安装，手动安装也有点麻烦 解决方案见archlinux中文维基，将freetype2降级即可 ","date":"2023-09-18","objectID":"/posts/linux-font/:1:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#解决wps-office打开文档时字体显示过粗"},{"categories":null,"content":" 查看fallback到的字体使用Chrome浏览器查看，打开网页https://c.runoob.com/front-end/61/在线编辑HTML，在CSS中指定字体，然后F12打开浏览器开发者工具，选中元素，点击Computed，就能看到实际渲染使用的字体 ","date":"2023-09-18","objectID":"/posts/linux-font/:2:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#查看fallback到的字体"},{"categories":null,"content":" fc-*系列工具","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#fc-系列工具"},{"categories":null,"content":" fc-list执行 shell fc-list 可以输出计算机上所有字体 bash fc-list :lang=zh 可以输出中文字体 bash fc-list :spacing=100 可以输出所有等宽字体 ","date":"2023-09-18","objectID":"/posts/linux-font/:1:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#fc-list"},{"categories":null,"content":" fc-match执行 bash fc-match mono 可以根据mono请求字体，这实际上是调用了字体匹配模块的功能。 bash fc-match -s mono 可以输出所有满足请求的字体并排序 需要debug时，可以设置FC_DEBUG环境变量 bash FC_DEBUG=1 fc-match mono FC_DEBUG的每个位都有约定的含义，见https://man.archlinux.org/man/fonts-conf.5 ","date":"2023-09-18","objectID":"/posts/linux-font/:2:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#fc-match"},{"categories":null,"content":" fc-cache bash fc-cache --force 强制重新生成字体缓存，在修改了字体配置或安装了新字体后执行，可以立即生效 ","date":"2023-09-18","objectID":"/posts/linux-font/:3:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#fc-cache"},{"categories":null,"content":"这篇文章是wikipedia的recsys词条的翻译以及简化版本，原文见https://en.wikipedia.org/wiki/Recommender_system recsys(推荐系统)的种类 collaborative filtering（协同过滤）根据相似用户的行为为用户推荐内容，推荐理由是“与你相似的人都喜欢xx”， 缺点是需要大量用户行为数据，冷启动慢 content-based filtering（基于内容过滤）给物打上标签，推荐具有相似标签的物，推荐理由是“与你喜欢的xx有关”， 少量用户行为数据即可启动，但是只能推荐相似的物，无法推荐新物 knowledge-based systems ","date":"2023-08-04","objectID":"/posts/recsys-summary/:0:0","series":null,"tags":["Mechine Learning"],"title":"推荐系统简单介绍","uri":"/posts/recsys-summary/#"},{"categories":null,"content":" collaborative filtering协同过滤的假定是 过去相似的用户，在未来也是相似的 过去用户喜欢的物，在未来也是喜欢的 推荐系统只使用了不同用户对不同物的评分，通过使用评分，推荐系统定位用户和物，使用邻居生成推荐 协同推荐的分类 memory-based 基于内存的协同过滤，例子是user-based algorithm(基于用户的推荐算法) model-based，基于模型的协同过滤，例子是matrix factorization（矩阵分解） 优点是不需要机器分析内容（使用NLP分析文本并打上标签等等），能准确推荐复杂的物，缺点是需要大量用户行为数据，冷启动慢 判断用户的相似度使用的算法有 k-nearest neighbors(kNN算法) Pearson correlation coefficient(皮尔逊相关系数) approximate nearest neighbors(ANN,近似最近邻算法) 协同过滤的缺点 冷启动 新用户和新物缺少数据，无法推荐 可扩展性 随着用户和物的增加，计算量增加，大型推荐系统需要很高的算力 稀疏性 用户和物的数量都很大，但一个用户只会和极少的物交互，数据很稀疏 item-to-item collaborative filtering（基于物的协同过滤）也是协同过滤的一个例子，它的推荐理由是“喜欢x的人也喜欢y ” ","date":"2023-08-04","objectID":"/posts/recsys-summary/:0:0","series":null,"tags":["Mechine Learning"],"title":"推荐系统简单介绍","uri":"/posts/recsys-summary/#collaborative-filtering"},{"categories":null,"content":" Content-based filtering基于内容过滤的推荐系统使用的数据是物的特征（打的标签）和用户的偏好资料， 它将推荐问题转换成了将一群用户分为喜欢某特征和不喜欢某特征的分类问题 为了创建用户偏好资料，推荐系统集中于两种信息 xxxxxxxxxx fn(5); 118e: bf 05 00 00 00 mov $0x5,%edi 1193: e8 b1 ff ff ff call 1149 \u003c_Z2fni\u003etext 用户与推荐系统交互的历史 为了获取物的特征，推荐系统常用TF-IDF（又称向量空间表示）算法 推荐系统基于权重向量创建用户的偏好资料，权重向量中的每一个权重表达了每个特征对用户的重要性。计算权重向量的方法有： 取用户有关的物的权重向量的平均值，还有贝叶斯分类器，聚类分析，决策树，神经网络 基于内容过滤的一个关键问题是，推荐系统不能从一个内容源中学习到用户的偏好然后在其他类型的内容中使用学习到的用户偏好。例如 推荐系统从用户阅读新闻的行为中学习到了用户的偏好，但不能在推荐音乐，视频，产品等物时使用这些偏好。为了克服这个问题， 大多数基于内容过滤的系统都会使用混合式的系统 ","date":"2023-08-04","objectID":"/posts/recsys-summary/:0:0","series":null,"tags":["Mechine Learning"],"title":"推荐系统简单介绍","uri":"/posts/recsys-summary/#content-based-filtering"},{"categories":null,"content":" Hybrid recommender systems大多数推荐系统都采用混合式的方案，结合协同过滤、基于内容过滤等等。 混合式的方案有几种实现方法，可以让不同的推荐系统分别生成推荐然后将结果合并，也可以将协同过滤的能力加入到 基于内容过滤的系统中（或者相反） 混合式的推荐系统的准确度一般比单一的推荐系统高，而且能够克服单一推荐系统的缺点，例如冷启动和稀疏性问题 一些混合式的技术有 Weighted 将不同推荐系统给一个物的评分求加权平均值，仅仅通过数值的方法来结合不同的推荐系统 Switching 在不同的推荐系统中切换，采用所选的系统 Mixed 将不同推荐系统的结果合并 Feature Combination 将来自不同知识源的特征结合起来，输入给一个推荐系统 Feature Augmentation 计算一个或一组特征，其结果作为下一个推荐系统的输入 Cascade 不同推荐系统被赋予不同的优先级，当高优先级的推荐系统给一些物打分相同时，低优先级的推荐系统继续打分，改变评分相同的情况 Meta-level 一个推荐系统的输出作为另一个推荐系统的输入 reference: [1] wikipedia, Recommender system https://en.wikipedia.org/wiki/Recommender_system ","date":"2023-08-04","objectID":"/posts/recsys-summary/:0:0","series":null,"tags":["Mechine Learning"],"title":"推荐系统简单介绍","uri":"/posts/recsys-summary/#hybrid-recommender-systems"},{"categories":null,"content":" 需求我有两个外置屏幕，一个1K 23.8英寸，一个1K 21英寸，同时内置屏幕在1K和2K之间（2240x1400）但只有13英寸，所以需要这个配置： 内置屏幕：缩放比例150%，字体DPI 144 外置屏幕1：缩放比例100%，字体DPI 96 然后残念的是KDE并不支持同时连接不同显示器并设置不同的缩放比例和分辨率，所以我采用的设置是 接上外置屏幕时，关闭内置屏幕，设置缩放比例100%，字体DPI 96 断开外置屏幕时，设置缩放比例150%，字体DPI 144 然而每次设置，都需要打开KDE systemsetting，修改设置后注销，很麻烦，再加上我使用的主题问题（见末尾），需要在不同字体DPI下设置不同的window decoration，而设置window decoration只能修改配置文件。当接上或者断开外置屏幕时，需要改很多设置，非常麻烦！ 于是我就想，能不能写一个脚本，自动化这个过程呢？ ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:0:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#需求"},{"categories":null,"content":" 踩坑过程","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:0:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#踩坑过程"},{"categories":null,"content":" xrandr在google搜索 kde change scale command line，大部分内容都是xrandr，这东西并没有满足我的需求，使用xrandr --output DisplayPort-0 --scale 1.5x1.5后，发现它是将屏幕的帧缩放后输出，它会直接修改屏幕的逻辑分辨率，而我想要的是保持逻辑分辨率在物理分辨率（1K）的情况下，缩放显示内容 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:1:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#xrandr"},{"categories":null,"content":" kscreen-doctor又发现能够通过kscreen-doctor output.eDP.scale.1,5修改指定屏幕的缩放比例，然而并没有效果，查阅文档后发现这个命令只能对wayland起作用 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:2:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#kscreen-doctor"},{"categories":null,"content":" QT_SCREEN_SCALE_FACTORS仔细想了一下，可能缩放比例这个概念就不太正确，分辨率并没有问题，KDE只是一个桌面环境，在KDE修改了缩放比例后，它会以某种方式通知GUI程序，告诉他们应该采用什么样的缩放比例，然后GUI程序就能根据缩放比例调整按钮，文字，图标的大小，达到一个与屏幕大小观感协调的效果。查阅了archlinux wiki后，我发现了这个环境变量QT_SCREEN_SCALE_FACTORS bash ➜ ~ env | grep QT QT_AUTO_SCREEN_SCALE_FACTOR=0 QT_IM_MODULE=fcitx QT_SCREEN_SCALE_FACTORS=eDP=1;DisplayPort-0=1;DisplayPort-1=1; QT会遵循这个环境变量调整缩放比例，所以修改这个环境变量就能达到目的了，于是我把这个环境变量保存在~/.xprofile，但重新登录后发现没有起作用，发现环境变量并没有被修改 考虑了一下，应该是修改后，又被KDE修改了，因为缩放比例这个设置保存在KDE中，KDE会根据这个设置去修改底层的一些设置，所以还是要从KDE入手 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:3:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#qt_screen_scale_factors"},{"categories":null,"content":" 寻找KDE设置文件在网上搜索能知道KDE的配置文件都在~/.config/下，然而具体是哪一个，网上并不能搜索到。于是我先按照名字找到了~/.config/xsettingd/xsettingd.conf，我发现有一个选项在修改缩放比例后会改变 shell ➜ ~ cat ~/.config/xsettingsd/xsettingsd.conf Gdk/UnscaledDPI 147456 Gdk/WindowScalingFactor 1 Net/ThemeName \"Breeze\" Gtk/EnableAnimations 1 Gtk/DecorationLayout \"icon:minimize,maximize,close\" Gtk/PrimaryButtonWarpsSlider 0 Gtk/ToolbarStyle 3 Gtk/MenuImages 1 Gtk/ButtonImages 1 Gtk/CursorThemeSize 24 Gtk/CursorThemeName \"breeze_cursors\" Net/IconThemeName \"Win11\" Gtk/FontName \"Noto Sans, 8\" 我发现Gdk/UnscaledDPI这个选项，当缩放比例是100%时为98304，当缩放比例为150%时为147456，而Gdk/WindowScalingFactor这个选项并不会改变，猜测它就是xrandr中的scale选项，于是我尝试修改这个选项，发现也没有起作用。 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:4:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#寻找kde设置文件"},{"categories":null,"content":" 监控读写文件根据我的猜想，在KDE修改设置后，重新登录或者重启就能够生效，一定是把修改保存到了文件，然后启动的时候根据配置文件来设置一些选项，于是我就考虑监控文件读写，进而找到配置文件 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:5:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#监控读写文件"},{"categories":null,"content":" 通过文件修改时间监控文件写入文件写入后，文件的修改时间会更新，于是我利用find命令查找文件修改时间满足一个范围内的文件 shell ➜ ~ #!/bin/bash # 定义要监测的目录 directory=~/.config # 转换路径为绝对路径 directory=$(realpath \"$directory\") # 获取脚本启动时的时间戳 script_start_time=$(date +%s) # 创建一个关联数组来存储文件的修改时间 declare -A mod_times while true; do # 使用find命令查找目录下所有在脚本启动后被写入的文件 while IFS= read -rd '' file; do current_mod_time=$(stat -c %Y \"$file\") # 获取文件的修改时间是否在脚本启动之后 if [ \"$current_mod_time\" -gt \"$script_start_time\" ]; then # 如果文件在之前的记录中不存在或修改时间不同，则输出文件路径 if [[ ! \"${mod_times[$file]}\" || \"${mod_times[$file]}\" -ne \"$current_mod_time\" ]]; then echo \"文件已被修改：$file\" mod_times[\"$file\"]=$current_mod_time fi fi done \u003c \u003c(find \"$directory\" -type f -print0) sleep 1 # 每秒检查一次done 启动这个脚本，然后打开KDE systemsetting，修改缩放比例，找到一些文件被修改了，其中有~/.config/kcmfonts 它的内容如下 shell ➜ ~ cat ~/.config/kcmfonts [General] forceFontDPI=0 根据文件的修改时间，文件名的提示，还有文件内容的提示，只需要修改这个配置文件，就能达到修改字体DPI的目的 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:5:1","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#通过文件修改时间监控文件写入"},{"categories":null,"content":" 更简单的做法在reddit上看到了另一个做法，修改设置后按照修改时间对文件进行排序，找到最新修改的文件。这个方法确实很简单，我找到了~/.config/kdeglobals这个文件，而且非常巧妙的是，它有一段内容为 text [KScreen] ScaleFactor=1.5 ScreenScaleFactors=eDP=1;DisplayPort-0=1;DisplayPort-1=1; 根据这个group名和key名，可以确定ScaleFactor就是最终的答案了 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:5:2","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#更简单的做法"},{"categories":null,"content":" 修改配置文件最开始我使用sed修改文件，缺点就是 写sed很麻烦 担心改错，所以最开始不敢写回文件 保存修改很麻烦，需要写入一个临时文件，然后再把临时文件重命名为原文件 在reddit上看到有一个命令是kwriteconfig5，是KDE提供的用来修改那些’hidden’（没有提供GUI配置选项）的配置选项，它明显比直接修改文件要方便而且安全 要修改缩放比例，只需要kwriteconfig5 --file ~/.config/kdeglobals --group KScreen --key ScaleFactor 1.5 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:6:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#修改配置文件"},{"categories":null,"content":" 命令行注销也许是X11或者QT的缺陷，修改了缩放比例和字体DPI后，只能对新启动的应用生效，所以通常会注销然后重新登录，所以脚本修改这些设置后，也应该注销 然而这个注销就麻烦了，命令行，注销，一看到这两个词，我就在想，这不就是一个Ctrl+D或者exit就解决的问题吗。然而，这个是ssh会话中使用的，而我想要注销的应该是桌面会话 在网上找到了一些注销方法，有注销X会话的，直接让屏幕卡住了，我的猜想是，X是GUI的底层，而KDE作为桌面环境明显在它之上，也就是说应该注销KDE的会话 在网上找到了这个方法qdbus org.kde.ksmserver /KSMServer logout 0 0 0，非常有用，是通过类似进程间通信的方式通知KDE注销，跟手动注销的功能完全一模一样 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:7:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#命令行注销"},{"categories":null,"content":" 检测外置屏幕连接状态脚本需要检测现在使用的是什么屏幕，然后作出不同的设置 为了简单，我就只检测屏幕连接的数量，如果连接的屏幕数量为2，就认为外置屏幕已经连接，为1就认为外置屏幕已经断开 脚本如下 shell xrandr --listactivemonitors | awk '/Monitors:/ {print $2}' ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:8:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#检测外置屏幕连接状态"},{"categories":null,"content":" 最终成果 shell #!/usr/bin/bash SCALE=$(xrandr --listactivemonitors | awk '/Monitors:/ {print $2}') THEME_CONFIG=/home/arch/.local/share/aurorae/themes/Win11OS-dark/Win11OS-darkrc if [ \"$SCALE\" -eq 1 ]; then kwriteconfig5 --file /home/arch/.config/kdeglobals --group KScreen --key ScaleFactor 1.5 kwriteconfig5 --file /home/arch/.config/kcmfonts --group General --key forceFontDPI 144 cp \"$THEME_CONFIG-150\" \"$THEME_CONFIG\" echo \"one monitor connected, scaling to 150%\" elif [ \"$SCALE\" -eq 2 ]; then kwriteconfig5 --file /home/arch/.config/kdeglobals --group KScreen --key ScaleFactor 1 kwriteconfig5 --file /home/arch/.config/kcmfonts --group General --key forceFontDPI 96 cp \"$THEME_CONFIG-100\" \"$THEME_CONFIG\" echo \"two monitors connected, scaling to 100%\" fi sleep 1 # loginctl terminate-session $XDG_SESSION_ID # qdbus org.kde.KWin /Session org.kde.KWin.Session.quit qdbus org.kde.ksmserver /KSMServer logout 0 0 0 运行这个脚本，就能做到自动化设置了 KDE窗口超大外边距 参考reddit和github issue,这其实是主题在字体高DPI时的一个bug，解决办法就是修改主题的配置文件，我使用的win11 dark主题，配置文件在~/.local/share/aurorae/themes/Win11OS-dark/Win11OS-darkrc，修改 text PaddingTop=32 PaddingBottom=76 PaddingRight=47 PaddingLeft=47 这四个值，就能控制窗口的外边距 这个问题，最麻烦的就是，它并没有提供GUI的修改方式，只能通过配置文件来修改，所以定位问题相当麻烦 此外在150%缩放比例下修改主题配置后，切换到100%缩放比例下，发现窗口边距直接挤压到窗口内部了，非常难看。。。。 解决办法就是，分别在150%缩放比例和100%缩放比例下修改主题配置，然后在脚本中根据缩放比例来选择不同的配置文件，这样就能解决这个问题了 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:0:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#最终成果"},{"categories":null,"content":" 总结不得不说linux桌面真是够折腾的，也许搞了半天，只不过是实现一个windows早就有的功能。linux桌面真不适合个人用户使用。不过，linux是自由的，windows是商业的，专有的，这注定了大部分人会选择windows，而linux因为市场小，发展更慢，桌面体验肯定是不及windows的（如果商业软件体验都不如自由软件，那么商业软件怎么存活？）。虽然折腾桌面很麻烦，但确实方便了不少。使用linux是自由的，桌面哪里看不顺眼都能改，甚至还能换桌面环境和窗口管理器，还能自由选择X11和wayland，而用windows只能微软喂什么就吃什么。小小的自由的代价，还是能接受的 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:0:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#总结"},{"categories":null,"content":"箭头函数和普通函数中的this js const obj = { name: \"Alice\", ptr:this, sayName: function () { console.log(this) }, sayNameArrow: () =\u003e { console.log(this) } }; const sayName = obj.sayName; const sayNameArrow = obj.sayNameArrow; obj.sayName(); sayName(); obj.sayNameArrow(); sayNameArrow(); 输出为 text {name: 'Alice', ptr: Window, sayName: ƒ, sayNameArrow: ƒ} demo1.js:5 Window {window: Window, self: Window, document: document, name: '', location: Location, …} demo1.js:8 Window {window: Window, self: Window, document: document, name: '', location: Location, …} demo1.js:8 Window {window: Window, self: Window, document: document, name: '', location: Location, …} 可见： 普通函数的this指向调用它的对象，如果在obj上调用它，既obj.sayName()，那么this就指向obj，如何在全局作用域调用它，既sayName()，那么this就指向全局对象window 箭头函数不提供this，它的this是捕获外部的this，在此处就相当于是捕获了obj.ptr，而obj内的this指向的是obj所在的作用域，也就是全局作用域，所以obj.sayNameArrow()和sayNameArrow()的this都指向全局对象window 如果尝试打印obj.ptr，会发现它在浏览器中就是window，也就是全局对象 ","date":"2023-07-16","objectID":"/posts/this-in-js/:0:0","series":null,"tags":["JS"],"title":"JS中的this","uri":"/posts/this-in-js/#"},{"categories":null,"content":"C++11后引入了右值引用等特性，用来支持移动语义和完美转发，在了解右值引用前，需要了解一些前置的概念 左值(lvalue) 左值字面意义是在等号左边的值，左值是寻址的，具名的，有标识符的 有一个特点是，所有声明的变量都是左值 右值(rvalue) 右值字面意义是在等号右边的值，右值不可寻址，不具名 具体而言： 一个整数字面量是右值，因为它不对应一个内存存储位置，在汇编中，它存在于指令中的立即数字段 一个临时对象是右值，临时对象是为了写连续的表达式而被编译器支持的，当有例如func(obj())时，首先建立一个obj对象，这个对象没有名字，它实际上有一个对于的内存存储位置，但在这行代码执行完后就会被销毁，所以它叫做临时对象 cpp对临时对象有一个限制，因为临时对象是马上就会被销毁的，所以对临时对象的修会被抛弃 fn(int a) 可以用fn(a)和fn(1)调用，但是会造成复制 fn(int \u0026a)不可以用fn(1)调用，因为cpp认为int\u0026是允许修改的，而如果修改一个字面量，因为找不到它的内存存储位置，所以无法修改 fn(const int\u0026 a)可以用fn(1)调用，因为fn通过const关键字保证自己不会修改临时对象，所以允许传入字面量 ","date":"2023-05-29","objectID":"/posts/rvalue-reference/:0:0","series":null,"tags":["C/C++"],"title":"右值引用","uri":"/posts/rvalue-reference/#"},{"categories":null,"content":" 左值引用左值常常被称为是变量的别名，为什么呢？ 根据左值的概念，可以确定 cpp int a = 1; int\u0026 b = a; b = 2; std::cout \u003c\u003c a \u003c\u003c std::endl; a = 3; std::cout \u003c\u003c b \u003c\u003c std::endl; 从抽象的角度来看，a，b具有响应式的关系，修改一个，另一个也会改变 但实际上，a，b是对同一个地址的引用，换句话来说，a，b ‘underlying’ 的对象只有一个，这里的对象并不是面向对象的对象 反汇编的结果也能证实这一观点 text int a = 5; 1170: c7 45 e4 05 00 00 00 movl $0x5,-0x1c(%rbp) int \u0026b = a; 1177: 48 8d 45 e4 lea -0x1c(%rbp),%rax 117b: 48 89 45 e8 mov %rax,-0x18(%rbp) 可见，b其实跟*(\u0026a)是同义的，而我们知道，*和\u0026效果刚好是相反的，也就说，b和a是同一个东西，这代表”b是a的别名“，也可以得出\u0026b和\u0026a是同一个东西，这代表”b和a ‘underlying’的对象是同一个“ 当左值引用作为函数参数传递时，在汇编层面上，实际上传递的是地址 左值引用的初衷也是简化指针的使用，左值引用具有指针的优点：能在函数内修改外部的值，又规避了指针的缺点：错误的指针运算会导致野指针，也可以认为它是受约束的指针 ","date":"2023-05-29","objectID":"/posts/rvalue-reference/:0:0","series":null,"tags":["C/C++"],"title":"右值引用","uri":"/posts/rvalue-reference/#左值引用"},{"categories":null,"content":" 右值引用当自己动手实现一个栈类时，会遇到这个问题 cpp Object obj; vector.push(obj); 当push的定义为push(Obeject obj)时，会造成复制行为 当push的定义为push(Object\u0026 obj)时，虽然可以避免复制，但是又会产生一个新的问题 cpp void function(Vector\u0026 vector){ Object obj; vector.push(obj); return； } 这时，由于obj对象是分配在栈上的，当函数退出时，栈帧被清空，obj对象也就不存在了，然而vector还保留着对obj对象的引用 这种情况其实经常发生，它表现了资源移动时的矛盾：又要避免复制，又要避免引用的对象提前销毁 一个简单的方法是使用new，在堆上构造obj，这样obj的生命期就足够长，能够避免obj提前被销毁 然而new后还需要delete，而new和delete不在同一个上下文中，非常容易忘记delete 这时我们就会想，有没有一个方法能够适当延长obj对象的生命期，又能让他自动销毁呢？ 答案就是右值引用了，push定义为push(Object\u0026\u0026 obj)时，编译器会延长obj对象的生命期，在这个例子中，会采用返回值优化（Return Value Optimization, RVO）或命名的返回值优化（Named Return Value Optimization, NRVO），通过把obj这个对象构造在调用者的栈上，避免退出函数时obj对象被销毁，从而延长了obj对象的生命期 下面这个例子进一步说明了右值引用延长了临时对象的生命期 cpp #include \u003ciostream\u003e class Object { public: Object() { std::cout \u003c\u003c \"Object constructed\" \u003c\u003c std::endl; } ~Object() { std::cout \u003c\u003c \"Object destroyed\" \u003c\u003c std::endl; } }; void processObject(Object\u0026\u0026 obj) { std::cout \u003c\u003c \"Processing object\" \u003c\u003c std::endl; // 对临时对象进行处理，这里只是简单地输出信息} int main() { Object\u0026\u0026 ref = Object(); // 将临时对象绑定到右值引用 std::cout \u003c\u003c \"Before function call\" \u003c\u003c std::endl; processObject(std::move(ref)); // 通过右值引用传递临时对象 std::cout \u003c\u003c \"After function call\" \u003c\u003c std::endl; return 0; } 编译后输出为 text Object constructed Before function call Processing object After function call Object destroyed 右值引用会延长临时对象的生命期直到右值引用绑定的对象的生命期结束 回到之前的例子，如果一个函数又要接收左值作为参数，又要接受右值作为参数，可以用fn(int\u0026\u0026 a)，同时能够在函数里修改a，但是对a作出的修改最终都会被抛弃 为什么对a作出的修改都会被抛弃呢？ 因为右值是不具名的，即使它被改变了，也没有任何方法能够访问到它 cpp #include \u003ciostream\u003e using namespace std; void fn(int \u0026\u0026 a){ while(a\u003e0){ cout \u003c\u003c a \u003c\u003c endl; a--; } } int main(){ fn(5); return 0; } 输出为 text 5 4 3 2 1 这个例子可能非常反直觉，当执行a--时，肯定有一个内存存储位置被赋值了，但是这个位置在哪里？ 反汇编后结果如下 text int main(){ ... fn(5); 11c4: c7 45 f4 05 00 00 00 movl $0x5,-0xc(%rbp) 11cb: 48 8d 45 f4 lea -0xc(%rbp),%rax 11cf: 48 89 c7 mov %rax,%rdi 11d2: e8 82 ff ff ff call 1159 \u003c_Z2fnOi\u003e 编译器居然为我们分配了一个变量！ 汇编代码等效为 cpp int x = 5; fn(x); 如果把fn修改为void fn(int a)，相应的反汇编结果为 text fn(5); 118e: bf 05 00 00 00 mov $0x5,%edi 1193: e8 b1 ff ff ff call 1149 \u003c_Z2fni\u003e ","date":"2023-05-29","objectID":"/posts/rvalue-reference/:0:0","series":null,"tags":["C/C++"],"title":"右值引用","uri":"/posts/rvalue-reference/#右值引用"},{"categories":null,"content":" MATLAB数值求解微分方程所谓数值求解，也就是无法获得解的方程，只能获得y(x)函数在x取值范围内的近似值 所有MATALB的DOE solver都可以解决形如$\\frac{\\mathrm{d}y}{\\mathrm{d}t}=f(t,y)$的微分方程，所以很多时候需要把待求解微分方程化成这种形式，这种形式有几种特点 导数在等号左边 只有两个变量 导数只有一阶 不过实际上，一些不满足这种形式的微分方程也可化成这种形式 ","date":"2023-05-26","objectID":"/posts/matlab-calculus/:1:0","series":null,"tags":["科学计算"],"title":"MATLAB微积分","uri":"/posts/matlab-calculus/#matlab数值求解微分方程"},{"categories":null,"content":" 一阶微分方程数值求解$$ y^{’} = \\frac{x\\sin x}{\\cos y} $$ 这个微分方程形式非常好，可以直接拿来求解 使用ode45函数，x的取值范围为$[0,1]$，$y(0)=0$,取初值为0 先定义微分函数 matlab function ydot = fn(x, y) ydot = x * sin(x) / cos(y); end 然后使用ode45求解 matlab [x, y] = ode45(@fn, [0,1], 0); x向量的每一列都对应y向量的每一列 然后用这个微分方程的解析解与数值解做比较 matlab [x, y] = ode45(@fn, [0,1], 0); subplot(1,2,1); plot(x, y); x = 0:0.01:1; y = asin(sin(x)-x.*cos(x)); subplot(1,2,2) plot(x, y); function ydot = fn(x, y) ydot = x * sin(x) / cos(y); end 结果如下 ","date":"2023-05-26","objectID":"/posts/matlab-calculus/:1:1","series":null,"tags":["科学计算"],"title":"MATLAB微积分","uri":"/posts/matlab-calculus/#一阶微分方程数值求解"},{"categories":null,"content":"ranger是linux的一个终端文件管理器 ，它的feature有 vi按键绑定 与shell环境完美结合，可以使用各种shell工具 在tty上也能工作 像vim一样的可扩展性 本文是为了帮助我记忆一些ranger常用的功能而写的 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#"},{"categories":null,"content":" 文件树中导航h,j,k,l同vi按键绑定 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#文件树中导航"},{"categories":null,"content":" 删除dD 删除 dT 移动到回收站 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#删除"},{"categories":null,"content":" 重命名a或A重命名，自动移动光标到扩展名前，默认行为是不修改扩展名 cw也可以重命名，这个按键在vim中代表改变单词（change word）,与a的区别是，a修改文件名是在原文件名的基础上修改的，而cw要输入完整的文件名 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#重命名"},{"categories":null,"content":" 历史导航一般的文件管理器往往有一个左右的箭头，代表回到之前的目录/回到之前离开的目录，或者更简单点，类似于浏览器的历史导航功能 H或L在历史中导航，同vi按键绑定 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#历史导航"},{"categories":null,"content":" 复制y，按键绑定同vi，表示yank 复制，接下一个按键才能表示一个具体操作 yy 复制文件，如同vim的yy表示复制一行 yn 复制文件名，即yank name y. 复制不带扩展名的文件名，即 yank name before . yp 复制文件路径 即yank path 另外， dd代表剪贴，也有复制的功能 与其他文件管理器不同的是，ranger维护一个复制缓冲区，当已经复制一些文件后，可以向复制缓冲区中添加或删除文件 ya 向缓冲区中添加文件 yr 将文件从缓冲区中删除 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#复制"},{"categories":null,"content":" 粘贴pp 粘贴一个已经复制的文件到当前目录，同vim按键绑定 po 粘贴并覆盖，即paste and overwrite 当出现重名文件时，会自动修改文件名 使用shell复制时，往往会遇到这种情况：复制大文件时，会阻塞终端，花费时间很长，而且没有进度条 而ranger可以在后台复制大文件，不阻塞当前操作，并且会在底栏显示任务进度 可以输入w查看ranger在后台进行的任务 pP和pO对应pp和po，但是会在后台完成 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#粘贴"},{"categories":null,"content":" 多tab众所周知有一个操作系统的默认文件管理系统在过去一直没有tab栏的功能，跨目录复制文件时，常常需要打开两个窗口 alt+$i 表示打开第$i个tab，$i可以是数字1-9，还有两个特殊的按键 alt+l 表示移动到上一个tab 即 left tab alt+r 表示移动到下一个tab 即 right tab ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#多tab"},{"categories":null,"content":" 查看文件元数据一般的文件管理器常常有查看文件创建日期，大小的功能，但是往往还有所不足，例如 目录的大小往往不显示（需要花费时间统计） 文件的权限，所有者往往隐藏在属性一栏里 文件的种类往往要通过扩展名判断 ranger作为一个神级文件管理器，这些功能自然都是有的 对于文件，会在文件名的右侧显示出大小，对于文件，默认显示4K（因为linux的目录是一个抽象的文件，它占用一个block，一个block大小是4K，用来存储目录的元数据） 可以用du命令统计文件大小，等效于执行du --max-depth=1，也可以用dU，会将du的输出按照大小排序 ranger的底栏会显示当前文件的权限（rwx），所有者/组，大小，上次的修改日期，当前目录的所有文件大小总和，当前文件所在的磁盘的剩余空间，当前屏幕占所有内容的进度（类似于vim显示光标在文本中的百分比位置） 类似于shell，文件会被高亮显示，可以根据颜色快速区分目录，图片，压缩包，适配，可执行，软链接等等 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#查看文件元数据"},{"categories":null,"content":" 快速导航一般的文件管理器往往在左侧有一些常用的位置，可以快速到达，ranger也可以快速到达一些常用的位置 g即go，可以用来快速到达一个位置 gh 即go home 相当于执行cd ~，这应该是linux用户最常用的功能 gp 即go /tmp，快速到达/tmp目录 gi 相当于执行 fm.cd('/run/media/' + os.getenv('USER'))，这个目录是用来mount用户的外接存储设备的，U盘，机械硬盘都会被mount到这里 gg和 G 类似与vim的按键绑定，快速到达当前目录的开头和结尾 还有g/,ge,go等等，但是使用次数比较少，没有必要记忆 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#快速导航"},{"categories":null,"content":" 打开shell在图形化的文件管理器中寻找文件时，往往需要打开shell输入命令，一般的文件管理器都有打开shell的功能，例如Windows的Explore可以Shift+右键可以在右键菜单中看到Open in Terminal，而KDE的dolphin甚至可以在下方打开一个pannel，随时使用shell 要快速执行一个shell命令，可以输入!或s在底栏输入shell命令，但是这种方式不会返回任何输出（实际上，当退出ranger后就能看到之前shell命令的输出） 为了获得输出，可以输入S，会打开一个shell，要退出这个shell只需要像一般的终端一样输入exit或按下Ctrl+D，会返回到ranger ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#打开shell"},{"categories":null,"content":" 打开文件很多文件管理器都有一个功能，就是打开文件，比如在Windows上双击一个扩展名为txt的文件，就会用记事本打开它，但是一般的文件管理器提供的这种功能往往有所不足，比如 文件无法预览 文件类型未知 要用其他方式打开文件，往往需要打开一个二级菜单 而ranger利用linux的生态巧妙地解决了这三个问题 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#打开文件"},{"categories":null,"content":" 文件预览预览就是在不打开文件的情况下（不使用默认软件打开它）快速查看文件内容 在windows上实现文件预览，可以打开Explore的预览功能，但是这种功能实际使用中比较鸡肋，因为它只能预览极少类型的文件（例如txt），而且还会占用窗口很大的空间 实际上，日常使用中遇到的文件类型是非常复杂的，比如说纯文本的文件 txt 各种语言的源文件，例如c,cpp,h,py,java,js,html,css,cs… 数据交换文件，例如json, xml, scv… 配置文件,例如conf, ini, cfg, yaml… 日志文件，例如log,out等 没有扩展名的纯文本 各种各样编码方式的纯文本 可见纯文本文件的类型就有非常多种，而不同纯文本文件的用途不同，期望的显示方式也不同，比如说 大部分文件都只需要开头十几行，不需要读取完整的文件造成过多的磁盘访问浪费性能 各种语言的源文件、配置文件、数据交换文件最好能有语法高亮，并使用等宽字体显示 日志文件，最好高亮显示Warning等信息 即使没有扩展名，也最好能够识别出它是纯文本并预览 另外，还有很多各种各样的文件类型需要使用不同的预览方式，例如 office的doc/docx, ppt/pptx, xls/xlsx文件快速预览 图片jpg, png, svg等等的预览 html，md文件的预览 最特殊的，二进制文件，类型非常多，常见的有 各种平台上的可执行 各种平台上的动态库，静态库 数据文件（数据格式有约定） 压缩文件，存档文件 … 可见种类实在是太多了，很多文件管理器往往只能做到预览一部分的文件 ranger通过简单的配置就能做到识别文件并预览大部分的文件，可以通过修改%rangerdir/data/scope.sh来启用纯文本文件以外的预览（预览二进制） scope.sh会自动寻找已经安装的其他软件并使用它，比如说 file 用于检测文件类型 chardet 一个python的模块，用于检测文件编码方式 python-bidi 用于显示从右到左书写的文字，例如阿拉伯语 img2txt 用于显示图片的ASCII字符画 w3mimgdisplay / ueberzug / mpv / iTerm2 / kitty / Terminology等等，用于图片预览 convert 是imagemagick工具的一部分，用来自动旋转图片并预览svg图片 ffmpegthumbnailer 用于显示视频的封面（缩略图） highlight / bat / pygmentize 用于代码的语法高亮 atoll / bsdtar / unrar / unzip / zipinfo / sed / tar / 7z 用来预览存档和压缩文件 lynx / w3m / elinks 用来预览html文件（渲染html） pdftotext / mutool预览pdf的文本，pdftoppm把pdf转成图片预览 djvutxt 预览文本类型的DjVu文件, ddjvu把DjVu文件转成图片预览 calibre / epub-thumbnailer 预览epub文件（电子书文件格式）的图片 transmission-show 预览BitTorrent文件（种子文件）的信息 mediainfo / exiftool 预览媒体文件 odt2txt 预览Open Document（开放文档格式，是文档格式的标准，office的word, ppt, excel也支持这些格式所以能预览） python / jq 预览json文件 fontimage 预览字体文件 这种机制的优点就是，只要有可以用的工具，ranger就会使用它来预览，而不需要任何额外配置，如果没有，ranger也能正常工作，只是少一个功能 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:1:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#文件预览"},{"categories":null,"content":" 打开文件当光标在一个文件时，可以输入l使用默认的方式打开一个文件，这个操作很符合vim的操作的直觉 也可以输入r，它会弹出一个打开方式的列表，可以输入数字选择打开的方式，也可以直接回车代表默认方式 此外，当光标处于目录时，输入l会进入这个目录，而输入r可以选择一个方式打开这个目录此时可以选择用dolphin打开这个目录 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:2:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#打开文件-1"},{"categories":null,"content":" 高级功能","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#高级功能"},{"categories":null,"content":" 过滤linux的shell在文件系统中导航时，使用tab进行补全是很方便的，比如说一个文件特别长，我不想完整输入，只需要输入前面几个字符，再按tab，就能自动补全了，这也是shell好用的一个重要原因 类似地，ranger也有根据文件名的前几个字符快速确定文件的功能 输入f，开始查找文件，只需要输入文件的一部分字符，ranger会自动把光标移动到搜索到的文件上，如果能够唯一确定文件，ranger会直接打开它（打开文件或目录），熟练使用这个功能，可以快速在文件树中导航！ 如果f查找的结果不唯一，可以用n到达下一个搜索结果，用N到达上一个搜索结果 如果f搜索的结果有很多，跳转起来也是相当麻烦的，而且有些情况下，需要查看一类文件，例如 找到同一扩展名的文件 找到命名具有同一规律的文件 这种时候可以输入zz，开启模糊查找模式，它跟f的区别就是，会过滤掉不匹配的结果，而且不会自动进入目录 有了zz和f这两个命令，就能快速在一个十分复杂的文件系统中导航 此外，shell还可以在任何一个地方使用cd命令快速到达另一个地方，而不管这两个地方相隔多远，ranger也可以直接输入cd，然后输入路径，就能到达指定的路径，这个功能就像g这个按键一样，可以迅速离开当前位置而不经过它的上级目录 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:1:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#过滤"},{"categories":null,"content":" 占坑","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:2:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#占坑"},{"categories":null,"content":"最近遇到了一个函数传参造成的问题，于是来稍微研究一下这个东西 什么是函数传参顺序？ 一个简单例子 c bar(foo(1), foo(2)); 为了准备bar函数需要的参数，需要先执行foo函数，但是有两个foo函数，应该先执行哪个？ 在一般情况下，先执行哪一个并没有什么影响，然而在一些特殊情况下，我们可能非常在意foo函数执行的顺序 比如说 foo函数内部做出了访问文件系统，发起网络请求等对外界造成影响的操作 foo函数内部有状态变量（类似状态机），每次执行foo函数时，会改变内部状态，foo函数的输出也取决于内部状态 ，一个最简单的例子就是foo函数表示弹栈操作 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:0:0","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#"},{"categories":null,"content":" 为了研究函数传参的顺序到底是从左到右还是从右到左，我做了以下实验首先考虑到函数传参的顺序实际上是调用者与被调用者约定的一种数据交换格式，函数的参数可以借由寄存器传递， 也可以把参数埋在调用者的栈内，也可以复制到被调用者的栈内，所以不必分析哪一个foo函数先执行，只需要 分析机器指令准备参数的顺序 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:1:0","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#为了研究函数传参的顺序到底是从左到右还是从右到左我做了以下实验"},{"categories":null,"content":" C首先新建文件test.c，内容如下 c #include \u003cstdio.h\u003e void fn(int x, int y) { printf(\"%d %d\", x, y); } int main() { fn(1, 2); return 0; } 用gcc编译，然后查看反汇编代码 shell gcc -g ./test.c objdump -S ./a.out main函数的反汇编代码如下 text 0000000000001166 \u003cmain\u003e: 1166: 55 push %rbp 1167: 48 89 e5 mov %rsp,%rbp 116a: be 02 00 00 00 mov $0x2,%esi 116f: bf 01 00 00 00 mov $0x1,%edi 1174: e8 c0 ff ff ff call 1139 \u003cfn\u003e 1179: b8 00 00 00 00 mov $0x0,%eax 117e: 5d pop %rbp 117f: c3 ret 可见自定义的fn函数的传参顺序是从右到左 还可以看出，2被放入了esi，1被放入了edi fn函数的反汇编代码如下 text 0000000000001139 \u003cfn\u003e: 1139: 55 push %rbp 113a: 48 89 e5 mov %rsp,%rbp 113d: 48 83 ec 10 sub $0x10,%rsp 1141: 89 7d fc mov %edi,-0x4(%rbp) 1144: 89 75 f8 mov %esi,-0x8(%rbp) 1147: 8b 55 f8 mov -0x8(%rbp),%edx 114a: 8b 45 fc mov -0x4(%rbp),%eax 114d: 89 c6 mov %eax,%esi 114f: 48 8d 05 ae 0e 00 00 lea 0xeae(%rip),%rax # 2004 \u003c_IO_stdin_used+0x4\u003e 1156: 48 89 c7 mov %rax,%rdi 1159: b8 00 00 00 00 mov $0x0,%eax 115e: e8 cd fe ff ff call 1030 \u003cprintf@plt\u003e 1163: 90 nop 1164: c9 leave 1165: c3 ret fn函数把edi和esi的值复制到栈帧中，然后再复制到寄存器中，可以确定先准备了2，再准备了1 猜测0xeae(%rip)存放着字符串\"%d %d\"的值，进入gdb查看这个地址的值 text (gdb) si 0x0000555555555156 3 void fn(int x, int y) { printf(\"%d %d\", x, y); } (gdb) p (char*)($rip+0xeae) $22 = 0x555555556004 \"%d %d\" 所以可以确定，printf函数的字符串是最后一个被传入的，所以这个printf函数也是从右到左 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:1:1","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#c"},{"categories":null,"content":" Python新建一个test.py，内容如下 python import dis def fn(x, y): print(x, y) def main(): fn(1, \"2\") dis.dis(main) 在终端执行脚本 shell python ./test.py 结果如下 text 9 0 LOAD_GLOBAL 0 (fn) 2 LOAD_CONST 1 (1) 4 LOAD_CONST 2 ('2') 6 CALL_FUNCTION 2 8 POP_TOP 10 LOAD_CONST 0 (None) 12 RETURN_VALUE 可以看出自定义的fn函数是从左到右传参的 但是，python的函数传参实际上相当复杂，涉及到位置参数，默认参数，可变参数，关键字参数等等，具体传参顺序 还得看python解释器的实现 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:1:2","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#python"},{"categories":null,"content":" 占坑","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:1:3","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#占坑"},{"categories":null,"content":" 总结汇编的函数调用约定，占坑 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:2:0","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#总结"},{"categories":null,"content":"在linux使用shell时常常会遇到一些使用场景需要大量重复敲击按键，带来了一些麻烦，所以学会一些快捷键是 必备的，但是有些快捷键几乎没用，也没用记忆的必要 首先声明一点，重点是记住快捷键的功能，而不是快捷键的按键绑定，因为对于不同的终端模拟程序，这些功能基本都是 提供的，但是按键绑定可能有所不同(说的就是PowerShell)，另外有些终端是支持修改按键绑定的 以下的快捷键按键绑定都是标准的linux shell按键绑定，在Konsole上测试通过 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#实用的快捷键"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#快速跳转到命令的开头"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#发送eof"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#打断前台程序"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#暂停前台程序"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#控制屏幕输出"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#历史回溯"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#清空屏幕"},{"categories":null,"content":" 用处不大的快捷键 快速删除当输入一个很长的命令，突然发现需要先执行另外一个命令，这时有两个做法 Ctrl+C打断 Ctrl+U删除光标左边的全部字符串 Ctrl+U虽然可以根据光标删除，但是实际使用场景常常可以被Ctrl+C替代 移动光标的高级方式除了Ctrl+A，这些移动光标的方式基本都不常用 Ctrl+A 移动到命令行首 Ctrl+E 移动到命令行尾（end） Ctrl+F 前移一个字符（forward） Ctrl+B 后移一个字符（backward） … 还有很多这种命令，就不一一列举了 实际上Ctrl+左右箭头就能实现在词间移动，而且更加直观 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:2","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#用处不大的快捷键"},{"categories":null,"content":" 用处不大的快捷键 快速删除当输入一个很长的命令，突然发现需要先执行另外一个命令，这时有两个做法 Ctrl+C打断 Ctrl+U删除光标左边的全部字符串 Ctrl+U虽然可以根据光标删除，但是实际使用场景常常可以被Ctrl+C替代 移动光标的高级方式除了Ctrl+A，这些移动光标的方式基本都不常用 Ctrl+A 移动到命令行首 Ctrl+E 移动到命令行尾（end） Ctrl+F 前移一个字符（forward） Ctrl+B 后移一个字符（backward） … 还有很多这种命令，就不一一列举了 实际上Ctrl+左右箭头就能实现在词间移动，而且更加直观 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:2","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#快速删除"},{"categories":null,"content":" 用处不大的快捷键 快速删除当输入一个很长的命令，突然发现需要先执行另外一个命令，这时有两个做法 Ctrl+C打断 Ctrl+U删除光标左边的全部字符串 Ctrl+U虽然可以根据光标删除，但是实际使用场景常常可以被Ctrl+C替代 移动光标的高级方式除了Ctrl+A，这些移动光标的方式基本都不常用 Ctrl+A 移动到命令行首 Ctrl+E 移动到命令行尾（end） Ctrl+F 前移一个字符（forward） Ctrl+B 后移一个字符（backward） … 还有很多这种命令，就不一一列举了 实际上Ctrl+左右箭头就能实现在词间移动，而且更加直观 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:2","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#移动光标的高级方式"},{"categories":null,"content":" 关于复制因为Ctrl+C被拿去打断进程了，复制粘贴就变成了Ctrl+Shift+C和Ctrl+Shift+V，这确实带来了麻烦！ 但是考虑到这是linux的默认设置，如果修改了这个配置，在新机器上可能会不习惯，最终还是慢慢适应了 但是这个快捷键在跨应用复制的时候会带来不少困扰！（尤其是Ctrl+Shift+C在edge上也许表示复制元素，一旦按下 这个按键就会打开浏览器开发者工具） ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:3","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#关于复制"},{"categories":null,"content":"matplotlib 是python的可视化库，但是如果在matplotlib的图表中使用了中文， 会找不到中文字体而显示乱码，网上有很多教程解决这个问题，但是在我的linux上都不管用 经过不断尝试和google，终于找到了方法 可以随便选择能够选择中文的字体，但是要注意font family和字体名称的问题，以下以微软 雅黑为例 把msyh.ttc放到matplotlib的字体目录下 shell mv /path/to/msyh.ttc /path/to/matplotlib/mpl-data/fonts/ttf/ 其中第一个路径是微软雅黑字体文件的路径，对于linux来说，这个字体可以从网上下载 如果安装了这个字体可以在/usr/fonts下找到（用locate命令搜索, 见linux文件搜索神器 第二个路径是matplotlib安装的目录，可以执行以下代码找到这个目录 python import matplotlib print(matplotlib.matplotlib_fname()) 修改matplotlib配置文件 打开matplotlib的全局配置文件，会看到这段话 text ## This is a sample Matplotlib configuration file - you can find a copy ## of it on your system in site-packages/matplotlib/mpl-data/matplotlibrc ## (relative to your Python installation location). ## DO NOT EDIT IT! ## ## If you wish to change your default style, copy this file to one of the ## following locations: ## Unix/Linux: ## $HOME/.config/matplotlib/matplotlibrc OR ## $XDG_CONFIG_HOME/matplotlib/matplotlibrc (if $XDG_CONFIG_HOME is set) ## Other platforms: ## $HOME/.matplotlib/matplotlibrc ## and edit that copy. 这句话的意思就是，为了不污染全局配置，可以把这个配置文件复制到用户的配置目录下，单独为一个用户配置 shell cp /path/to/matplotlibrc ~/.config/matplotlib/matplotlibrc 然后用vim打开matplotlibrc，找到以下两行，取消注释改成这样 text font.family: Microsoft YaHei, sans-serif font.serif: Microsoft YaHei, DejaVu Serif # 此处把微软雅黑放到第一个位置 最关键的步骤，移除缓存 网上很多教程都有这一步：执行python代码 python from matplotlib.font_manager import _rebuild _rebuild() 但是我执行这个代码的时候出现了Import Error，也许是版本问题 为了强制重新生成字体缓存，可以删掉matplotlib的缓存 shell rm -rf ~/.cache/matplotlib rm -rf ~/.matplotlib/*.cache 搞定，至此可以放心的使用matplotlib了 ","date":"2023-04-02","objectID":"/posts/matplotlib-chinese-font/:0:0","series":null,"tags":["Linux","科学计算"],"title":"matplotlib在linux平台上显示中文的解决方案","uri":"/posts/matplotlib-chinese-font/#"},{"categories":null,"content":"使用Linux时，常常需要在文件系统中快速搜索到内容，比如说 在一个项目中需要快速找到一个文件的路径，需要按照文件名搜索出路径 想找某个文件，但是完全不知道它在哪里，需要全局搜索 在一个项目中想要搜索一个特定字符串的出现 ","date":"2023-04-01","objectID":"/posts/linux-file-search/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux搜索神器","uri":"/posts/linux-file-search/#"},{"categories":null,"content":" 需求1: 根据文件名搜索路径–find可以使用find命令，它是linux大多数发行版都自带的命令 shell find . -name \"filename\" 这个命令会在当前目录下递归搜索叫做filename的文件，但是这个文件名必须是完全匹配 如果只是知道文件名的大概，或者无法保证文件名完全一致，可以用正则匹配 shell find . -name \"filename.*\" 这个命令会搜索所有满足正则表达式filename.*的文件，但是注意，由于bash会将*解释为匹配的文件，必 须用双引号把括起来 至此这个命令足够日常使用了，但是有些情景就不好用了，例如完全不知道这个文件的路径，只知道它的名字，或许可 以这样 shell find / -name \"filename\" 这个命令会在根目录递归搜索所有文件，似乎能达到目的，但是它会去尝试读取一些系统文件和权限不足以访问的 文件 ，导致输出一大堆错误信息 ，为了避免错误输出淹没了查找结果的输出，可以给予高权限 shell sudo find / -name \"filename\" 但是这个命令其实相当危险！，作为超级用户，不应该给予它如此高的权限，这是没必要的，还可能有风险 而且由于linux实现的的文件系统是VFS(虚拟文件系统)，并不是所有文件的open和read操作都会在硬盘上生效， 比如说，访问/proc下的文件实际上是从内存中读取进程的相关信息，访问/dev下的文件实际上是尝试从 设备中读取数据，另外实际上你也会发现，即使给了最高的权限，还是有些文件无法被读取 很明显，我们想要搜索的文件常常都是用户文件，它的权限不高，所以没必要用这种方式，另外为了防止错误信息 淹没了查找结果，可以把错误信息丢掉 shell find / -name \"filename\" 2\u003e/dev/null 在shell中，2代表标准错误，同理0代表标准输入，1代表标准输出，\u003e代表重定向输出，/dev/null 是linux的空设备，它相当于一个无底洞，输出到/dev/null就相当于丢弃输出 虽然find命令很强大，但是如你所见，用它搜索文件有时候还是不好用 ","date":"2023-04-01","objectID":"/posts/linux-file-search/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux搜索神器","uri":"/posts/linux-file-search/#需求1-根据文件名搜索路径--find"},{"categories":null,"content":" 需求2:全局搜索文件–locatelocate可能需要自己安装，如 archwiki所说，locate命令是在预先建立好的文件系统 索引数据库中搜索，这可以大大加快速度（当用find全局搜索或者在机械硬盘中搜索时往往能体会到find的速度） locate的工作原理有点类似于Windows平台的everything， 但实际上locate可能胜过everything 第一次使用locate命令前需要先建立索引(需要root权限) shell sudo updatedb 然后直接搜索 shell locate \"filename\" 可以在全局查找文件，另外locate会考虑权限控制，只会显示用户可访问的文件，就不会出现在/proc和/dev 下搜索的情况 这个命令用来全局模糊搜索非常好用，因为locate默认把参数解释为正则匹配的partten 在日常使用的过程中可能会出现这个问题，locate输出的结果太多了，例如 shell locate python | wc 411629 411761 48329698 如上，用wc统计出有411629行，也就是有411629个匹配结果！ 让我们来看看为什么会有这么多结果，首先可以发现，如果一个目录名包括了python字符串，那么这个目录下所有文件 都会命中正则匹配！例如/home/arch/.cache/JetBrains/CLion2022.3/python_stubs/-548636620/PySide6 另外有些目录下的匹配结果是不需要的，比如说我只想看看我的电脑上有多少个python解释器， 那么~/.cache很有可能就是不需要的,那么如何避免这些情况呢？ 更加准确的描述方式 如果我只想找到python解释器的位置，那么python-stub还有python-websockets就是不满足的，可以 扩展正则语法的否定预查更加精准的匹配，然而这个情景下，用准确的文件名匹配更好 shell locate \"*/python\" 这个命令的意思是*匹配前的路径，python匹配文件名，这样就能精准匹配到名为python的文件 过滤不需要的信息 执行过一遍locate后我已经知道某些路径下的搜索结果是不需要的，例如我想过滤~/.cache下的所有结果 shell locate \"python\" | grep -v \".cache\" 这里用到了grep的反向匹配过滤掉~/.cache下的所有匹配结果，但是这么过滤后可能还是太多了，需要 进一步过滤，例如想要过滤python-websockets下的所有结果，通过查看grep的手册发现并没有反向匹配两种pattern的方法，这里可以利用linux shell的 强大之处 shell locate \"python\" | grep -v \".cache\" | grep -v \"python-websockets\" 利用最简单的概念和最简单的操作就能组合出非常复杂的流程，这体现出linux设计的优点，也体现了 最小惊讶原理，说实话 我第一次看到这种用法只吃惊了1秒！ ","date":"2023-04-01","objectID":"/posts/linux-file-search/:0:2","series":null,"tags":["Linux","Shell"],"title":"Linux搜索神器","uri":"/posts/linux-file-search/#需求2全局搜索文件--locate"},{"categories":null,"content":" 需求3:搜索文件内容–grep,ag,ack在VScode和jetbrain系IDE中都可以通过Ctrl+Sift+F在整个项目中搜索文件内容，linux的命令行也有对应的 工具grep和ag，但是grep的命令太长，所以这里暂时略过grep(因为我也不会) ag是The Silver Searcher的指代，tldr对ag的介绍是 {% blockquote %} Recursively search for PATTERN in PATH. Like grep or ack, but faster. {% endblockquote %} ag大多数发行版都没有自带，需要自己安装 shell sudo pacman -S the_silver_searcher 假设我想看一个python项目引入了哪些库，可以用ag搜索import语句 shell ag \"import\" ag默认使用正则表达式搜索，而且搜索速度非常快！ 搜索非常快的原因见github仓库 ","date":"2023-04-01","objectID":"/posts/linux-file-search/:0:3","series":null,"tags":["Linux","Shell"],"title":"Linux搜索神器","uri":"/posts/linux-file-search/#需求3搜索文件内容--grepagdelackdel"}]