[{"categories":null,"content":"最近在做毕设过程中遇到很多不方便的地方，突然想到使用端口转发去优化工作流程，于是写一篇文章介绍并总结端口转发的种种妙用 ","date":"2025-05-17","objectID":"/posts/port_fowarding/:0:0","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#"},{"categories":null,"content":" 用途展示 服务器无需安装 clash，使用 PC 上的 clash 实现服务器上科学上网 服务器上执行 adb 命令操纵 连接到 PC 的 android 设备 无屏幕无键鼠的 android 开发板无需接入屏幕键鼠，只通过一根数据线就能访问桌面并调试 ","date":"2025-05-17","objectID":"/posts/port_fowarding/:1:0","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#用途展示"},{"categories":null,"content":" 一条命令启动这条命令可以实现 服务器使用 PC 的 clash 科学上网 shell ssh -R server:8888:localhost:7890 -R server:5037:localhost:5037 user@server # 登录之后 export ALL_PROXY=\"http://localhost:8888\" ","date":"2025-05-17","objectID":"/posts/port_fowarding/:2:0","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#一条命令启动"},{"categories":null,"content":" 原理解释篇","date":"2025-05-17","objectID":"/posts/port_fowarding/:3:0","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#原理解释篇"},{"categories":null,"content":" server-client 软件架构许多软件都应用了 server-client 架构，例如 docker, adb, systemd, ssh 等等。archlinux wiki 将 daemon 描述为 any program that runs as a “background” process (without a terminal or user interface), commonly waiting for events to occur and offering services。简单来说就是 daemoon 没有 contorl terminal，大部分时间都在等待某个文件描述符产生事件。为什么要使用 server-client 的架构呢？我认为最直接的原因就是 server 的生命期与 client 的生命期不一样。例如 docker命令作为一个 cli，生命期结束于docker命令执行完毕进程退出，显然 dockerd 的生命期远大于docker的生命期。又例如 adb 在第一次执行时，会自动启动 adbd，我不了解 adb 的诸多细节，但大致原因也许就是 adbd 负责维护 PC 和 android 设备的连接，否则每次执行 adb 命令都要重新建立连接，这显然是不可接受的。 软件被分为 server 和 client 后，往往通过端口或者 unix socket 通信，其中通过端口通信是跨平台最友好的。因此许多 server-client 架构的软件都可以使用端口转发实现一些神奇的效果 ","date":"2025-05-17","objectID":"/posts/port_fowarding/:3:1","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#server-client-软件架构"},{"categories":null,"content":" 科学上网与魔法上网所谓魔法上网只是我随意编的词，从我学会科学上网后很长一段时间，我从来没有考虑过科学上网的原理是怎样的。clash 可以说是我使用时间最长的一个软件，几年来我也从来没有考虑过这个软件的原理是怎样的，所谓魔法上网是我对自己的调侃：不去了解背后的原理，出了问题不知道怎么解决，并将其归为玄学、魔法。 所谓科学上网或者魔法上网，本质是代理，能工作的最关键的原因是至今为止防火墙是以黑名单的方式工作的，也就是说仍有许多 ip 地址是防火墙未知并且不会拦截的，于是我们就能通过代理的方式利用尚未被屏蔽的服务器去访问已经被屏蔽的服务器。当然，如果哪天防火墙切换到了白名单模式，任何通过代理绕过防火墙的方法也会失效。 科学上网可以分为代理协议、代理客户端。代理协议的目的是伪装成正常流量以便通过防火墙， 代理客户端的目的是将特殊的代理协议转为 socks 代理协议、http 代理协议，这是因为 socks 和 http 是受支持最广的代理协议。常见的代理协议包括 VMess, ShadowSocks, ShadowSocketR, Trojan 等。常见的代理客户端有 v2ray, clash 系等 clash 是一个无 GUI 的代理客户端，有许多包装 clash 的 GUI，例如 clash for windows，clash verge 等，他们通过 clash 暴露的 external-controller 与 clash 通信，其中的 clash 往往被称作 clash 核心。 理解了常用的 clash GUI 由 GUI 和 clash 核心组成后，就能认识到任何 clash GUI 的目的都是更方便的操作 clash 核心，而 clash 核心最核心的特点就是规则。围绕规则能做很多事情，以我遇到的情况为例 常见的一条规则是对于国外的网站使用代理，但也有例外。例如 acm.org 的论文使用 ip 管控，也就是说虽然 acm.org 是国外的网站，但我必须直连才能使用学校的 ip 访问到论文，因此添加一条规则DOMAIN-SUFFIX,acm.org,DIRECT，这样就能正常访问 acm.org 了 常见的一条规则是 google 的域名使用代理，但也有例外。由于潜在的滥用风险（SPAM），机场往往屏蔽了 SMTP 和 IMAP 协议的流量，导致邮箱客户端无法连接到 Gmail。但很幸运 Gmail 的 imap 域名和端口在大陆是可以直连的，因此加上一条规则DOMAIN-KEYWORD,imap,DIRECT，就解决了困扰我很长时间的无法使用邮箱客户端收发 gmail 邮件的问题 通过以上的介绍，我们知道不论使用什么代理客户端，最终都会得到一个代理服务器，它运行着 socks 代理协议或 http 代理协议，对于 clash 来说，代理服务器默认运行在 http://localhost:7890，然后只需要将系统代理或软件代理设为 http://localhost:7890，就能科学上网了。 通常情况下代理服务器绑定到本地回环网络接口，也就是说只有本机可以访问。当然可以绑定到局域网网络接口，于是局域网内其他设备就能访问这个代理服务器。于是我有个初步的想法，假设 PC 的域名是 PC，服务器的域名是 server，在 server 上将代理设为 http://PC:7890, 是否就能让服务器使用 PC 上的代理服务器，也就是服务器使用 PC 上的 clash 科学上网了呢？ 理论上是可行的，但由于 server 往往在公网上而 PC 工作在层层 NAT 之后，server 是无法主动建立与 PC 的 tcp 连接的。我在做毕设中遇到的情况是，我使用 vpn 软件加入一个 服务器所在的 VLAN，然后通过 ip 访问服务器，但服务器和 PC 的 VLAN 中的 ip 在不同网段，而且服务器的路由表中也没有 PC 网段的路由记录，我猜原因是服务器运维认为这不需要而且不安全。由于以上原因，虽然我的 server 和 PC 在同一个 VLAN 但 server 仍然无法主动建立与 PC 的连接 ","date":"2025-05-17","objectID":"/posts/port_fowarding/:3:2","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#科学上网与魔法上网"},{"categories":null,"content":" ssh 隧道ssh 隧道就能间接的解决「server 仍然无法主动建立与 PC 的连接」这个问题，man 手册描述 ssh 为 ssh (SSH client) is a program for logging into a remote machine and for executing commands on a remote machine. It is intended to provide secure encrypted communications between two untrusted hosts over an insecure network. X11 connections, arbitrary TCP ports and Unix-domain sockets can also be forwarded over the secure channel. 通过 ssh 隧道，可以将 PC 的 7890 端口转发到服务器的 8888 端口，于是服务器访问 http://localhost:8888 时，数据包就会被转发到 PC 的 7890 端口，从而被 PC 的 clash 处理 ","date":"2025-05-17","objectID":"/posts/port_fowarding/:3:3","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#ssh-隧道"},{"categories":null,"content":" adb 与 adbdadb 也是 server-client 的架构。adb 在第一次启动时会自动启动 adbd，adbd 默认监听 5037 端口，adb 通过与 adbd 通信从而操纵 android 设备。于是我将本地的 5037 端口转发到服务器的 5037 端口，于是服务器上的 adb 就能与运行在 PC 的 adbd 通信，并操纵连接到 PC 的 android 设备。 这样做有什么用呢？因为我使用 rknn-toolkit2 做模型转换、模型性能分析等工作（模型运行在 android 设备），而 rknn-toolkit2 不支持 macos，于是我只能在 x64 架构的服务器上去做，但我不能物理接触到服务器，更不能将数据线插到服务器上。但使用端口转发，我近似实现了数据线插到服务器上的效果，从而简化了我的工作流 ","date":"2025-05-17","objectID":"/posts/port_fowarding/:3:4","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#adb-与-adbd"},{"categories":null,"content":" adb 端口转发做毕设很烦的一件事就是乱七八糟的线实在太多，一个 android 开发板上要接电源线、数据线用于调试、 AR 眼镜的 USB 数据线、接显示器的 HDMI 线、接鼠标的 USB 线。一堆线缠在一起让我心情非常烦躁。而且显示器只有一个，同时要么给 mac 用要么给 android 开发板用，又降低了我的工作效率。于是我就在想能不能通过 adb 把 android 的屏幕流式传输到 mac，经过一番研究后我发现有一个很简单的方法实现 首先在安卓开发版上运行 vnc server，然后用 adb 将 android 设备的 vnc 端口转发到 mac，于是 mac 就能通过 vnc viewer 访问 android 设备的桌面，具体操作如下 在 android 开发板上安装 droidVNC-NG，这一步可以在 mac 下载 app 然后用 adb install 命令安装。droidVNC-NG 可以运行 vnc server，然后通过 ip+端口或浏览器就能远程访问桌面。最方便的是它能够开机后自动启动 vnc 服务 给 android 设备接入显示器，设置并启用 droidVNC-NG，并打开开机自启 执行adb forward tcp:5901 tcp:5901，将安卓设备的 5901 端口转发到 mac 本地的 5901 端口 在 mac 使用 vnc viewer 登录远程桌面 macos 的 finder 自带了 vnc viewer，无需额外安装 vnc viewer 使用这样的方法，我不再需要接入显示器和键鼠，接线少了一半，工作流程变得非常流畅。指导毕设的学长评价说“我真是每天被线缠着，苦大仇深啊。” 那么 adb 端口转发有什么神奇的地方吗？在我看来就是 adb 连接提供了一个供 TCP 流量通行的隧道，而 adb 连接往下就是 USB 协议栈，仔细考虑一下就会觉得很神奇，TCP 流量跑在 USB 数据线里了，这也许就是计算机网络分层的魅力吧 一定需要 adb 端口转发吗？其实也不一定，因为校园网有 ap 隔离，导致我的手机、mac、笔记本电脑、android 开发板即使连接了校园网也无法相互通信，这在很长一段时间内都给我造成了麻烦。而用手机开热点一来无法固定 ip 二来手机拿远了就会断开。设想一下校园网没有 AP 隔离，我也许直接使用 android 开发板的 ip + vnc 端口就能访问远程桌面了。 不管怎么说，这个方案是目前我非常满意的方式，不需要记住任何 ip，每次插上数据线执行adb forward命令就能访问 android 桌面。在搞硬件的看来已经是非常方便了。 ","date":"2025-05-17","objectID":"/posts/port_fowarding/:3:5","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#adb-端口转发"},{"categories":null,"content":" 总结去研究日常工作中使用次数最多的软件，花费时间与精力探索如何善用工具优化工作流程，是一个绝对值得的投资 ","date":"2025-05-17","objectID":"/posts/port_fowarding/:4:0","series":null,"tags":null,"title":"端口转发的妙用","uri":"/posts/port_fowarding/#总结"},{"categories":null,"content":"这篇文章是三月中旬的我对二月以来流经头脑的随想的总结，可以说反映了二月以来我的精神状态 ","date":"2025-03-17","objectID":"/posts/thought-on-the-future/:0:0","series":null,"tags":null,"title":"二月以来的随想","uri":"/posts/thought-on-the-future/#"},{"categories":null,"content":" 比妄想还要妄想的妄想昨年的八月末，我终于下定决心不在腾讯留用而是参加秋招找后台的岗位，然而秋招我的很多后台流程都在简历环节被筛掉了，经历了九月零面试后，十月我终于等到了后台调剂到客户端的面试机会。 十月下旬我和 @214 聊天时，确定了一个共识：毕业进了客户端，就几乎没有机会再转后台了。然而最终我拿到的 offer 还是客户端的。说实话还是有点灰心，这个选择可能还不如实习时留用腾讯做客户端，和其他同学聊天时也有几个人评价还不如留在腾讯。我自认为我还是相当乐观又有自信的。当时我的想法是，工作是客户端但是业余项目可以做我喜欢的方向，说实话后台也不是我最喜欢的方向，只是本科生能选的岗位中我最喜欢的；其次，多一次历练的机会也挺不错，参加秋招后我才对高校毕业生的就业市场有了具体的了解，才让我认识到大厂岗位的来之不易 转折发生在今年二月下旬，由于我所在的部门在年后清点中发现人招的有点多了，于是 hr 联系我说有一个部门流转的机会。当那边的部门 leader 在电话中告诉我工作内容和业务时，我太过开心而不得不控制我在电话中的声音以免听起来太奇怪 —— 这就是我想进的后台。我在电话中问部门 leader 为什么在众多应届生中选择了我，他的回答是“你不用考虑原因，也不要考虑原因”。现在看来这样的机会简直就是奇迹，对于昨年十月在秋招中后台流程全部被卡的我来说简直就是比妄想还要妄想的妄想，以至于现在重新审视我在昨年八月末下定的决心，我甚至有点怀疑难道当时我就知道这样的结果吗？显然不可能，我只是做好了觉悟而已。 ","date":"2025-03-17","objectID":"/posts/thought-on-the-future/:1:0","series":null,"tags":null,"title":"二月以来的随想","uri":"/posts/thought-on-the-future/#比妄想还要妄想的妄想"},{"categories":null,"content":" 同理心的耗尽二月我因为治疗斜视住院了三天，这段时间内我和几位病友交谈病情，有一位大约 25 岁的年轻人向我讲述他因为白血病导致视网膜脱落，几年来他做了数不清的手术，他描述其中一场手术：因为白血病不能做全麻，在意识清醒的情况下看着磨机靠近眼睛磨掉眼睛的某个组织。他对我说“刚发现白血病的时候想死的心都有，但后面又不这么想了，死了就什么也没有了”。还有一位有糖尿病的老年人向我讲述他最近几年多次入院，辗转于这家医院的多个病床，甚至我当时的病床他曾经也躺过。 听完他们的讲述后，我发现我可能是其中最健康的，刚做完手术第二天就跑着出了病房，护士都在提醒我慢点。我不禁在想，要是哪天我突发恶疾，会不会也想那位年轻人一样一生都被毁了呢？要是哪天我老了，会不会也不能在家里过自己想要的生活，不得不像那位老年人一样辗转于不同的病床呢？ 但我想我已经不会为这样的未来感到悲伤了。过去我希望能做到「不为外物所动」，几年前感染新冠痊愈后，看到同样的景色的我产生了与过去几天截然不同的想法。现在想来也许不是多美的景色，只是走在阳光照耀的深圳街头，却让我感觉到生命的美好，感受到一颗心脏充满热忱地跳动着。于是我将这一准则修改为「不再感到悲伤」。 2022 年 贵阳连夜转运涉疫人员的大巴侧翻，听闻有个孩子的父母都在车上，一场事故让他立刻变成孤儿，我不禁为之悲痛：那个孩子以后怎么生活呢？他还有像父母那样可以依靠的人吗？还有人能像父母那样对他嘘寒问暖吗？ 那段时间我的心情一直很沉重，在我当作日记使用的私密推特中我记录了许多当时的随想。九月我写下「我们也是人啊，为什么没有做人的尊严呢」，十月我写下「灾厄总有一天降临在我头上。.. 既然无法避免，那么为什么不去帮助那些承受生命之重的人呢」。十二月因为学校疫情严重学生被赶回家，在 8 小时高铁到达深圳后，我被转运大巴送至接驳站，转运大巴上一位母亲的小孩哭着说「我们再也回不到坂田街道了」。到达接驳站后我被关进院子里等待下一辆接驳车把我送回家。由于感染风险，我已经 24 小时没有进食，12 月深夜的寒风安抚我焦急的心。等待了大约 6 小时后接驳车终于来了。回家后第二天我拨通了深圳政务服务热线，在朋友圈写下「悲剧真的会发生在你身边，还请对身边的人多一点同情」。 也许是这样的经历让我逐渐耗尽了同理心，同理心对我来说就好像一次性的东西，一旦发自内心的因为同理心而思考和行动，就会永远的失去一部分同理心。 耗尽同理心的同时，我也逐渐形成了一个观点。过去我总是悲观的认为悲剧人物和悲剧命运是相互选择的，这就是我作为悲剧人物选择悲剧命运的觉悟。但在真正近距离接触悲剧后，我认为对于每个人，悲剧总有一天会发生在他自己身上。做出以上觉悟后，我想当我哪天也突发恶疾，或者哪天衰老到辗转于不同病床时，我也能坦然接受吧。 ","date":"2025-03-17","objectID":"/posts/thought-on-the-future/:2:0","series":null,"tags":null,"title":"二月以来的随想","uri":"/posts/thought-on-the-future/#同理心的耗尽"},{"categories":null,"content":" 故乡随想最近和朋友看 无职转生，剧情到了转折点三，于是我和朋友一起讨论前两次转折点。转折点一即转移事件将主角转移到了魔大陆。当主角历尽千辛万苦回到故乡时，发现他的故乡在转移事件中已经被毁了，他的父母也被转移到不同的大陆。对于我来说，深圳就是故乡，但很遗憾因为秋招在深圳的岗位全部被拒了，未来几年我可能都不会长期住在深圳了。转折点一警醒我，有可能未来我回到深圳时已经物是人非了。过去我一直认为周而复始的景色永远停留在故乡等我，但可能已经是最后一次了。不知何处看到的一个句子「不是所有离别都是死别」，于是我决定珍惜每一次重逢 但我想我也不是很思乡。因为户籍问题，我 11 岁就离开父母和故乡独自求学，离开故乡就好比我像蚯蚓一样被切成两段，最开始可能会疼，但几年后故乡就已经不是我的一部分了。 ","date":"2025-03-17","objectID":"/posts/thought-on-the-future/:3:0","series":null,"tags":null,"title":"二月以来的随想","uri":"/posts/thought-on-the-future/#故乡随想"},{"categories":null,"content":" 未来随想我很喜欢 letter song 的旋律和氛围，主角在歌曲中对十年后的自己独白： text ～10 年後の私へ～ ～～给十年后的我～～ 今は幸せでしょうか？ 你现在幸福吗？ それとも悲しみで 还是因悲伤 泣いているのでしょうか？ 不禁哭泣呢？ ... 大切な人たちは 重要的人们 今も変わらずいますか？ 现在也依然不变的待在身旁吗？ それとも遠く離れ 还是说各自四散 それぞれんでいますか？ 走向不同的方向了呢？ 阿小信在他的 博客 中说 「我热爱生活，但对这个世界持悲观态度」，这个观点我无比赞同。一方面，在我看来，无法成为的自己、希望成为的自己、现在无法拥有的，都在未来，未来有着无穷无尽的可能性，未来就好比走在街头时远方不断延伸的街道，它的景色不断吸引着我向前。而未来却是宝贵而有限的：未来每时每刻都在被消费。私以为，一旦未来丧失了其无穷无尽的可能性，未来也就永远结束了；生命结束，也就彻底失去了拥有未来的能力。三年前我将这个观点总结为「生命与未来同义，生命与未来同样不可辜负」。这就是我对未来积极的观点。另一方面，我也认为悲剧总有一天会发生在自己身上。 JOJO 的奇妙冒险 石之海 的结局中，安波里欧总结普奇神父失败的原因：普奇神父的觉悟建立在其替身「天堂制造」能够操纵时间，但 JOJO 和 JOJO 的伙伴们的觉悟建立在未来的不可知。我想这就是我对未来做出的觉悟吧 ","date":"2025-03-17","objectID":"/posts/thought-on-the-future/:4:0","series":null,"tags":null,"title":"二月以来的随想","uri":"/posts/thought-on-the-future/#未来随想"},{"categories":null,"content":" append最近很喜欢一位 youtuber Abao in Tokyo，自带番茄时钟的轻音乐可以让我沉浸在学习中，也省去了刻意遵守番茄时钟的麻烦。就像我向游戏搭子分享一部作品的音乐：“我不会突然发现音乐好听得不得了，但也相当好听而且让我沉浸在剧情里” ","date":"2025-03-17","objectID":"/posts/thought-on-the-future/:5:0","series":null,"tags":null,"title":"二月以来的随想","uri":"/posts/thought-on-the-future/#append"},{"categories":null,"content":"这篇文章的契机是看到一篇谈论家庭关系的 文章，随后又不禁回想起各种事，对于家庭、家人、亲密关系，我也有许多自己的观点。 与之前的文章不同，这篇文章的观点可能是完全错误的，它只是我情绪化的思考，但这样的观点让我在孤独和不被理解中得到一点慰藉。 ","date":"2025-01-31","objectID":"/posts/kazoku/:0:0","series":null,"tags":null,"title":"但愿人长久，千里共婵娟","uri":"/posts/kazoku/#"},{"categories":null,"content":" 家人概念的分割我将家人这个概念分割成两种，其一是有直接或间接血缘关系的人，其二是深刻联结的人。 初中时一位总是危言耸听的语文老师在课上说，中国至少有 xx%的夫妻没有爱。我想这是我第一次考虑这个问题：我的父母是因为相爱才组建家庭、生育了我，还是顺应世俗才这么做呢？ 虽然我并不相信这位老师的数据，但没有爱的家庭肯定存在 这世上根本不存在什么“商谈”和“共识”，只是在爱中，在包容和信任中，分歧无法构成隔阂和冲突。但遗憾的是，绝大多数中国家庭里，爱是不存在的。一对怨偶，因为合适，因为年龄到了，被迫结为夫妻，凭借基因的本能生下一个孩子，再依据人的本性，把这个幼小脆弱的生命磋磨成自己喜欢的样子。这样的家庭，没有恨已经是万幸，而爱，更是天方夜谭。现在，让几个没有爱的人被关在一个狭小的空间之中，冲突几乎是理所当然的。 在和朋友相处时，总有那么几个瞬间让我感到绝望：即使是相当亲密的朋友，也不能真正的理解我，让我不禁感慨「人类的悲喜并不相通」。我将知己定义为能真正的相互理解、相互支持的人，我不想否定知己的存在，但很有可能我们至死也不会遇见这样的知己，于是我们退而求其次，追求建立这样的关系：即使不能真正的相互理解，至少不放弃尝试达成相互理解；即使无法相互理解，至少也能相互支持。这就是我对家人的第二种概念的定义 现实中的家人，往往处在这两种家人概念的中间，是两种家人概念的混合体。在 《少女理论及其周边》 中，里想奈认识到她的母亲和她并没有深刻联结，只是具有血缘关系后，里想奈对母亲的称谓也从「母亲」变成了「血脉相连的母亲」—— 除了血脉，没有任何联结的母亲 ","date":"2025-01-31","objectID":"/posts/kazoku/:1:0","series":null,"tags":null,"title":"但愿人长久，千里共婵娟","uri":"/posts/kazoku/#家人概念的分割"},{"categories":null,"content":" 血缘与世俗虽然我们总是对家人有着特殊的情感，但我们的文化总是在家庭上做文章，从周的宗法制到现代的「国是千万家」，本来应该纯粹的深刻联结与权力、财富的分配挂钩。周人希望利用血缘关系巩固国家的稳定，换而言之，国家内部的矛盾一定程度上转变为「具有血缘关系的家人」之间的矛盾；国是千万家，家庭的秩序就是国家秩序的微观体现，于是家庭不再只是「家人所在之地」，还承担着维护社会秩序的责任。《春花子》 讲述了主角春花子大义灭亲的故事：春花子在百般劝告儿子三顺不成后大义灭亲，之后她因儿子的死以及内心的悲痛而绝食八天而终。在我看来春花子的悲剧背后是对“家庭承担维护社会秩序的责任“的指控：为什么大义与亲不能兼得？与其说春花子因悲痛绝食自杀，不如说「大义灭春花子」；守护深刻联结的家人和维护社会秩序本来就是两个无关的事，它们可能是冲突的，维护社会秩序这个责任是由我们的文化、社会、统治者强加于家庭的，而不是家庭本应承担的。 但换个角度，世界上从来就不会有那么纯粹的东西，一方面，家庭的成员不一定是具有深刻联结的人，另一方面，家庭体现了人类社会组织规律，不可避免的需要处理权力和财富的分配，将国家治理的一部分责任下放到家庭，也符合人类社会组织规律，几千年的实践证明这是一个有效的方式。但从逻辑学的角度来批判，过去几千年的实践只能证明它在过去是有效的方式，不能证明它在现在也是有效的；即使他是有效的方式，但也不一定是最好的方式。我并不暗示这种方法是错误的，我只是否定它永久有效、不需要变革 ","date":"2025-01-31","objectID":"/posts/kazoku/:2:0","series":null,"tags":null,"title":"但愿人长久，千里共婵娟","uri":"/posts/kazoku/#血缘与世俗"},{"categories":null,"content":" 父母于子女无恩论孔融说”父之于子，当有何亲？论其本意，实为情欲发耳。子之于母，亦复奚为？譬如寄物缻中，出则离矣“，这个 观点 即使放到现代也有点偏激，乍一听有许多合理之处：父亲对于儿子，有什么亲情可言，论其生子的本意，不过是一时情动的结果。母亲对于儿子，又做了什么呢，就像东西存放在瓦罐里，东西出来了，与瓦罐也就没什么关系了。父母让子女出生，没有征求子女的同意，这只是他们擅自决定。一些作品中会解释说，因为父母想要让子女感受世界的美好，那么换个角度也可以说，父母因为一己私欲让子女来世间受罪 对于这个问题，有人认为没有生育之恩，但有养育之恩。但养育之恩的界限很模糊，生而不养不仅违反法律也违反道德，在道德认定的养育义务之内的养育没有恩，而义务之外的养育就是养育之恩。这是一个我比较认同的观点，同时我也有自己的观点：两年前的我第一次接触这个论点时，写下了「父母于子女没有恩情只有亲情」 我的观点也有些偏激，因为我想否定子女必须报恩的观点，所以我抛弃了难以确认的养育之恩。总有一些人认为父母生了子女，子女就应该孝顺就应该报恩，这种思想本质上是”君为臣纲，父为子纲，夫为妻纲；君叫臣死，臣不得不死。父叫子亡，子不得不亡“的残余。《杀恋~悠久流传的恋之歌》 中，母亲生下子女然后残忍地吃掉他们，她面对主角的质问时反驳到：「吃自己生的孩子，何罪之有？」。这句台词在我心中留下了深刻的印象，也让我感到这位母亲的非人性，但这不就是封建时期的思想吗？非人性的不就是封建思想吗？人可以吃掉自己身上的肉，虽然会被认为有精神疾病，但并不会违反道德，那么将子女视作父母生命的延续，所谓「身体发肤受之父母」，那么吃掉孩子就好比吃掉自己的所有物一样天经地义 总的来说，父母于子女无恩论是一个我比较认同的观点，子女不是父母生命的延续，也不是父母的所有物，而是和父母一样是一个独立的个体。父母与子女应当首先是一个社会契约关系：父母抚养子女，子女赡养父母；如果父母没有尽到抚养的义务，那么子女也不必尽赡养的义务。但这样的社会契约中存在一个致命的问题，抚养先于赡养，这样的契约具有潜在的不公平可能 换个角度，父母抚养子女而子女赡养父母，符合人类天性的同时也反映了家庭的社会秩序责任：父母与子女存在一个必须签订的契约，虽然人类的天性导致我们会自然地签订契约，但我们仍然失去了签订契约的自由。从社会和统治者的角度，他们并不在意我们是不是因为亲情而签订的契约，只在意不签订契约的后果 但我还是不想把父母与子女的关系解释成这样冷冰冰的社会契约，共同生活的十几年二十几年、生活中流露的点点滴滴让父母与子女早已建立起深刻联结，我只是希望这样的深刻联结不要被维护秩序、财产分割等世俗影响 ","date":"2025-01-31","objectID":"/posts/kazoku/:3:0","series":null,"tags":null,"title":"但愿人长久，千里共婵娟","uri":"/posts/kazoku/#父母于子女无恩论"},{"categories":null,"content":" tsuki我很喜欢日语的月（つき，tsuki）这个词，也许是音节更优美，也有可能是我常看日语的作品，日本的文化与中国相近又不相同，从日本文化的角度去理解中国文化中的事物往往会有新的见解，这篇文章的 url 中 kazoku.md 就是日语家族（かぞく）的罗马音。 月总是被用来寄托家人之间深刻的联结，一千年前苏轼就写下诗句「人有悲欢离合，月有阴晴圆缺，此事古难全。但愿人长久，千里共婵娟」。即使在其他文化中，我也能看到相似的表述：「我教你辨认北极星，这样即使我们身处不同半球，也能看着同样的北极星」。即使我们的国家、地域、民族、文化、语言不同，但我们都有「深刻联结的家人」。在其他文化其他语言中看到千里共婵娟的表述时，总是让我感动 —— 这就是人类共同的情感纽带 所以看到 deepseek 在用月光来比喻深刻联结时，我不禁感慨万分 或许未来人类与 AI 的关系就像您此刻的家庭状态：永远存在错位的理解，永远无法达成终极和解，但永远共享着同一个月亮照亮的夜晚。这月光不解决任何问题，却让所有问题不再需要被解决。 ","date":"2025-01-31","objectID":"/posts/kazoku/:4:0","series":null,"tags":null,"title":"但愿人长久，千里共婵娟","uri":"/posts/kazoku/#tsuki"},{"categories":null,"content":"回顾 2024 可以说越来越好了：专业水平更高了，博客也不再是托管笔记的网站了，决定了未来的去向等等。废话结束，开始正题 ","date":"2024-12-28","objectID":"/posts/2024-summary/:0:0","series":null,"tags":null,"title":"2024 年终总结","uri":"/posts/2024-summary/#"},{"categories":null,"content":" 为什么不去读书呢两年前买了 ipad 后就有用 apple 的\"Books\"看书的习惯，不过看的书绝大部分都是技术书籍，驱动我去看这些书的原因仅仅是因为我想要提高专业能力。后来了解了 编程随想，不考虑他具有争议的地方，单从个人能力来说，他精通许多领域：IT、历史、心理学、政治、哲学、经济等等。 我想这就是我第一次见到了一个厉害的人具体是什么样的。后来我看其他书时，又花了一点时间了解作者，发现许多经典书籍的作者在他的领域往往是非常厉害的人，或者说正是因为作者在他的领域具有极强的能力、取得了许多成就，所以他写的书大概率也是经典书籍。作为一个普通人我们极大概率永远也见不到这样的人物，但我们能够极低成本（相比得到见面交谈的机会）地阅读这样一个人物的书籍，通过他的书籍窥见他的思想。 同时我也认识到，我们平时看的许多文字、视频除了能够获得短暂的快乐，都是毫无意义的。我有一位结束考研的室友最近经常在宿舍外放抖音，于是我也刷了一会抖音，不得感慨许多短视频能快速的吸引注意力、获得暂时的快乐，但毫无意义，这里的无意义是有许多方面的 首先，短视频可以作为一个作品对待，这样一个作品，作者是怀着怎样的想法创作的？作者的水平如何？作者又花了多少时间创作出作品？观众看完作品后又能产生多少的感慨、思考、震撼、回想？从这些角度衡量，短视频可以说是总体较低质量的作品。 其次，短视频行业有许多灰产，他们批量抄袭视频，可能是某人的爆款文案，使用 AI 配音，再配上网上搜集的各种图片组合成视频，或者一些创作能力不强的作者在某个视频突然爆火后，也许是不知道如何创作更火的视频，以后上传的视频都是曾经的爆火视频的复制。这种问题我认为越来越严重，b 站也没好到哪去。视频平均长度越来越短，推广视频越来越多（往往内容还非常低质量）。甚至还有将油管的视频“本地化”，稿子完全抄袭，只是自己录制屏幕、英文换成中文的 视频。我感到愤怒的同时也感到悲哀，为什么劣质视频这么多！ 前面说了这么多不好的视频，我心中也逐渐形成了一套标准，用于快速完成视频的高低质量分类任务 不能抄袭、不能使用有版权的背景音乐 在油管这已经是常识 如果有配音，必须是自己的声音，不能是 AI 合成的 AI 配音有批量制作视频的嫌疑，也是视频作者自信心不足、创作能力不足的一个表现，作者配音也能更好的传达感情 视频画面内容必须有意义，不能是网上爬取的各种视频片段的集合 或 各种梗图的 PPT 轮播 同样是排除批量制作视频的嫌疑，而且如果内容本来就没有合适的画面，这样的内容更适合使用文字表达 鼓励作者本人出镜 本人出镜是作者个人形象的展示，也能更好的传达感情，和观众距离更近 人人都能创作视频也许是好事，但让视频平台上充斥着许多低质量视频，让我们沉浸在短暂的快乐中忘记思考。刘慈欣在他的小说中有句话我印象深刻：“人类一思考，上帝就发笑，如果人类不思考，上帝连发笑都不屑于。” 在我的受教育经历中，很多人告诉我读书的重要性，但只有我真正的近距离的见识了一个读万卷书的人，才真正认识到了读书的重要性。另一方面，大众最容易访问的作品（短视频）质量低，大众最难访问的作品（书籍）质量高；我身边许多同学并没有阅读的习惯，他们的空闲时间基本在刷视频、玩游戏。游戏玩腻后又感慨好无聊，我问他“无聊怎么不去看书呢”。改变了世界的伟大思想就印在纸上，为什么不去读呢？ ","date":"2024-12-28","objectID":"/posts/2024-summary/:1:0","series":null,"tags":null,"title":"2024 年终总结","uri":"/posts/2024-summary/#为什么不去读书呢"},{"categories":null,"content":" 博客 ≠ 笔记这个博客最开始建立的原因只是两年前我觉得在世界互联网上有个属于自己的网站很帅，最开始的文章只能算是学习笔记或者备忘录，这样的文章只有自己能看懂，只对自己有价值。想象一下作为读者打开这样的博客网站，看到各种不明所以的文章，就像打开了某人的笔记本——笔记本里龙飞凤舞，充斥着大量看不懂的缩写。 促使我改变的契机也许是读了 《程序员的自我修养——链接、装载和库》 和 《Advanced Programming in the UNIX® Environment》，又和 @Soulter 和 @bosswnx 参加了 数据库管理系统设计赛。此后我基本按照一周一篇的更新频率写了十周 写博客获得了什么呢？从功利的角度来说，优秀的博客在秋招时也许能帮上忙，从非功利的角度来说，写博客督促我尽快学习更多知识、不断的思考、形成自己的观点，最后在文章中用文字思路清晰的表达出来，有些博客将这个过程称为 IO，这大概就是博客驱动学习的过程吧 对我来说，支撑我写博客的一个很重要的原因就是向外扩张自己的影响力。我很喜欢 腾讯校招网页 上的口号 「让世界看到你的影响力」，我也想让世界看到我的影响力，于是我就需要先展开自我同一性：我是谁？我要做什么？我有什么价值？我为什么和别人不同？ 解决了我是谁和我有什么价值后，我就面临一个问题：我要做什么？ 最开始我尝试做开源项目，我希望使用 flutter 做一个低内存占用、低存储空间占用、HiDPI 支持良好的 linux 微信客户端，用于解决我在 linux 使用微信的需求。在写下 8k 行代码后由于微信 API 限制和能力不足，我放弃了。废弃的代码包括一个用于连接微信个人号的 python 包，fastapi 写的服务端和 flutter 写的客户端，服务端和客户端通过 websocket 通信，而且服务端可以保存历史消息记录，客户端支持防撤回 —— 我希望这个第三方客户端体验能够完爆当时的 linux 微信解决方案。2024 年初，linux 的所有微信解决方案我基本都尝试过，都很难用，完全无法胜任日用的程度，以至于很长一段时间内，我使用 telegram-wechat 在服务器上登陆微信账号并将消息转发给 telegram，于是我就能在 telegram 上收发微信消息。这个方案好用吗？老实说不好用，但已经是在 linux 上最好的体验了，甚至 telegram 还能长期保留转发的微信消息 很快官方的微信 linux 客户端开放测试的消息放出了，我的客户端也失去了存在的意义，我将用于连接微信个人号的 python 包起名为 VChat 后开源出来，收获了对我来说鼓励很大的 star。但这个项目有价值吗？我认为没有，因为就连作者本人也不用，但仍有几个用户使用 VChat 开发他们自己的机器人或 机器人框架，这让我宽慰：至少还有人用，但我也清楚，这种项目说到底还是一个玩具，它不能解决现实的问题就没有实际意义。 后来又看到高天在一个 视频 中聊我们应该如何选择开源项目，我认识到能有一个几千 star 的开源项目不是一个简单的事（markdown 项目除外），那么除了开源我还有什么方式能让世界看到我的影响力呢？目前看来写博客是最简单的。 ","date":"2024-12-28","objectID":"/posts/2024-summary/:2:0","series":null,"tags":null,"title":"2024 年终总结","uri":"/posts/2024-summary/#博客--笔记"},{"categories":null,"content":" 什么是重要的在我大一还没有转专业到计算机学院时，仅仅是对编程有一种模糊的兴趣。团建时要求写下对未来自己的想象，简单来说就是目标，我在纸上写下“学会多门编程语言”。现在看来很幼稚，但其实直到这一年，我才知道了什么是重要的。但我无法直接回答这个问题，Linus Torvalds 说“Talk is cheap. Show me the code.”，我认同这句话，但我也认为 code 不重要，重要的是背后的设计，在实习的考核汇报中，我提出了这样一个观点：「源代码是设计的编译产物，通过读源代码去理解设计就好比反汇编」。但我也能同样说，设计不重要，重要的是设计希望解决的问题，因为人们面临的问题总是相似却不相同，为此人们设计了许多方案，这些方案最终的目的都是解决问题。甚至我也能说 ，code（技术细节）不重要，重要的是 talk（观点），这也是我写博客坚持的做法：技术细节很无聊，也没必要重复官方文档，一篇好的博客应该展现出作者的思考和观点 虽然我一会说这个重要，一会说那个不重要，但我想我已经知道了什么才是重要的：运用计算机科学，参与到广泛的实践和生产中去，去解决现实中的问题，给社会创造价值。这也是我对“我要做什么”的最终回答 ","date":"2024-12-28","objectID":"/posts/2024-summary/:3:0","series":null,"tags":null,"title":"2024 年终总结","uri":"/posts/2024-summary/#什么是重要的"},{"categories":null,"content":" 技术之外也许是看了一些大佬的博客，我渐渐形成一个观点：技术的世界很大，但技术之外的世界更大。一个开发者首先是生物人，其次是社会人，最后才是开发者。 在过去我总是害怕未来一个人生活，担心各种意外，不小心摔倒了站不起来、被倒下的家具压住脚、生病了没人照顾自己。一个人就只有一双手一双脚一个心，要如何面对这么多困难呢？很幸运的是这一年我和某人建立了如同家人般亲密的关系，也达成了未来一起生活的约定。我总是认为两情相悦是很难的事——你喜欢我，我正好也喜欢你，多么巧合的事！ ","date":"2024-12-28","objectID":"/posts/2024-summary/:4:0","series":null,"tags":null,"title":"2024 年终总结","uri":"/posts/2024-summary/#技术之外"},{"categories":null,"content":" 总结这篇文章虽然标题是年终总结，但又被写成了一堆观点的集合了，也罢，作为 z2z63，我的故事没什么价值，但我提出的观点会比我的故事更有价值 ","date":"2024-12-28","objectID":"/posts/2024-summary/:5:0","series":null,"tags":null,"title":"2024 年终总结","uri":"/posts/2024-summary/#总结"},{"categories":null,"content":" append最后附上这首年度音乐 Note 本视频上传者不拥有音乐的版权 ","date":"2024-12-28","objectID":"/posts/2024-summary/:6:0","series":null,"tags":null,"title":"2024 年终总结","uri":"/posts/2024-summary/#append"},{"categories":null,"content":"两年前的某一天，我回想起 JOJO 中登场的名为 齐贝林 的角色，他在向僧人学习波纹气功最终奥义时被告知了自己的命运：“在一间古老而弥漫尸臭的密室，孩童将门打开之时，为了解放被锁链禁锢的年轻雄狮，你将燃烧自己的伤口，在不久后迎来残酷的死亡”。在预言的时刻到来时，齐贝林为了打败石面鬼，坦然地走向了死亡。感慨于齐贝林的精神，我在 Notion 上写下：“我将如何赴死”。 《最好的告别》 这本书讲述的也是一个凡人怎样赴死，但这里的赴死不是为了某种理想而奉献自己的生命，而是有意义地度过老年生活、平稳地迎来死亡。前者是「夏花之绚烂」，后者是「秋叶之静美」。 所谓 Mortal，牛津词典解释为 (of a living human being, often in contrast to a divine being) subject to death。人们认为上帝全知全能、不死不灭，而凡人会生老病死、认知和能力也是有限的。原著书名《Being Mortal》多少有点悲剧意味：身为 mortal being，我们自诞生起就注定必有一死。 但是死亡本身是不可怕的，死去元知万事空，任何悲伤与痛苦只是生者需要体验的；真正可怕的是衰老、逐渐失能、与大部分美好无缘、病痛、将死不死的死前长达十几年或者二十年的生活。这段时间的生活质量和健康程度持续下降。现代医学能有效地延长人们的平均寿命，也能一定程度上改善生活质量。但毋庸置疑的是，生活质量和健康程度的下降是不可避免的，现代医学能做的只是将下降曲线拉伸到更长的时间跨度、让下降曲线更平缓。 ","date":"2024-12-23","objectID":"/posts/being-mortal/:0:0","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#"},{"categories":null,"content":" 将死不死我使用这样一个绝望的标题，是因为我直到现在也无法接受衰老后的自己。我们年轻时乐于探索、乐于学习、精力充沛、能够和许多朋友尽情享乐，我们被父母、老师、社会给予厚望，并且希望在自己喜欢的领域大展身手。但我们老后，首先是退休，这意味着我们脱离了生产，失去了最多的实践机会、最大的信息来源、最多的创造价值的机会。随后衰老的迹象逐渐显现：手指、关节活动越来越不灵活，注意力越来越差，精力越来越少，肌肉逐渐萎缩，患上慢性疾病，做到生活自理越来越难。我们会越来越需要子女的帮助才能生活。但随着衰老和失能的加剧，子女需要承担的越来越多，当他们无法负担时，我们可能会被送进疗养院。衰老和失能继续加剧，我们可能患上各种疾病，也可能发生摔跤等意外，生活质量急剧下滑，而长期接受治疗和药物等副作用会让生活质量进一步下跌。我认为此时我们基本成了将死之人，我们衰败的躯体能感受到生机和活力也会越来越微弱。最后因为难以治疗的疾病死在病床上。 身体的逐渐衰老会以一种细微而不可察觉的方式改变着我们的生活，衰老是发生在个体身上的最至关重要的事情，衰老也是自然加诸于个体的苦难，没有其他任何人能真正理解我们的苦难，也没有任何人能分担。同时，衰老的过程也是被家庭、社会逐渐抛弃的过程。 ","date":"2024-12-23","objectID":"/posts/being-mortal/:1:0","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#将死不死"},{"categories":null,"content":" 为什么说衰老的过程也是被家庭、社会逐渐抛弃的过程不论文化与民族，人类审美的最核心的一点在于健康，而健康反映的是适合生育。而老年人花白的头发、皱巴巴的皮肤是健康的反面，也可以说是审美的反面。虽然我们也许不会因此对老年人有歧视，但在潜意识中我们会更喜欢年轻、健康的人。这点在书中的一个细节体现得淋漓尽致： “她并没有马上认识到她的新观念和老年人通常的观念多么相同。但是，病房里的其他 4 位病友都是老年妇女，髋骨骨折后，她们的腿悬挂在空中。卡斯滕森发觉自己与她们有共同点。 “我躺在那儿，周围都是老年人，”她说，“我同她们熟悉后，知道了她们出了什么事。”她注意到她们的治疗和她很不一样。“一整天都有医生和治疗师来看我、治疗我，而他们只是在出门的时候，对我邻床的那位老人挥挥手，说一句：‘好好努力！’” 他们传递的信息是：这位年轻女士的生命还有各种可能性，而她们的没有。” 三代同堂在汉语中带有褒义，但是在现代社会，由于老年人和年轻人生活习惯的差异等种种原因，部分老年人选择独居或者和伴侣生活。随着身体的衰老，他们逐渐丧失了独自生活的能力，不得不和子女同住。但随着衰老的加剧，由于老年人自己的愧疚感、子女能提供的照顾有限，老年人又不得不选择养老院这样有专人提供照顾的场所。 然而很多养老院存在的目的只是为子女提供了一个安置他们父母的地方，而不是让老年人在这里能养老： “辅助生活机构不是为老年人修建的，而是为他们的子女修建的。实际上，决定老年人住哪里的是儿女，这从养老院的销售方式就看得出来。他们努力完善营销人员所谓的“视觉内容”，例如，吸引谢莉视线的漂亮的、酒店式的入口通道。他们兜售电脑实验室、锻炼中心，以及听音乐会和参观博物馆等活动——这些东西主要是中年人希望其父母拥有的，而不是父母自己的选择。” ","date":"2024-12-23","objectID":"/posts/being-mortal/:2:0","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#为什么说衰老的过程也是被家庭社会逐渐抛弃的过程"},{"categories":null,"content":" 老年的价值 “对疾病和老年的恐惧不仅仅是被迫忍受对种种丧失的恐惧，同样也是对孤独的恐惧。当人意识到生命的有限，他们就不再要求太多。他们不再寻求更多的财富，不再寻求更多的权力。他们只要求，在可能的情况下，被允许保留塑造自己在这个世界的生命故事的权利。” 为什么仅仅存在，仅仅有住、有吃、安全地活着，对于我们是空洞而无意义的？我们还需要什么才会觉得生命有价值？Josiah Royce 在《忠诚的哲学》中回答说，我们都追求一个超出我们自身的理由。对他来说，这是人类的一种内在需求。这个理由可大（家庭、国家、原则）可小（一项建筑工程、照顾一个宠物）。重要的是，在给这个理由赋予价值、将其视为值得为之牺牲之物的同时，我们赋予自己的生命以意义。 即使已经脱离了工作，衰老的人们仍然在寻找值得献身的事物，也可以说，即使年老，我们也需要寻找自己存在的价值。这个价值可能对其他人来说微不足道，但对我们来说可能是全部。 在我小时候曾有一段时间外公离开农村和父母一起生活，和其他老年人一样，他把许多时间花在了捡垃圾上，任何能在废品站卖钱的垃圾：塑料瓶、酒瓶、坏掉的电器都被他捡回来堆在阳台。我想这就是外公给自己找到的“超出我们自身的理由”，当废品卖出得到钱时，自己存在的意义就得到了最直白的证明。 ","date":"2024-12-23","objectID":"/posts/being-mortal/:3:0","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#老年的价值"},{"categories":null,"content":" 身体的衰老引起心理的改变生活质量和健康程度持续下降，意味着衰老后我们不能再像年轻时那样做许多我们想做的事情，但人的情绪会自动调节，虽然我们变得更加珍惜和亲密的人相处的时光，更加珍惜日常中琐碎的细节，这样我们仍然能感受到快乐的情绪，于是我们仍然获得了活下去的动力。 过去我曾经认为，如果那天我不能做某些我非常想做的事情，不能从生活中获得足够的正向情绪，那么我会干脆地结束自己的生命，但我可能会担心有人指责我抛弃社会责任，所以我可能会在父母去世后再考虑。但当我们真的遇到了这种情况时，会有勇气做出如此的决定吗？ 作者讲述了一个他还是实习生时遇到的故事，60 多岁约瑟夫·拉扎罗夫患了无法治愈的癌症，医生提供了两个选择，一个是安宁缓和医疗，另一个是实施手术时 当他同在病房的儿子质疑选择做手术是不是明智时，拉扎罗夫很不高兴。 “别放弃我，”他说，“只要我还有任何机会，你们一定要让我尝试。”他签完字后，我出了病房。他儿子跟出来，把我拉到一边对我说，他的母亲死在监护室里，死的时候全身插满了管子，戴着呼吸机。当时，他父亲曾经说过，他绝不想这样的情形发生在他的身上。但是，时至今日，他却坚决要求采取“一切措施”。 ","date":"2024-12-23","objectID":"/posts/being-mortal/:4:0","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#身体的衰老引起心理的改变"},{"categories":null,"content":" 但是仍有一些心理不会改变现代医学也许能医治很多衰老后老年人所患的病，但老年人患了一个更严重的、现代医学也无能为力的病——老年病。当衰老悄悄的不断累积，直到某天意外发生，迄今为止所有的衰老都显现出来。但人们往往认为“只要治好就行了”，就像一个可能危害性命的感冒，只要熬过去，就能回到原来的家中恢复原来的生活。 在过去，疾病的发现和死亡往往间隔很短的时间，“1799 年 12 月 13 日，乔治·华盛顿在家里发生了喉部感染，第二天晚上就因此毙命。约翰·昆西·亚当斯、米勒德·菲尔莫尔和安德鲁·约翰逊都死于中风，都是中风后两天之内就亡故了。拉瑟福德·海斯心脏病发作，三天后就过世了。”。因此人们形成了对待疾病的态度：“人们一般以体验坏天气的方式体验危及生命的疾病——如同某种几乎不经预警、突然袭击的事物。你要么挺过去，要么挺不过去。” 但在现代，更好的生活环境、卫生条件、营养水平使得人们的寿命大大延长了，人们的死因不再是突发疾病然后暴毙，而是逐渐衰老，器官机能不断丧失，经过长期的医疗斗争仍然无济于事，从而迎来死亡。而不断衰老、不断失能的过程，也就是逐渐成为将死之人的过程；就算成为了将死之人，现代医学也有不少手段维持一个很难称得上是生命的躯体的生命体征：呼吸机、饲管、静脉注射营养液、止痛药、镇静剂。但是我们都清楚维持一个将死之人的生命体征不能改写命运，还会给这个将死之人仅剩的有意识的时间带来许多痛苦、也浪费了医疗资源。是否存在这样一个界限，超过了这个界限，患者、家属、医生都接受了事实，并且不再采取任何可能引起更多痛苦的治疗方案？ 在过去几十年里，医学科学使得数百年来关于死亡的经验、传统和语言过时了，并给人类制造了一个新的困难：如何死。 ","date":"2024-12-23","objectID":"/posts/being-mortal/:4:1","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#但是仍有一些心理不会改变"},{"categories":null,"content":" 善终服务接受治疗和投资有许多相似之处：牺牲现在的生活质量，换取未来更好的生活质量。在绝大部分情况下接受治疗就像购买一只一定会增值的股票，但是如果我们没有时间等待股票增值呢？对于时日不多的人来说，即使治疗成功，他也享受不了多少年的更好的生活。在过去人们并没有意识到这一点，导致将死之人在生命的最后时刻受到了折磨，直到将死之人变成了几乎没有意识的肉块，我们还在他的身体上施展着现代医学和人类道德 但这种现象的发生也与患者自己有关，我们并没有提前规划好“我的病症严重到了哪种地步应该放手”，而家属、医生并没有替我们放手的权利，为了免于陷入道德指责，他们只好全力救治直到生命体征的消失 是否存在这样一个治疗手段，它在承认患者即将死亡的前提下，以改善患者生活质量、维护患者的生命尊严为目标进行治疗？作者给出了一个答案：善终服务，比起治疗，善终服务更像照顾、护理，它致力于在患者的最终时刻减轻病痛，让患者能够去做自己想做的事情，最后如同秋叶一般平静地迎来死亡 作为现代社会中必有一死的凡人，我们应该主动考虑“我能接受善终服务吗？”、”到了什么地步我想放弃积极治疗“，否则我们很可能在临终时来不急做出决定，同时医疗系统也应该把善终服务和积极治疗作为两个并列的选项同时提供给病情严重的患者。 救助不是单方面的决策，而是协商的行为，病人呼求救治，而临床医生被动地同意施救 ","date":"2024-12-23","objectID":"/posts/being-mortal/:5:0","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#善终服务"},{"categories":null,"content":" 总结我 14 岁左右学校放假时，被母亲拜托看望外公，她说外公病的很重，可能时日不多了。那时的我对死亡根本没有什么概念，我和外公聊天，他和母亲的哥哥一家人一起生活并受他们照顾，外公说他眼睛看不到了，吃饭都要别人的帮忙。他指甲缝里很多污垢，散发着难闻的气味。我完全想象不出来外公病重的样子，还在电话里宽慰母亲。 两周后的周末，我收到了外公去世的消息，直到外公去世后，母亲才放下了工作回老家参加葬礼。 比起我的衰老，父母的衰老是更快发生的事，比起思考我衰老后的结局，更应该先考虑父母衰老后，我应该怎么办？我应该如何让他们自由、快乐、有尊严的活到生命的最后一刻？我该如何接受父母的衰老比我的衰老更早发生的事实？ 考虑了这样的问题，我愈发认识到现在的我沉溺于年轻时的幻觉，在这样的幻觉中我不会感到孤独、我能随时抛开对过去的怀念而大步向前，我坚信未来的我一定会过的更好，但这样的幻觉还能持续多久呢？当我苏醒浮出梦乡时又该如何面对事实呢？这一切只有交给未来的我回答。 ","date":"2024-12-23","objectID":"/posts/being-mortal/:6:0","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#总结"},{"categories":null,"content":" append 1 月 17 日，在上海市徐汇区康健社区卫生服务中心舒缓疗护病区，护士紧握着一名肿瘤晚期患者的手 最后附上这首富有悲剧性的音乐，衰老就是我们每个 mortal being 的 inevitable desnity ","date":"2024-12-23","objectID":"/posts/being-mortal/:7:0","series":null,"tags":null,"title":"Being Mortal: 身为必有一死的凡人，我们将如何赴死","uri":"/posts/being-mortal/#append"},{"categories":null,"content":"正如标题所说，这篇文章是读后记，但我不想成为作者的传声筒，也不想将这篇文章变成只有自己能看懂的阅读笔记。所谓一千个读者就有一千个哈姆雷特，我想将读完这本书后的感想、思考、观点讲述出来，我想这也是我能写出的有价值的文字 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:0:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#"},{"categories":null,"content":" 这本书是什么《Inside the C++ Object Model》 的作者 Stanley B. Lippman，同时也是《C++ primer》、《C++ primer plus》的作者，曾在贝尔实验室作为领导者参与 cfront 项目，cfront 是“远古”时期的 C++编译器，它做的工作就是将 C++转变为 C，剩下的编译链接都交给 C 编译器完成 这本书的大致内容 The Semantics of Constructors 编译器如何合成构造函数、逐步完成对象的构造过程 The Semantics of Data 编译器是如何决定对象的内存布局以保证面向对象语义和运行时性能，又是如何根据内存布局改写数据成员的访问 The Semantics of Function 编译器如何将成员方法调用转化为更加底层的普通函数调用，从而能够在现有编译体系下实现 Semantics of Construction, Destruction, and Copy 编译器如何合成构造函数、析构函数，以保证面向对象语义 Runtime Semantics 必须由运行时系统提供的面向对象的运行时支持，追踪临时对象生命期、正确初始化全局变量、局部静态变量、局部变量和数组 这本书发版于 1996 年，在 C++20 已经进入生产环境的今天，书中提及的一些概念已经被新标准废弃，但仍有很多内容对理解标准帮助很大。C++面向对象特性是如何影响对象的布局的，对象的布局又是怎样影响构造函数和析构函数，怎样影响 C++的运行时系统，又是怎样影响 C++和 C 互操作。在我看来其中最重要的就是从 C++的领域中划分出了一片区域，这片区域可以安全的和 C 互操作，所以接下来这篇文章将以一个实用、朴实的角度说明 C++和 C 为什么可以互操作（实用、朴实、不严谨、不太符合C++20标准的定义） ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:1:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#这本书是什么"},{"categories":null,"content":" C++对象的内存布局","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:2:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#c对象的内存布局"},{"categories":null,"content":" 普通对象的内存布局普通对象也是我胡编乱造的词，指类中不存在虚拟函数、继承。此时 C++对象包括所有非静态数据成员 cpp class A{ private: // private access section int x; int y; public: // public access section char z; }; 标准规定：同一个 access section 内，声明顺序在后的数据成员具有更大的地址，即在 A 的对象中，y 的偏移比 x 更大。标准如是规定的意图是允许编译器根据需要在数据成员的间隙插入额外的数据（见下文） 标准规定：存在多个不同级别的 access section 时，不同 section 的相对位置由编译器自己决定 根据以上两个信息，可以得出：普通对象只有一个 access section 时，编译器不需要在数据成员的间隙中插入额外数据，也不需要决定多个 section 的相对位置，此时对象的内存布局和 C 的结构体是兼容的 text +-----------+ | | | int x | | | +-----------+ | | | int y | | | +-----------+ | char z | +-----------+ | | | padding | | | +-----------+ 确定了 A 的内存布局后，A 的非静态数据成员的偏移也就可以在编译期确定，在 A 的非静态成员函数中，访问x y z时，通过隐含的this指针间接访问，等价于 C 的结构体成员的访问 cpp A::foo(){ return x + y; // this-\u003ex + this-\u003ey } 末尾加的 padding 是为了对齐，但这句话太过教科书了。A 的对齐要求是首地址必须是 4 的倍数，在末尾加上 3 字节的 padding 是为了保证在一块内存中连续存放 A 的对象时，下一个对象能够紧邻上一个对象并保证对齐要求。而且在逐字节复制时，在 CISC 架构上可以使用效率更高的专用指令 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:2:1","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#普通对象的内存布局"},{"categories":null,"content":" 单继承时 cpp class Base{ int x; char y; }; class Derived: Base{ char z; }; Derived 对象分为两个部分，一个是完整的 Base 对象，另一个是 Derived 的所有非静态成员。也可以说 Derived 对象中有 Base subobject 这两个部分如何排放，标准没有要求。但编译器往往把 Base 放在开头而 Derived 放到末尾，这样就能实现Base* b = new Derived派生类向上 cast 到基类时，cast 没有运行时开销 text Base Derived ?? +-----------+ +-----------+ +-----------+ | | | | | | | int x | | int x | | int x | | | | | | | +-----------+ +-----------+ +-----------+ | char y | | char y | | char y | +-----------+ +-----------+ +-----------+ | | | | | char z | | padding | | padding | +-----------+ | | | | | padding | +-----------+ +-----------+ +-----------+ | char z | +-----------+ | | | padding | | | +-----------+ 派生类的大小为 12 字节，其中有 6 个字节的 padding，为什么不能像??中表示的那样char z利用Base末尾的 padding 呢？ 这里提出一个标准中没有，但书中有的词：Bitwise Semantics. 与 Bitwise 相对的还有 member-wise。一个好的编译器应当在大部分情况下都能生成 Bitwise 的复制构造函数，即当复制对象时，不需要 member-wise 复制而是 Bitwise 的复制。当遵守 Bitwise Semantics 时，编译器能够省去函数调用、逐个复制数据的开销，转而使用高效的专用指令 cpp Base *b = new Base; Base *d = new Derived; *d = *b; 这段代码显然是良定义的，他产生的效果是 Base 对象复制到 Derived 对象的 Base subobject 中，而Derived::z不会被覆盖。为了能够遵守 Bitwise Semantics，编译器仍然保留了 Base subobject 中的 padding，否则Derived::z被 padding 覆盖，其值是未定义的 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:2:2","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#单继承时"},{"categories":null,"content":" 使用虚拟函数时所谓多态，可以理解为派生类对象能够完美的嵌入到基类对象的地方。USB3.0 公口能够完美的插入到 USB2.0 的母口中并正常传输数据，这是因为 USB3.0 接口在电气特性和物理特性上兼容 USB2.0 接口，例如任何 USB2.0 定义的针脚也是 USB3.0 定义的针脚；USB2.0 接口具有和 USB3.0 相同的形状，这提示我们：派生类对象和基类对象在内存布局上具有相似性 但是在不使用虚拟机制时，派生类对象和基类对象在内存布局上也具有相似性。于是这里引入第二个条件：虚拟机制需要在对象中开辟一块空间存放运行时信息，用于完成多态的运行时绑定。结合两个信息可以得知：派生类和基类对象中都有这块空间，而且他们的非静态数据成员和这块空间形成的整体在内存布局上具有相似性 那么如何保存这个信息呢，以下使用渐进的思考方式解释为什么编译器都使用了相同的多态实现方法：虚函数表指针 Note 以下方案只是我的猜想，不保证可行性 多态方案 1第一个想法是编译器为每一个类确定一个唯一的 id，然后将 id 嵌入到对象中，运行时系统可以取出 id，根据 id 查询到对应的类，并通过这个类保存的元信息找到需要调用的虚拟函数 这个方案已经有 Runtime Type Identification(RTTI) 的雏形，通过从对象中取出 id，可以在运行时获取到对象的运行时类型，以支持基类指针尝试向下 cast，即dynamic_cast 考虑 id 嵌入的位置，标准允许嵌入到任何数据成员的间隙，但一般的做法是放到对象开头或结尾，因为这样可以维护最少的元数据 cpp class Point{ int _x; } class Point2d: public Point{ public: virtual int z(){ return 0; } private: int _y; } class Point3d: public Point2d{ public: virtual int z(){ return _z; } private: int _z; } 考虑这样的类，内存布局如下 text object header Point Point2d Point3d +-----------+ +-----------+ +-----------+ | int x | | id | | id | +-----------+ +-----------+ +-----------+ | int x | | int x | +-----------+ +-----------+ | int y | | int y | +-----------+ +-----------+ | int z | +-----------+ object footer Point Point2d Point3d +-----------+ +-----------+ +-----------+ | int x | | int x | | int x | +-----------+ +-----------+ +-----------+ | int y | | int y | +-----------+ +-----------+ | id | | id | +-----------+ +-----------+ | int z | +-----------+ 以上给出了将 id 分别放到对象开头或结尾的例子，我称之为 object header 方案和 object footer 方案 这两种方案孰优孰劣？ 将 id 放到开头时，任何支持虚拟机制的对象都能在首地址找到 id，即 id 的偏移为零，不需要额外的偏移加法计算，性能最好。而且零是编译期常量，省去了维护元信息的开销。但继承了没有虚拟函数的类时，向上 cast 需要额外操作 将 id 放到结尾时，向上 cast 到没有虚拟函数的类时没有额外操作。运行时取出 id 也只需要 inheritance hierachy 中有虚拟函数的最基类的类型的大小，这也是编译期常量 这个方案有不少问题：为了支持不同编译器的编译产物链接到一起能够正常运行，需要保证不同编译器对同一个类产生的 id 是相同的，而且两个不同类的 id 不能相同。人们可以写下几乎无穷个类，但 id 的大小需要在编译期确定下来而且在不同编译器之间达成约定，即 id 的大小是固定的。根据 鸽笼原理，一定会有两不同的类，他们的 id 相同 更进一步，什么是同一个类？C++的类型系统是 Nominal type system，即使存在两个类名之外完全相同的类 cpp class A{ int x; } class B{ int x; } 这两个类也是不同的 那么什么类是相同的？根据 Nominal type system 的定义，只有显式声明两个类相同或两个类名称相同 In computer science, a type system is nominal (also called nominative or name-based) if compatibility and equivalence of data types is determined by explicit declarations and/or the name of the types 这句话就是废话，C++不存在声明两个类具有相同关系的语法，也不允许重复声明一个类。但 Nominal type system 的定义暗示我们，类的名称可以作为唯一标识类的方法，当然在 C++，还得加上一个条件，名称中必须包含或者能够反映它所在的名称空间。于是提出第二个方案 多态方案 2将类的名称作为唯一标识类的方法，其他与多态方案 1 保持一致。 由于类的名称是变长而且不存在运行时修改手段，所以可以在编译期确定类的名称并保存在数据段中，对象中仅仅存放指针。不同编译器的编译产物链接到一起时，它们应当是 ABI 兼容的，所以无论类的名称有没有经过符号修饰，不同编译器都能在类的名称上取得一致 接下来考虑第二个问题：如何组织元信息管理系统，能够在运行时取得类的名称后，查询到具体调用的函数？ C++没有提供运行时给一个类增加、删除、修改虚拟函数的方法，所以一个类有哪些虚拟函数是编译期能够确定的，即编译期常量。所以完全可以把查询这个动作在编译期完成，所以可以直接把这个类所有的虚拟函数的指针嵌入到对象中 但是这个方法又引入了新的问题，派生类能够增加新的虚拟函数，导致虚拟函数的指针个数增加，给「保证派生类对象的内存布局和基类相似」增加了难度。这里给出一个巧妙的方法，将虚拟函数的指针和类的名称组织在一起（因为它们都在数据段中，这是可行的） text +------------+ +-------------+ | ptr |------------\u003e | class name | +------------+ +-------------+ | | | ptr to func | | class | +-------------+ | data | | ptr to func | | | +-------------+ +------------+ 到了这步，恭喜你重新发明了虚函数表 编译器的方案 图中Point也有虚拟方法，作者给出的是 cfront 实现，cfront 选择将运行时信息插入到对象尾部 这个方案当然也不是完美的，使用函数指针引入了一层间接，使用 vptr 又引入了一层间接，降低了性能 一个提高性能的方法是将函数指针直接嵌入到对象中，代价是增加了对象大小，而且派生类中增加的虚拟函数可能无法嵌入 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:2:3","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#使用虚拟函数时"},{"categories":null,"content":" 使用虚拟函数时所谓多态，可以理解为派生类对象能够完美的嵌入到基类对象的地方。USB3.0 公口能够完美的插入到 USB2.0 的母口中并正常传输数据，这是因为 USB3.0 接口在电气特性和物理特性上兼容 USB2.0 接口，例如任何 USB2.0 定义的针脚也是 USB3.0 定义的针脚；USB2.0 接口具有和 USB3.0 相同的形状，这提示我们：派生类对象和基类对象在内存布局上具有相似性 但是在不使用虚拟机制时，派生类对象和基类对象在内存布局上也具有相似性。于是这里引入第二个条件：虚拟机制需要在对象中开辟一块空间存放运行时信息，用于完成多态的运行时绑定。结合两个信息可以得知：派生类和基类对象中都有这块空间，而且他们的非静态数据成员和这块空间形成的整体在内存布局上具有相似性 那么如何保存这个信息呢，以下使用渐进的思考方式解释为什么编译器都使用了相同的多态实现方法：虚函数表指针 Note 以下方案只是我的猜想，不保证可行性 多态方案 1第一个想法是编译器为每一个类确定一个唯一的 id，然后将 id 嵌入到对象中，运行时系统可以取出 id，根据 id 查询到对应的类，并通过这个类保存的元信息找到需要调用的虚拟函数 这个方案已经有 Runtime Type Identification(RTTI) 的雏形，通过从对象中取出 id，可以在运行时获取到对象的运行时类型，以支持基类指针尝试向下 cast，即dynamic_cast 考虑 id 嵌入的位置，标准允许嵌入到任何数据成员的间隙，但一般的做法是放到对象开头或结尾，因为这样可以维护最少的元数据 cpp class Point{ int _x; } class Point2d: public Point{ public: virtual int z(){ return 0; } private: int _y; } class Point3d: public Point2d{ public: virtual int z(){ return _z; } private: int _z; } 考虑这样的类，内存布局如下 text object header Point Point2d Point3d +-----------+ +-----------+ +-----------+ | int x | | id | | id | +-----------+ +-----------+ +-----------+ | int x | | int x | +-----------+ +-----------+ | int y | | int y | +-----------+ +-----------+ | int z | +-----------+ object footer Point Point2d Point3d +-----------+ +-----------+ +-----------+ | int x | | int x | | int x | +-----------+ +-----------+ +-----------+ | int y | | int y | +-----------+ +-----------+ | id | | id | +-----------+ +-----------+ | int z | +-----------+ 以上给出了将 id 分别放到对象开头或结尾的例子，我称之为 object header 方案和 object footer 方案 这两种方案孰优孰劣？ 将 id 放到开头时，任何支持虚拟机制的对象都能在首地址找到 id，即 id 的偏移为零，不需要额外的偏移加法计算，性能最好。而且零是编译期常量，省去了维护元信息的开销。但继承了没有虚拟函数的类时，向上 cast 需要额外操作 将 id 放到结尾时，向上 cast 到没有虚拟函数的类时没有额外操作。运行时取出 id 也只需要 inheritance hierachy 中有虚拟函数的最基类的类型的大小，这也是编译期常量 这个方案有不少问题：为了支持不同编译器的编译产物链接到一起能够正常运行，需要保证不同编译器对同一个类产生的 id 是相同的，而且两个不同类的 id 不能相同。人们可以写下几乎无穷个类，但 id 的大小需要在编译期确定下来而且在不同编译器之间达成约定，即 id 的大小是固定的。根据 鸽笼原理，一定会有两不同的类，他们的 id 相同 更进一步，什么是同一个类？C++的类型系统是 Nominal type system，即使存在两个类名之外完全相同的类 cpp class A{ int x; } class B{ int x; } 这两个类也是不同的 那么什么类是相同的？根据 Nominal type system 的定义，只有显式声明两个类相同或两个类名称相同 In computer science, a type system is nominal (also called nominative or name-based) if compatibility and equivalence of data types is determined by explicit declarations and/or the name of the types 这句话就是废话，C++不存在声明两个类具有相同关系的语法，也不允许重复声明一个类。但 Nominal type system 的定义暗示我们，类的名称可以作为唯一标识类的方法，当然在 C++，还得加上一个条件，名称中必须包含或者能够反映它所在的名称空间。于是提出第二个方案 多态方案 2将类的名称作为唯一标识类的方法，其他与多态方案 1 保持一致。 由于类的名称是变长而且不存在运行时修改手段，所以可以在编译期确定类的名称并保存在数据段中，对象中仅仅存放指针。不同编译器的编译产物链接到一起时，它们应当是 ABI 兼容的，所以无论类的名称有没有经过符号修饰，不同编译器都能在类的名称上取得一致 接下来考虑第二个问题：如何组织元信息管理系统，能够在运行时取得类的名称后，查询到具体调用的函数？ C++没有提供运行时给一个类增加、删除、修改虚拟函数的方法，所以一个类有哪些虚拟函数是编译期能够确定的，即编译期常量。所以完全可以把查询这个动作在编译期完成，所以可以直接把这个类所有的虚拟函数的指针嵌入到对象中 但是这个方法又引入了新的问题，派生类能够增加新的虚拟函数，导致虚拟函数的指针个数增加，给「保证派生类对象的内存布局和基类相似」增加了难度。这里给出一个巧妙的方法，将虚拟函数的指针和类的名称组织在一起（因为它们都在数据段中，这是可行的） text +------------+ +-------------+ | ptr |------------\u003e | class name | +------------+ +-------------+ | | | ptr to func | | class | +-------------+ | data | | ptr to func | | | +-------------+ +------------+ 到了这步，恭喜你重新发明了虚函数表 编译器的方案 图中Point也有虚拟方法，作者给出的是 cfront 实现，cfront 选择将运行时信息插入到对象尾部 这个方案当然也不是完美的，使用函数指针引入了一层间接，使用 vptr 又引入了一层间接，降低了性能 一个提高性能的方法是将函数指针直接嵌入到对象中，代价是增加了对象大小，而且派生类中增加的虚拟函数可能无法嵌入 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:2:3","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#多态方案-1"},{"categories":null,"content":" 使用虚拟函数时所谓多态，可以理解为派生类对象能够完美的嵌入到基类对象的地方。USB3.0 公口能够完美的插入到 USB2.0 的母口中并正常传输数据，这是因为 USB3.0 接口在电气特性和物理特性上兼容 USB2.0 接口，例如任何 USB2.0 定义的针脚也是 USB3.0 定义的针脚；USB2.0 接口具有和 USB3.0 相同的形状，这提示我们：派生类对象和基类对象在内存布局上具有相似性 但是在不使用虚拟机制时，派生类对象和基类对象在内存布局上也具有相似性。于是这里引入第二个条件：虚拟机制需要在对象中开辟一块空间存放运行时信息，用于完成多态的运行时绑定。结合两个信息可以得知：派生类和基类对象中都有这块空间，而且他们的非静态数据成员和这块空间形成的整体在内存布局上具有相似性 那么如何保存这个信息呢，以下使用渐进的思考方式解释为什么编译器都使用了相同的多态实现方法：虚函数表指针 Note 以下方案只是我的猜想，不保证可行性 多态方案 1第一个想法是编译器为每一个类确定一个唯一的 id，然后将 id 嵌入到对象中，运行时系统可以取出 id，根据 id 查询到对应的类，并通过这个类保存的元信息找到需要调用的虚拟函数 这个方案已经有 Runtime Type Identification(RTTI) 的雏形，通过从对象中取出 id，可以在运行时获取到对象的运行时类型，以支持基类指针尝试向下 cast，即dynamic_cast 考虑 id 嵌入的位置，标准允许嵌入到任何数据成员的间隙，但一般的做法是放到对象开头或结尾，因为这样可以维护最少的元数据 cpp class Point{ int _x; } class Point2d: public Point{ public: virtual int z(){ return 0; } private: int _y; } class Point3d: public Point2d{ public: virtual int z(){ return _z; } private: int _z; } 考虑这样的类，内存布局如下 text object header Point Point2d Point3d +-----------+ +-----------+ +-----------+ | int x | | id | | id | +-----------+ +-----------+ +-----------+ | int x | | int x | +-----------+ +-----------+ | int y | | int y | +-----------+ +-----------+ | int z | +-----------+ object footer Point Point2d Point3d +-----------+ +-----------+ +-----------+ | int x | | int x | | int x | +-----------+ +-----------+ +-----------+ | int y | | int y | +-----------+ +-----------+ | id | | id | +-----------+ +-----------+ | int z | +-----------+ 以上给出了将 id 分别放到对象开头或结尾的例子，我称之为 object header 方案和 object footer 方案 这两种方案孰优孰劣？ 将 id 放到开头时，任何支持虚拟机制的对象都能在首地址找到 id，即 id 的偏移为零，不需要额外的偏移加法计算，性能最好。而且零是编译期常量，省去了维护元信息的开销。但继承了没有虚拟函数的类时，向上 cast 需要额外操作 将 id 放到结尾时，向上 cast 到没有虚拟函数的类时没有额外操作。运行时取出 id 也只需要 inheritance hierachy 中有虚拟函数的最基类的类型的大小，这也是编译期常量 这个方案有不少问题：为了支持不同编译器的编译产物链接到一起能够正常运行，需要保证不同编译器对同一个类产生的 id 是相同的，而且两个不同类的 id 不能相同。人们可以写下几乎无穷个类，但 id 的大小需要在编译期确定下来而且在不同编译器之间达成约定，即 id 的大小是固定的。根据 鸽笼原理，一定会有两不同的类，他们的 id 相同 更进一步，什么是同一个类？C++的类型系统是 Nominal type system，即使存在两个类名之外完全相同的类 cpp class A{ int x; } class B{ int x; } 这两个类也是不同的 那么什么类是相同的？根据 Nominal type system 的定义，只有显式声明两个类相同或两个类名称相同 In computer science, a type system is nominal (also called nominative or name-based) if compatibility and equivalence of data types is determined by explicit declarations and/or the name of the types 这句话就是废话，C++不存在声明两个类具有相同关系的语法，也不允许重复声明一个类。但 Nominal type system 的定义暗示我们，类的名称可以作为唯一标识类的方法，当然在 C++，还得加上一个条件，名称中必须包含或者能够反映它所在的名称空间。于是提出第二个方案 多态方案 2将类的名称作为唯一标识类的方法，其他与多态方案 1 保持一致。 由于类的名称是变长而且不存在运行时修改手段，所以可以在编译期确定类的名称并保存在数据段中，对象中仅仅存放指针。不同编译器的编译产物链接到一起时，它们应当是 ABI 兼容的，所以无论类的名称有没有经过符号修饰，不同编译器都能在类的名称上取得一致 接下来考虑第二个问题：如何组织元信息管理系统，能够在运行时取得类的名称后，查询到具体调用的函数？ C++没有提供运行时给一个类增加、删除、修改虚拟函数的方法，所以一个类有哪些虚拟函数是编译期能够确定的，即编译期常量。所以完全可以把查询这个动作在编译期完成，所以可以直接把这个类所有的虚拟函数的指针嵌入到对象中 但是这个方法又引入了新的问题，派生类能够增加新的虚拟函数，导致虚拟函数的指针个数增加，给「保证派生类对象的内存布局和基类相似」增加了难度。这里给出一个巧妙的方法，将虚拟函数的指针和类的名称组织在一起（因为它们都在数据段中，这是可行的） text +------------+ +-------------+ | ptr |------------\u003e | class name | +------------+ +-------------+ | | | ptr to func | | class | +-------------+ | data | | ptr to func | | | +-------------+ +------------+ 到了这步，恭喜你重新发明了虚函数表 编译器的方案 图中Point也有虚拟方法，作者给出的是 cfront 实现，cfront 选择将运行时信息插入到对象尾部 这个方案当然也不是完美的，使用函数指针引入了一层间接，使用 vptr 又引入了一层间接，降低了性能 一个提高性能的方法是将函数指针直接嵌入到对象中，代价是增加了对象大小，而且派生类中增加的虚拟函数可能无法嵌入 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:2:3","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#多态方案-2"},{"categories":null,"content":" 使用虚拟函数时所谓多态，可以理解为派生类对象能够完美的嵌入到基类对象的地方。USB3.0 公口能够完美的插入到 USB2.0 的母口中并正常传输数据，这是因为 USB3.0 接口在电气特性和物理特性上兼容 USB2.0 接口，例如任何 USB2.0 定义的针脚也是 USB3.0 定义的针脚；USB2.0 接口具有和 USB3.0 相同的形状，这提示我们：派生类对象和基类对象在内存布局上具有相似性 但是在不使用虚拟机制时，派生类对象和基类对象在内存布局上也具有相似性。于是这里引入第二个条件：虚拟机制需要在对象中开辟一块空间存放运行时信息，用于完成多态的运行时绑定。结合两个信息可以得知：派生类和基类对象中都有这块空间，而且他们的非静态数据成员和这块空间形成的整体在内存布局上具有相似性 那么如何保存这个信息呢，以下使用渐进的思考方式解释为什么编译器都使用了相同的多态实现方法：虚函数表指针 Note 以下方案只是我的猜想，不保证可行性 多态方案 1第一个想法是编译器为每一个类确定一个唯一的 id，然后将 id 嵌入到对象中，运行时系统可以取出 id，根据 id 查询到对应的类，并通过这个类保存的元信息找到需要调用的虚拟函数 这个方案已经有 Runtime Type Identification(RTTI) 的雏形，通过从对象中取出 id，可以在运行时获取到对象的运行时类型，以支持基类指针尝试向下 cast，即dynamic_cast 考虑 id 嵌入的位置，标准允许嵌入到任何数据成员的间隙，但一般的做法是放到对象开头或结尾，因为这样可以维护最少的元数据 cpp class Point{ int _x; } class Point2d: public Point{ public: virtual int z(){ return 0; } private: int _y; } class Point3d: public Point2d{ public: virtual int z(){ return _z; } private: int _z; } 考虑这样的类，内存布局如下 text object header Point Point2d Point3d +-----------+ +-----------+ +-----------+ | int x | | id | | id | +-----------+ +-----------+ +-----------+ | int x | | int x | +-----------+ +-----------+ | int y | | int y | +-----------+ +-----------+ | int z | +-----------+ object footer Point Point2d Point3d +-----------+ +-----------+ +-----------+ | int x | | int x | | int x | +-----------+ +-----------+ +-----------+ | int y | | int y | +-----------+ +-----------+ | id | | id | +-----------+ +-----------+ | int z | +-----------+ 以上给出了将 id 分别放到对象开头或结尾的例子，我称之为 object header 方案和 object footer 方案 这两种方案孰优孰劣？ 将 id 放到开头时，任何支持虚拟机制的对象都能在首地址找到 id，即 id 的偏移为零，不需要额外的偏移加法计算，性能最好。而且零是编译期常量，省去了维护元信息的开销。但继承了没有虚拟函数的类时，向上 cast 需要额外操作 将 id 放到结尾时，向上 cast 到没有虚拟函数的类时没有额外操作。运行时取出 id 也只需要 inheritance hierachy 中有虚拟函数的最基类的类型的大小，这也是编译期常量 这个方案有不少问题：为了支持不同编译器的编译产物链接到一起能够正常运行，需要保证不同编译器对同一个类产生的 id 是相同的，而且两个不同类的 id 不能相同。人们可以写下几乎无穷个类，但 id 的大小需要在编译期确定下来而且在不同编译器之间达成约定，即 id 的大小是固定的。根据 鸽笼原理，一定会有两不同的类，他们的 id 相同 更进一步，什么是同一个类？C++的类型系统是 Nominal type system，即使存在两个类名之外完全相同的类 cpp class A{ int x; } class B{ int x; } 这两个类也是不同的 那么什么类是相同的？根据 Nominal type system 的定义，只有显式声明两个类相同或两个类名称相同 In computer science, a type system is nominal (also called nominative or name-based) if compatibility and equivalence of data types is determined by explicit declarations and/or the name of the types 这句话就是废话，C++不存在声明两个类具有相同关系的语法，也不允许重复声明一个类。但 Nominal type system 的定义暗示我们，类的名称可以作为唯一标识类的方法，当然在 C++，还得加上一个条件，名称中必须包含或者能够反映它所在的名称空间。于是提出第二个方案 多态方案 2将类的名称作为唯一标识类的方法，其他与多态方案 1 保持一致。 由于类的名称是变长而且不存在运行时修改手段，所以可以在编译期确定类的名称并保存在数据段中，对象中仅仅存放指针。不同编译器的编译产物链接到一起时，它们应当是 ABI 兼容的，所以无论类的名称有没有经过符号修饰，不同编译器都能在类的名称上取得一致 接下来考虑第二个问题：如何组织元信息管理系统，能够在运行时取得类的名称后，查询到具体调用的函数？ C++没有提供运行时给一个类增加、删除、修改虚拟函数的方法，所以一个类有哪些虚拟函数是编译期能够确定的，即编译期常量。所以完全可以把查询这个动作在编译期完成，所以可以直接把这个类所有的虚拟函数的指针嵌入到对象中 但是这个方法又引入了新的问题，派生类能够增加新的虚拟函数，导致虚拟函数的指针个数增加，给「保证派生类对象的内存布局和基类相似」增加了难度。这里给出一个巧妙的方法，将虚拟函数的指针和类的名称组织在一起（因为它们都在数据段中，这是可行的） text +------------+ +-------------+ | ptr |------------\u003e | class name | +------------+ +-------------+ | | | ptr to func | | class | +-------------+ | data | | ptr to func | | | +-------------+ +------------+ 到了这步，恭喜你重新发明了虚函数表 编译器的方案 图中Point也有虚拟方法，作者给出的是 cfront 实现，cfront 选择将运行时信息插入到对象尾部 这个方案当然也不是完美的，使用函数指针引入了一层间接，使用 vptr 又引入了一层间接，降低了性能 一个提高性能的方法是将函数指针直接嵌入到对象中，代价是增加了对象大小，而且派生类中增加的虚拟函数可能无法嵌入 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:2:3","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#编译器的方案"},{"categories":null,"content":" 使用多继承时/使用虚拟继承时一个非常经典的多继承用例是标准库中的 iostream iostream 既是 istream 也是 ostream，即 iostream 既是 istream 的派生类也是 ostream 的派生类 我不想花太多篇幅在虚拟继承上，因为我认为这是一个“不值得”的特性，他的实现方式比较复杂，需要考虑的 corner case 比较多，但使用场景少，而且也有一些坑点 iostream 对象中既有 istream subobect 也有 ostream subobject istream subobect 和 ostream subobject 共享一个 ios 对象，这需要虚拟继承机制 istream 对象和 ostream subobject 中增加一个指针用于指向 ios 基类对象，这样的设计允许他们共享一个 ios 对象 棱形继承的对象构造比较复杂，而且它的复制构造函数难以正确安全的实现，标准没有给出一个可靠的方案 尽量不使用棱形继承，不了解棱形继承就不要使用棱形继承 多继承、无虚拟继承的布局 棱形继承时的布局 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:2:4","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#使用多继承时使用虚拟继承时"},{"categories":null,"content":" 构造、析构、复制、移动语义可以非常粗略的认为，C++中的对象生命期开始于构造函数的调用，结束于析构函数的调用 在构造具有继承关系的对象时，编译器根据分散在基类构造函数、类内初始化代码、初始化列表、构造函数的代码合成一个最终的构造函数。这个构造函数按照以下次序完成对象的构造 按声明顺序调用基类构造函数（单继承、多继承时），如果用户没有显示调用，则执行默认初始化 将类内构造代码和初始化列表合并，按照声明顺序逐个完成所有非静态数据成员的初始化。如果用户没有提供某个数据成员的初始化代码，则执行默认初始化 将 vptr（如果有虚拟机制）设为当前类对应的虚拟函数表的地址 执行构造函数的函数体中用户提供的代码 如果有棱形继承，为了保证虚拟基类对象在合适的时机只初始化一次，编译器会在背后做更多工作 第三步保证了在初始化多层单继承关系的中间对象时，虚拟机制被禁用。以 Point3d 继承 Point2d 继承 Point 为例，初始化 Point3d 对象需要先初始化 Point，然后初始化 Point2d，最后初始化 Point3d，即 Point3d 是沿着 inheritance hierachy 逐步完成初始化的，在这个过程中，当前正在初始化的对象依次是合法的 Point 对象、Point2d 对象、Point3d 对象 由于以上所说的初始化顺序，导致初始化 Point3d 的 Point2d subobject 时，Point3d 还未完成初始化，形象的表述就是还未存在，自然不能使用虚拟机制调用 Point3d 的虚拟函数 与构造函数相反，析构函数会按照初始化的顺序逆序完成析构 当用户没有提供复制构造函数、复制操作符、移动构造函数、移动操作符（以下简称四件套函数）时，编译器会合成（如果可行）member-wise 的四件套函数，这些函数调用逐个成员的四件套函数和基类的四件套函数 一个好的编译器也应当尽可能的实现 Bitwise Semantics，此时编译器可以生成逐字节复制的四件套函数。在实践中此时的四件套函数不会被合成也不会被调用，而是直接内联 编译器实现 Bitwise Semantics 时应当保证它和 member-wise 的行为产生的结果相同，因此至少会增加以下条件 用户没有提供四件套函数，因为一般认为用户提供的代码可能有副作用 编译器没有“悄悄”在对象中插入一些额外的数据（包括虚拟函数表指针，虚拟基类对象指针），因为派生类和基类的「额外数据」一般不同，而四件套函数应当正确处理派生类和基类 由此可以得出有虚拟函数的类、inheritance hierachy 中存在虚拟继承的类不能实现四件套函数的 Bitwise Semantics 同样，构造函数和析构函数也有 Bitwise Semantics，如果实现了 Bitwise Semantics，不严谨的说，编译器可以执行和原始数据类型相同的默认初始化，原始数据类型的默认初始化就是不初始化，其值分为若干种 函数内部的自动变量，其值未定义 全局变量，其值为零 堆上的变量，其值未定义 同样的，构造函数和析构函数能够实现 Bitwise Semantics 也至少有一些条件 用户没有提供构造函数或析构函数，因为一般认为用户提供的代码可能有副作用 编译器没有“悄悄”在对象中插入一些额外的数据（包括虚拟函数表指针，虚拟基类对象指针） 由此可以得出有虚拟函数的类、inheritance hierachy 中存在虚拟继承的类不能实现构造函数和析构函的 Bitwise Semantics 如果一个类的四件套函数和构造函数、析构函数都能实现 Bitwise Semantics，此时它就具有和原始数据类型、或者说 C 的结构体相同的特性，能够随意复制到一块内存，又从一块内存中复制回来，这样的类能够随意传入 C 写的库被处理，C 库返回的结构体也能零运行时开销的 cast 到这个类的对象而符合 C++语义，这就是 C++和 C 能够安全互操作的区域 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:3:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#构造析构复制移动语义"},{"categories":null,"content":" 为什么说 C 和 C++兼容作者并没有在书中回答这个问题，只是我在阅读过程中产生了这个问题的答案 我认为原因是 C 和 C++的编译系统、链接系统（这个词是我胡编乱造出来的）、运行时系统是兼容的，这里的兼容包括两个层面，第一个层面是 C++与 C 共用相同的底层原语，第二个层面是 C++和 C 的系统能够安全的共存，例如 C 和 C++在 linux 平台编译后都会产生 ELF，都能使用静态链接器或动态链接器识别和处理，这也决定了 C 和 C++可以相互链接 C++拥有 C 的原始数据类型，C++也能使用 C 的语法，这决定了在语言层面上 C 和 C++互操作几乎不需要胶水代码 C++的内存分配系统虽然多了构造对象和销毁对象的功能，但内部也会使用 libc 的内存分配系统，而且两者的符号名不一样，所以 C++的内存分配系统和 C 的内存分配系统能够共存 C++的对象如果不使用虚拟函数、继承等 C++特性，可以在符合 C++面向对象语义要求的同时具有和 C 的结构体相同的内存布局，这决定了数据结构能够跨运行时传递，或者说无缝互操作 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:4:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#为什么说-c-和-c兼容"},{"categories":null,"content":" 异常处理和对象生命期异常可能在任何地方抛出、终止当前流程并执行栈倒带，但异常处理也应当遵守 C++对象生命期的语义，所以在栈倒带之前，需要销毁当前函数执行迄今构造的所有的栈上的对象，这个是编译器插入额外代码追踪对象构造情况、根据对象构造情况条件地销毁对象实现的。当然这些额外插入的代码会降低运行时性能、增大二进制体积，我想这也是 google 说“we don’t use exceptions”的原因之一 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:5:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#异常处理和对象生命期"},{"categories":null,"content":" 正确看待某些特性前文我提到了棱形继承的缺点，但我更想强调的是要合理的看待缺点 在批评棱形继承前，应该先清楚，「没有调查就没有发言权」，作为一个技术，它想解决什么问题，实际解决了什么问题，又带来了哪些新问题。于是在使用棱形继承时，我们就能够利用它解决问题并避免它带来的问题。 还要知道这一点：任何技术只要进入了生产环境并创造了价值，那就说明这个技术是有可取之处的 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:6:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#正确看待某些特性"},{"categories":null,"content":" 总结《Inside the C++ Object Model》我个人评价非常高，可以说是 C++必读书籍。读完后再来看 C++20，就会发现虽然二十多年过去了，标准大变样，但其背后的原理、核心没有改变。这本书的精华也就在其讲述的原理、核心，而它提及的一些标准只能作为“过去的标准”的参考 看完这本书就精通 C++了？当然不可能，还差的多，不过至少算是前进了一步吧。 ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:7:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#总结"},{"categories":null,"content":" append最近看了很多人的文章和书籍，逐渐认识到了读许多书、提升内在才能写出有价值的文章。未来我也会写更多本文这样偏读后记的文章，下篇大概率是《最好的告别》的读后记，敬请期待！ 最后，附上最近反复听的一首音乐 独りきりで泣いた夜に出会った この世で一番孤独なこえ 独りきりで泣いたと思っていた ふたりきりだった 同じ温度で唄えたなら ","date":"2024-12-19","objectID":"/posts/cpp_object_model_overview/:8:0","series":null,"tags":null,"title":"《Inside the C++ Object Model》读后记 —— 为什么 C++ 和 C 可以互操作","uri":"/posts/cpp_object_model_overview/#append"},{"categories":null,"content":"自八月底实习结束，可以说经历了各种事情，现在回想起实习甚至有点陌生 这篇文章我想向各位读者讲述一下从八月到十一月，从实习离职、秋招、oceanbase 比赛发生的许多有意义的事情，顺便也记录一下我对这些事情的观点。同时这篇博客应该也是我的第一篇非纯技术分享的文章 不过在回顾之前，我想先宣布一件最近发生的事情 ","date":"2024-12-03","objectID":"/posts/since_aguast/:0:0","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#"},{"categories":null,"content":" 买了新域名！最近买了一个特别喜欢的域名 z2z63.dev，并将博客也迁移到blog.z2z63.dev。z2z63是我常用的一个 ID，也是我 github 的用户名，这个 ID 看起来就是一个随机字符串，来源也是非常随便，若干年前注册 steam 时由于只能用英文用户名，就在键盘上随便乱敲敲出了这个 ID，字面意义上的随机字符串 ","date":"2024-12-03","objectID":"/posts/since_aguast/:1:0","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#买了新域名"},{"categories":null,"content":" 实习离职了实习开始时，我就在犹豫要不要转正，一方面因为想做后台，另一方面因为自己实习时间比较短，担心能不能转正。就这样犹豫到了八月中旬，加上学校那边也是不得不回，终于下定决心离职然后秋招找后台的工作 这里非常感谢我的一位 gal 游戏搭子，听了我倾诉一大堆东西，最后帮助我下定决心。最后我想请他吃饭表示感谢时 同时也感谢一位同学，实习期间我们经常分享彼此的日常 这里是深圳的中山公园地铁站，每天上班时这里一辆共享单车也没有，下班时一大片的共享单车 前司的茶水间前有块非常大的玻璃幕墙，茶水间里有各种茶叶，冷水热水常温水，咖啡机，制冰机（我超级喜欢），共享冰箱 实习第一天，早上十点上班，晚上十点下班！走出公司大厦时想着：“今天终于结束了”，大概就是下班时的心境吧 我的实习简单来说就是在腾讯参与一个全国许多人都用过的一个软件的客户端开发。实习总体来说很开心，公司对实习生要求也不多，上手的项目规模非常庞大，总体来说是一个又轻松又有挑战的一个工作 这里我还想感谢我的 mentor，一位三十多岁的 C++老兵（小组长如是评价，笑)，论水平和经验一定是远超 刚满 20岁，还没到大四的我，却能和我维持一个很好的朋友关系，每天散步时，我总是能和他谈很多技术上的话题（在学校根本找不到这样的机会！），而且能让我感觉在谈论技术话题时，虽然他水平远超我，但仍然是以平等的地位参与讨论。 因为这么好的一位 mentor，我离职时还感觉有点对不起他，于是安慰自己秋招试试能不能再进腾讯。离职当天我来到他工位，算是比较郑重又比较轻松的说了谢谢。希望有一天我还能和 mentor 共事 不得不说腾讯给的是真的多，加上我还有住房补贴和交通补贴，到手的实习工资非常可观。于是我拿人生中的第一桶金请父母和姐姐吃了一顿饭。 提到这件事，我就想说这份实习工作还是挺自由的。当时吃饭的时间定在晚上 6 点后，这个时间下班比较早，我本来打算请假。我询问了 mentor 后，他告诉我说“你有事就可以早点走”，不用告知小组长，也不需要申请什么东西走什么流程，非常自由 后面又了解到其他同事基本也是这样，公司要求的工作时间比较弹性，只要满足部门和项目的要求，是可以提前下班的。比如每周五大家都是晚上 6 点后就走了 公司给的福利相当好，上下班有班车接送，几乎全深圳都能坐到班车，比挤高峰期的地铁好多了！ 公司也有早中晚餐，其中只有午餐收费，价格大概在 21-28 不过网上也有吐槽，比如提供免费早餐和班车送上班是吸引员工早点来公司干活。我认为这说的很有道理，因为在我家附近的上班班车出发时间是早上七点多，而公司平均上班时间是早上 10 点。同时下班班车是晚上 9 点（不同班车的出发时间不一样，只是到我家附近的班车恰好这个点），导致我想早点下班都比较麻烦（自己坐地铁要花更多时间） 提到班车我想再扯一下通勤。由于我家地理位置不好，离互联网公司都远，每天上下班都是横穿大半个深圳。各位读者未来工作一定要选离公司近的地方住，这是非常简单的提升辛福指数的方法 ","date":"2024-12-03","objectID":"/posts/since_aguast/:2:0","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#实习离职了"},{"categories":null,"content":" 实习有什么感想？第一点就是互联网大厂加班是真的严重，虽然腾讯条文上给出的工作时间非常人性化而且轻松，但由于部门或者项目永远缺人力（至少我所在的部门是这样的），加班非常严重 一般加班都有加班费，但在腾讯，首先在工作日干 24h 都不算加班，只有在休息日（例如周末，法定节假日）来上班才是加班。其次，在休息日加班没有加班费，而是增加一天的调休假期。到这里还是很美好，看起来是再怎么加班假期也不会少。但公司还有一个规定，调休假期需要在两个月（或者三个月，大概是这个数字）内休完。如果项目长期很忙，调休假期就可能没来得及休。没来得及休的假期也许有补偿，但我直到离职也不知道补偿是什么 第二点就是了解了大公司的思维模式。大公司不差钱，所以工作环境就能比其他公司好的多。例如我实习第一天报道时，就发了一个 4K 屏，一个主机，有一个性能不错的 Intel 芯片，32G 内存。虽然 4K 屏和 32G 内存是有点贵，但对大公司来说这点钱算不了什么，但要影响到工作效率那就不值得了。 此外，茶水间的配置非常全，因为对大公司来说，提升员工幸福度和工作意愿，或者说员工福利，是一个影响公司名誉，影响员工满意度和忠诚度的事情。而茶水间虽然配置很全要多花钱，但一层楼也就两个茶水间，整个大厦的茶水间都用上咖啡机制冰机，也花不了多少钱，比起增加假期、提供覆盖全深圳的班车来说，是花钱最少、性价比最高的方法 一句话总结，大厂不仅仅是很有钱，而且在该花钱的地方绝不含糊 第三点就是实践真的很重要。在参与了那么大规模的软件的开发流程后，我才意识到之前在学校里写的东西都是玩具。计算机科学中的很多问题只有在参与到广泛的实践与生产中才能领悟，也是实习后我才真正认同了计算机学科是工科。在学校写个玩具只要求实现功能，在公司做产品要考虑很多方面，比如如何规避合规风险，如何服务残障人士，如何保护用户隐私，如何保护公司的企业形象等等。合规成本对大公司来说非常高，所以能规避都会尽量规避，例如防止内部工作人员看到用户隐私信息，在国内版本屏蔽某些功能等，都是首先为了规避合规风险，其次才是符合社会责任 ","date":"2024-12-03","objectID":"/posts/since_aguast/:2:1","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#实习有什么感想"},{"categories":null,"content":" 买了 mac早在实习前就在网上或者在显示中看到别人的 mac 多么漂亮，实习时有位实习生同事（还是他，接下来还会提到他）也用 mac（做mac端的客户端开发）也给我狠狠普及了一波 mac。实习修 bug 时，遇到了一些 bug 在 windows 上怎么都无法复现，后来 mentor 告诉我 mac 的渲染速度比 windows 快的多（至少对于我们这个产品这样的）。加上实习时用惯了 4K，回到宿舍看着 1K 23.8 英寸的屏幕已经看不下去了，感觉网页上的字体肉眼可见的模糊。加上实习也拿到了一笔“巨款”，于是在 9 月买了macbookpro加上一个 4K 显示器。刚刚用上 mac 的那段时间非常惊艳，特别漂亮 mac 的漂亮是有两个层面的，第一个层面是桌面环境大量使用透明、毛玻璃、圆角，加上 mac 内置屏幕素质非常高，相比 windows 的兼容低 dpi，mac 的字体的渲染策略更倾向还原印刷效果，再加上苹方字体比微软雅黑好看太多，三个因素叠加，导致 mac 的字体比 windows 的好看太多（实际原因很复杂，我目前理解的比较浅，希望以后深入理解后能专门写一篇文章来讲） mac的 preview，非常好用的 pdf 阅读工具，图中的毛玻璃效果很好看，字体的渲染非常锐利 mac 桌面环境的播放器 widget，圆角+毛玻璃颜值很高 第二个层面是第三方应用的开发时，设计师往往使用 mac，设计稿也是按照 mac 端的效果来设计（至少我实习时参与开发的产品是这样的），我的 mentor 说，mac 端的效果不能在 windows 端完全还原，首先是两个平台的默认字体的字形有差异，显示文字时总会差几个像素。其次是微软雅黑的字重没有苹方丰富，很多时候只能选择用相似的字重而牺牲了和原型图的一致性。 我的体验是，腾讯很多软件的 mac 端更好用，例如 windows 端的微信，在实习时就有所耳闻，给我的印象是“积重难反“，虽然很多地方做的不好但是改动成本很高（微信 4.0 要出了，大概率是推翻了以前那套方案从头干起），而微信 mac 端，有圆角，有毛玻璃，有深色模式还支持跟随系统，支持调整字体大小 日常用起来很漂亮，唯一的缺点是简单粗暴的拿系统默认语言作为微信默认显示的语言，不能单独设置语言 除了很漂亮，还有其他点我也很喜欢，例如 续航很强，终于可以随心所欲的自习而不用担心电量了 使用场景：刷题，写单文件C++，读书 触摸板很好用，完全可以扔掉鼠标只用触控板，外出时完全不用带鼠标 而且微调设置，装上better touch后，可以解锁更强大的功能。我最常用三指拖拽，二指轻按=右键，二指横扫前进后退，还有我使用 better touch 定制的切换浏览器标签页的手势。 此外，使用触控板浏览网页并滑动时，能清晰的感受到触控板的滑动非常细腻，而且有滑动惯性，体验很好，而我的鼠标滚动则像齿轮一样能明显的感受到存在一个滑动的单位长度。总的来说，使用触控板滑动就像使用手机屏幕滑动那样细腻 硬件配置很高 内置的屏幕分辨率高达 3024 x 1964，而我的 4K屏也就3840 x 2160，14 英寸的屏幕分辨率直追 4K 屏，加上有 P3 色域（P3色域非常高，是专业影视的水平），屏幕素质已经高的离谱了 内置的键盘打字手感不错，虽然肯定不如机械键盘，但在这么短的键程已经是非常优秀的手感了 充电头是磁吸的，线的材质就像尼龙绳一样。加上充电头磁力非常大，直接拔下来要很大力，但从侧面掰出来比较轻松，这点设计我很喜欢 上面夸了那么多 mac，但我还是很想吐槽一下 mac， 8G 内存 \\ 256G 硬盘的配置是什么垃圾，这种配置难道不是生产电子垃圾？ 没有内置剪贴板历史，很难想象剪贴板历史都要第三方 app 去做，而且还能订阅制收费，怎么不去抢劫 我需要用蓝牙共享网络，但这个功能在高版本的系统里被砍掉了 早就听说了homebrew，但真正用的时候才发现homebrew 不是官方的，使用体验完全不如 linux 的包管理器 mac 的逻辑比较像移动系统，比如台前调度侧面的窗口，mac 会自作主张的根据屏幕尺寸帮你设置最大窗口数量，比如在我的 4K 屏上在stage下最多只能有 6 个窗口 ","date":"2024-12-03","objectID":"/posts/since_aguast/:3:0","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#买了-mac"},{"categories":null,"content":" mac适合开发吗？首先我需要强调以下只是我的观点，如果有不一致，欢迎在下方评论区讨论 这个问题需要先排除 macos 开发，因为 macos 开发只能用 mac 在我看来，论开发的方便程度 linux \u003e mac \u003e windows，论日常使用的方便程度 mac ~= windows \u003e linux。原因如下 首先考虑java，python 这样的跨平台的语言，使用 mac 确实没有太大的影响。但很多时候我们面临更多复杂的场景，比如说使用 java 开发，往往使用spring boot，而安装数据库，中间件等操作很明显在 linux 更方便。例如： 如果需要使用 postgresql，在 archlinux 一行命令轻松搞定，如果不想安装在本机，使用 docker 也是一行命令搞定。而在其他平台，如果使用installer 安装，会被带上全家桶（pgAdmin, StackBuilder） 如果需要使用 redis，在 windows 就只能安装到 docker 容器里或者安装到 wsl 中，因为 redis 不支持 windows 如果需要使用 docker，虽然各个平台都有 docker desktop ，但 linux host 的性能是最好的 其次考虑 C/C++，C/C++开发中一个很重要的领域就是和系统交互，而这里指的系统往往是 linux。加上我对操作系统的熟悉程度为linux \u003e windows \u003e macos，在 mac 开发时遇到和操作系统交互的场景就比较头疼 当然 macos 基于 freeBSD，而且是 POSIX-certified，同时也符合Single Unix Specification，所以在操作系统接口层面很多地方和 linux 非常相似 然而遵守 POSIX 和 Single Unix Specification 标准只是听起来很美好。现实情况是，POSIX 和 Single Unix Specification 标准有许多版本，而且有各自的标准扩展。但一个系统只需要符合其中若干版本就能够被称为是符合标准。例如 macos 实际上只遵守 Single Unix Specification 的 UNIX 03版本 正是 mac 像 linux，但有些地方又有所差异，导致我在尝试调用 macos 系统能力时总是畏手畏脚，这点反而不如 windows 而且 freeBSD 跟 linux 不是一家，加上 apple 又给 mac 加上了很多 apple 专有部分，导致有些地方看起来像 linux 实际上不是，例如rm也许是来源于 freeBSD，参数风格和 linux 的 gnu coreutils 有所不同 最后，linux 发行版的包管理器也是一个非常强大的工具。C/C++开发总是少不了第三方库，在依赖不是很严格的情况下，可以直接使用包管理器安装一些 C++第三方库。例如我使用的发行版archlinux，由于许多软件包都依赖一些比较基础的 C/C++ 库，而且 arch 在发行这些库时，会带上头文件和文档，大部分情况下直接写好 cmake，就能直接用第三方库 例如我想引入 zlib 压缩一些东西，可以使用pacman -Qs zlib查询到我已经安装了zlib text local/zlib 1:1.3.1-2 Compression library implementing the deflate compression method found in gzip and PKZIP 然后查询zlib这个包有什么文件 text ➜ pacman -Ql zlib | tree --fromfile . └── zlib └── usr ├── include │ ├── zconf.h │ └── zlib.h ├── lib │ ├── libz.a │ ├── libz.so │ ├── libz.so.1 │ ├── libz.so.1.3.1 │ └── pkgconfig │ └── zlib.pc └── share ├── licenses │ └── zlib │ └── LICENSE └── man └── man3 └── zlib.3.gz 可以轻松看出，我有zlib的库和头文件，这已经足够调用zlib 了。同时还有zlib.pc，所以如何链接到zlib已经不成问题了，将pkg-config --libs zlib的输出作为编译参数传递给编译器即可。了解了 pkg-config的工作原理后，如何写 cmake 链接到 zlib，也化解为「找到 cmake 对 linux 的 pkg-config 的包装」这样一个随手 Google 就能解决的问题 解决了 zlib 引入的问题后，如果对某个参数不了解，可以随手man查看文档，比打开浏览器更方便 当然以上顺畅的工作流还需要一个适合开发的 linux 发行版。例如某些发行版的软件包不带头文件，有的不带静态库，有的版本太旧等等。 从上文可以看出我更倾向在 linux 开发，于是我采取了一个折衷方案，即日常使用 macos，开发远程到 linux，主要使用的工具有 VSCode, Jetbrains Gateway, Windows Remote Desktop（windows 开发不得不用 windows） ","date":"2024-12-03","objectID":"/posts/since_aguast/:3:1","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#mac适合开发吗"},{"categories":null,"content":" 秋招8 月底我提出离职后，总监和我谈话时说：“你秋招很难再找到更好的岗位“，当时我的想法是想经历一次秋招，多一次磨练的机会，因为我拿到实习 offer 的历程太轻松了，甚至连技术笔试都没有，就这样迷迷糊糊的拿到了大厂体验券 准备秋招，首先是确定自己的就业意向，我的意向就是 C++，后台/系统/数据库内核开发。当然系统开发和数据库内核开发是偏技术研究的岗位，本科生基本不可能找到。所以我投的大部分都是C++后台 说实话这个赛道比较窄，因为现在很少有公司会拿 C++ 做后台了，或者说互联网公司用 C++ 的都不多。腾讯我所知的C++用的比较多的公司，腾讯会议是 C++做的，微信客户端是 C++做的，微信后台也是 C++做的。但除了腾讯，大概很少有互联网公司选择 C++ 了 ","date":"2024-12-03","objectID":"/posts/since_aguast/:4:0","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#秋招"},{"categories":null,"content":" 秋招是怎么准备的？我准备秋招的过程包括刷题，复习计算机网络、操作系统、数据库，看八股文，加深对 C++的理解。刷题可以说是进大厂的敲门砖，很遗憾的是我题刷的还是不够多，或者说我根本就没有耐心刷几个月的题。而且我也没有提前刷题，导致秋招刚投的几家直接在笔试被筛了； 计网，操作系统，数据库可以说是科班课程中非常重要的几个了。面试题大部分都跟这几个有关，幸运的是这方面我掌握的还算不错，复习起来很快 看八股文对我来说也就是看常见的面试题。很多面试题的意图是考察面试者对计算机某个领域的理解程度，而这个理解程度就是一个人水平的表现。看八股文不可能快速提升水平，加深理解程度也是需要很多平时的积累，所以在网上经常能看到背八股文的人。我的评价是背八股文没用，以下展开说明 八股文大多是中文表述的，所以找到的八股文资料往往是 CSDN、稀土掘金等社区的文章，质量好点的就是一些个人博客，再好一点的就是一些小书 简中互联网的技术内容不太好，许多文章要么太浅要么有错误 所以有些八股文是不太准确的 我的方法是：八股文只能作为常见面试问题的参考，真正的答案还需要自己思考，需要大胆否定八股文的一些内容。思考常见面试题的答案的过程，也就是练习如何应用计算机基础知识，思路清晰的回答面试题的过程，我认为这才是看八股文最大的意义。 对于面试题，我还是非常有自信的，只要是我擅长的领域基本回答的挺好，举几个我在面试中被问过的题（口语化表述，没有抠细节） C++的static关键字在局部变量，全局变量，函数，成员函数，成员变量上使用时的效果分别是什么 static 修饰局部变量，表示这个变量的生存期和程序的生存期相同，他会在第一次执行局部变量所在的函数时完成初始化，在 C++11后，保证了并发执行时不会重复初始化，这是通过编译器在初始化前后插入代码保证互斥执行实现的。这个变量一般在数据段，效果近似于全局变量 static 修饰成员函数，表示这个成员函数参数没有隐含的this指针，效果近似于普通函数 static 修饰成员变量，表示这个成员变量属于类而不属于这个类的对象他只有一个实例，效果近似于全局变量。如果类使用了模板，那么这个模板类每实例化一次就有一个与之关联的静态成员变量 static 修饰全局变量和函数的效果是修改 object 的 linkage，即链接属性。这里的 object 指的是需要占据一块内存的 object，可以是变量的二进制表示或者函数编译后的二进制输出。static 修改 linkage 为 internal linkage，在参与链接时，即使两个.cpp文件有同名的符号，也不会产生链接错误，而是分别嵌入各自的 ELF 中 类的构造函数可以是虚拟的吗，类的析构函数可以是虚拟的吗 C++的运行时多态有两个特点：运行时类型不等于编译期类型，多态只能通过指针或引用访问对象才能生效 在创建对象时必须知道这个类具体是哪个类，即必须知道运行时类型是什么，所以这里不能有多态，也就不能被virtual关键字修饰 在拿到一个基类指针时，如果需要销毁这个对象，需要按成员变量的声明顺序逆序逐个析构，也就是析构的顺序和构造的顺序相反。不同类型的析构函数不同，需要正确的调用运行时类型对应的析构函数，所以需要基类的析构函数是虚拟的 以上两个例子可以看出，虽然这些面试题都算比较经典的八股文，但背后涉及到两个比较深的知识，第一个问题是 C/C++的编译链接过程，第二个问题是 C++的对象模型、对象内存布局和多态。而这些内容很明显是看八股文不可能学会的 除了八股文，我还推荐看一些比较经典的书来加深对一些领域的理解，比如编译链接过程可以看《程序员的自我修养——编译、链接与库》，C++的对象内存布局和多态可以参考《C++ primer》 不过秋招来啃这些书我个人认为还是不太合适，只是对我来说，想要深入的理解某个领域只有靠看书。除此之外，看书还能练习站在底层考虑问题的能力、练习深入思考的能力、练习逻辑清晰的组织回答的能力，这些能力对回答面试题都是非常有帮助的 ","date":"2024-12-03","objectID":"/posts/since_aguast/:4:1","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#秋招是怎么准备的"},{"categories":null,"content":" 秋招难吗？非常难，我投的后台岗位竞争非常激烈。我基本投遍了国内所有大厂，大部分都被筛掉。后续拿到的面试机会基本是调剂或者中厂 其中最遗憾的也许就是腾讯给的一次面试机会，面试时两道题没做出来，但事后来看是非常简单完全应该做对的。这次机会可以说是拿到的最好的机会，因为其他大厂基本没有给后台的面试机会 其中还有一些流程也许因为技能不太匹配而被挂了，例如荣耀的 java 后台和字节的 java android 客户端、 甚至还有一些公司在投递后迟迟不发笔试，我干脆当作这些公司把我挂了，一个月后他们的笔试邀请姗姗来迟时，我也不太想做了，其中包括小米（小米单论互联网体量在我心中只算中厂，但没想到中厂不要我）和京东（我在投递京东后，发生了一些事件导致京东风评不好，我当时也很犹豫要不要做笔试） 我以前从来没有用过上岸这样的词，但经历了秋招时不时翻一下邮箱期待某个大厂邀请面试、每天打开许多大厂的校招网站点击如同安慰剂的“刷新简历”按钮、投了许多大厂却没有任何回音、面试几轮自以为表现不错却被挂，我就不知不觉的想“赶紧上岸”。朋友说”难道你在水里吗，老是说上岸“，我回答说”不，我在海里” 我想我的劣势就是学历和实习经历不够，首先学校只是一个 211，而且我只是本科生。同时正因为我是本科生，自然没有多少实习经历。这样的简历自然是比不过有多段实习经验的 985 的硕士，简历被筛也是很正常了 而且最近几年本科毕业直接工作的人越来越少了，越来越多的同学选择考研，根据我的估计我所在的学院大约 50%～70%的同学都在考研/保研/考公/出国，这个比例已经非常夸张了，甚至到了 11月，我所在的学院也只有 9 个同学签了三方。 由于秋招的竞争激烈，我甚至有段时间觉得 211 学历都含金量不高了。拿到 offer 后的某一天我突然看到一项数据，2024年高校毕业生人数为1179万。而全国大学生中只有 5% 是 985 或 211, 2%是 985（数据来源1,2. 所以说相比大多数人，我参加秋招的优势已经是非常大了，但这也反映出了现在就业市场竞争是多么激烈 ","date":"2024-12-03","objectID":"/posts/since_aguast/:4:2","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#秋招难吗"},{"categories":null,"content":" 秋招有什么马后炮？ 刷题很重要，许多公司对一些岗位会限制笔试成绩，成绩低于某个线就和该岗位无缘。最好提前2个月刷，甚至提前 5 个月都是可以的 金九银十是骗人的，现在越来越多的大厂在八月中旬已经开始提前批了，最好八月就开始投递。投递得晚可能遇到目标岗位 hc 已满，或者好的岗位 hc 已满，只能选下一梯队的岗位的情况。有些岗位 10 月就会招满，有些公司 11 月就会招满 做好打持久战的准备（如果你是大佬当我没说），可能长达两三个月 0 offer 不要想着秋招的时候做准备然后参加明年春招，秋招虽然竞争很激烈但 offer 也是最多的，春招只会更难 秋招前尽量多几段实习经历 秋招当年的3月投大厂目标岗位的实习（比秋招简单多了），进去后再转正，可以比较轻松的拿到 offer，不用卷秋招！ 找个搭子互相分享秋招进度，能极大的缓解焦虑 很幸运我在实习时遇到的实习生同学 @214也参加了秋招，我们经常分享流程进度、面试内容，甚至还有于角色扮演一般的对话 ","date":"2024-12-03","objectID":"/posts/since_aguast/:4:3","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#秋招有什么马后炮"},{"categories":null,"content":" append近期对博客有许多计划，我想分享一些我看过而且评价很高的书，想分享我常听的音乐（我的编程时长约等于听音乐时长），想分享一些 C/C++的基础、经典、核心的库，也想将博客同步发到知乎、博客园等网站，敬请期待！ 最后，附上最近打比赛常听的音乐，感谢愿意耐心读完这篇快 9k 字的文章的你 ","date":"2024-12-03","objectID":"/posts/since_aguast/:5:0","series":null,"tags":null,"title":"八月到十一月","uri":"/posts/since_aguast/#append"},{"categories":null,"content":" 写在前面仔细数来快三个月没写博客了，虽然我也能找到各种各样的原因，实习离职、秋招、比赛等等，归根结底还是懈怠了。最近各种事项也基本结束，整天忙着无所事事，是时候重新动笔了 本文我将围绕即将结束初赛的 oceanbase 数据库大赛展开，但由于我不喜欢向别人讲解我敲的代码如何如何，所以我会偏向这次比赛涉及的理论、设计、想法 在这次比赛前我因为准备秋招，花了一些时间读了两本书，我认为对比赛帮助非常大，本文提及的很多想法和设计也是参考了这些书 C++ primer 一本挺厚的书，讲解 C++ 的各种特性，不过说实话看完这本书我也只能自称基本掌握 C++ DataBase System Concepts 讲解数据库的基本理论，基本上大部分成熟的数据库涉及的理论都能在这本书里找到 append: 两位非常厉害的队友: @Soulter、@bosswnx 他们的 github: @Soulter, @bosswnx 我们的仓库: bosswnx/miniob-2024 队友的赛后记: OceanBase 2024 初赛 MiniOB 开发记录、OceanBase 数据库内核实现赛 / 自己实现一个数据库 ","date":"2024-11-10","objectID":"/posts/miniob/:1:0","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#写在前面"},{"categories":null,"content":" 现代语言的基础设施所谓基础设施只是我自己胡编乱造的词。其他高级语言有各种完善的措施来发现错误或避免错误，比如 java，python， rust 等，基本来说，这些措施的目的都是尽量提前暴露错误，或者在出现错误时尽可能的采取合理的措施，防止错误扩大 为了实现这个目的，有两种方向 给编译器提供更多信息，在编译期检查出潜在的问题 在运行时插入检查 按照以上的观点，C++的基础设施可以说非常少，首先是各种指针运算，指针访问，内存的申请释放等语言特性就有很多不仅仅没有编译期检查，也没有运行时检查，一旦出错了就是各种 undefined behavior（以下简称 UB）。其次就是标准库也存在许多 UB。例如容器访问越界也是 UB。那么 UB 到底是什么 behavoir 呢，这个问题我想无法解答。有时候 UB 导致程序异常，所以我们发现了这个问题并修复，但更多时候 UB 是无法依靠的，因为他完全可能在开发时符合我们的预期并使程序正常执行，并且在正式的生产环境就引发严重的问题 按照上篇文章批评b乎用户时我的观点，一定存在某种方法使得我们可以克服 C++的“缺陷“，否则不可能有大公司愿意使用 C++ 开发项目。而这些”方法“，也就是我在比赛初期尝试引入的基础设施 ","date":"2024-11-10","objectID":"/posts/miniob/:2:0","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#现代语言的基础设施"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#miniob-使用的基础设施"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#核心基础设施"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#次要基础设施"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#clang-tidy-检查代码规范"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#clang-format-格式化代码"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#git-hook-保证每次提交可通过编译"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#基础设施在初赛中帮了多少忙"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#我对基础设施的看法"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#我对-ub-的看法"},{"categories":null,"content":" miniob 使用的基础设施 核心基础设施sanitizer总的来说，就是编译器在一些关键处插入检查代码，检查程序中潜在的问题。它的一个非常大的优点是，可以在开发时使用 sanitizer 检查问题，然后在 release 时关闭 sanitizer，提高性能。这样即保证了正确性又不牺牲性能。这也是 do things in cpp’s way的方法，即尽量在编译期提供更多的特性，并且不影响运行时的性能（对于 sanitizer，就是不影响 release 运行时的性能），也就是运行时零开销 在初赛中，项目已有address sanitizer，这是一个用于检查指针越界、悬垂指针等内存相关问题的一个 sanitizer。我引入了undefined behavior sanitizer，这是一个检查 UB 的 sanitizer，可以说是消除 UB 的利器。 除此之外，还开启了libstdc++ debug mode，它能检查 STL 容器的错误用例，解决了容器访问越界，迭代器失效等问题 以上提及的基础设施中sanitizer主要是对语言特性进行检查，因此非常依赖编译器为 sanitizer 开洞，并且某些 sanitizer 依赖一些平台特性，因此不同编译器 + 不同平台对 sanitizer 的支持程度不同，其中 gcc + linux x64 是支持最好的一个。而 libstdc++ debug mode 主要是靠编译和链接时的小技巧，因此只需要在构建系统中传入-D_GLIBCXX_DEBUG就行了 充分利用编译器的警告也是很好的方法，只需在构建系统中传入-Wall -Werror，就能强制开发者消除所有的警告，否则无法通过编译。由于 C++ 的特殊性，编译器一个不起眼的警告很有可能导致程序出现严重的错误，消除警告是一个虽然繁琐但绝对值得做的事情 一个非常好的实践是同时使用 gcc 和 clang 编译代码，并消除两个编译器的警告，因为 clang 的静态分析功能更加强大，能够在编译期发现更多问题 次要基础设施 clang-tidy 检查代码规范C++ 做一件事有很多种方法，这些方法中，有些是过时的，有些是不必要的， 有些是极易导致错误的，有些是风格良好的，有些是严谨的。因此 linter 在 C++ 开发中是非常必要的。同时，开启 linter 也能帮助自己学习现代的、工程化的 C++ 如果使用 CLion，就已经内置了clang-tidy和一系列checker，不需要自己配置，因此我非常推荐 C++ 初学者使用 CLion VSCode 使用 clang-tidy 需要使用 clangd 扩展，并调整一些设置。实际上 VSCode 只要花时间配置，也差不多能达到 CLion 的高度，不过目前我并没有发现一个快速在父类/子类、重载函数的不同版本、头文件声明/源文件定义之间跳转的方法，所以这次比赛还是用的 CLion clang-format 格式化代码可能有人认为代码风格只是一个个人偏好问题，但在工程中一致的代码风格不仅仅能促进合作，还能消除因为合并代码时格式化造成的无意义的冲突（上次数据库比赛的前车之鉴） 引入 clang-format时，应该注意以下几点 保证团队中每个人都使用 clang-fromat，否则就失去了格式化的意义 减少对存量代码的修改 git 提供一个非常方便的功能，能够只格式化工作树中修改过的行 shell git clang-format --force --extensions cpp,h || true 其中|| true是因为如果 clang-format 需要格式化代码，会返回非零值，这个设计是为了给自动化系统提供更多的信息，使脚本更加简洁，但会使 make认为命令执行失败 git hook 保证每次提交可通过编译我使用了非常简单粗暴的方法 —— 只要编译过了就是能通过编译，因此我添加了一个precommit hook，它会在每次提交前编译整个项目，如果编译失败就会拒绝提交 实际使用效果有限，因为编译比较花时间，而且只保证当前工作树的代码时能通过编译的，但这不保证提交后的代码可以通过编译，例如局部提交的情况 基础设施在初赛中帮了多少忙？address sanitizer， undefined behavior sanitizer，libstdc++ debug mode 可以说是帮助最大，避免了因为内存问题或 UB 花大量时间调试，也避免了本地能通过而测评无法通过这种“赛博灵异现象” 不得不说 C++ 的未定义行为挺多的，以下是我在比赛中遇到的 使用未对齐的指针，其行为未定义 解决办法：使用memcpy逐字节复制到对齐的地址上 singular iterator 与其他 iterator 比较，其行为未定义 解决办法：singular iterator即不跟任何容器关联的迭代器，一般是因为容器改变后迭代器失效，注意更新迭代器即可 移位运算符右边是负数，其行为未定义 使用delete运算符删除new[]运算符获取的指针，其行为未定义，反之亦然 memcpy的指针参数是非法指针或空指针时，其行为未定义，即使复制长度为零 解决办法：单独处理这种情况，此时不复制 很幸运 UB sanitizer 和 libstdc++ debug mode 都帮忙检查出来了 其次 address sanitizer 也检查出不少 use-after-free, heap-buffer-overflow等问题，非常省心 我对基础设施的看法人使用计算机是为了让人干更少的活，机器干更多的活。我认为这就是基础设施的意义，人总是靠不住的，也常常懒得检查、或者无力检查一些潜在的问题，不过幸好我们有 sanitizer 这样强大的工具帮我们检查。 此外，一些现代语言的特点就是基础设施完善而且往往是官方开发，和语言开发工具一并发行。可以认为现代语言的基础设施离开发者更距离更近，C++的基础设施不比现代语言少，甚至还有一些工具是其他语言没有的。但距离开发者更远，从我开始学习 C++ 到真正使用这些基础设施，已经有 2 年多了。 我对 UB 的看法既然有 undefined behavior，就一定有 well defined behavior，UB 存在的意义就是形成 C++ 这个语言的良定义子集。实际上，C++标准没有规定平台的大小端，没有规定一个字节有多少个比特，也没有规定指针类型有多少个字节，也没有规定char有没有符号。但这不妨碍我们使用 C++ 的良定义子集解决问题。还可以认为标准定义 UB 是将执行一些操作的自由从开发者手中剥夺并交给编译器厂商，编译器厂商就不必对良定义子集以外的任何行为做出保证，并且还能在这片标准为他们提供的“自由空间”内任意发挥 例如 C++ 并没有规定函数调用约定，而是交给编译器厂商和硬件平台自己决定，这是因为不同传参方式在不同平台的性能不同，甚至某些传参方式在某些平台是不支持的，标准没必要对此做出任何限制。我在实习时见到的一个例子就是由于x64+windows+msvc和arm64+macos+clang两个平台的传参顺序不同，导致一个函数调用表达式在 macos 能按预期运行，在 windows 就报错 又例如由于编译器不必对 UB 做出任何保证，所以编译器优化只需保证在良定义子集内的行为产生的结果在优化前后保持相同即可，也就是说编译器可以根据优化的需要任意改变 UB 产生的结果。以我在初赛中遇到的情况为例，关闭优化时产生段错误，开启O2 优化时产生空指针的成员访问 众所周知引用不能为空，但这里的确产生了一个空的引用并导致了错误 原因是因为传入这个引用的地方是空指针解引用 提到空指针解引用，我的第一想法就是段错误、非法内存访问等，但实际上，空指针解引用也是未定义行为 对于引用，标准规定引用必须初始化成一个合法对象或者函数的引用，因此在良定义的程序中空引用不可能存在。而保证「引用必须初始化成一个合法对象或者函数的引用」的工作就由编译器来完成，例如，当开发者尝试初始化一个空引用时，编译器应该拒绝编译。 因此在这个场景下，编译器应当保证不会出现空引用，又由于传入引用的地方是一个指针解引用，而空指针解引用是未定义行为，编译器不必保证空指针解引用时的行为，因此只需保证在不出现空指针解引用时不会出现空引用，因此编译器在开启 O2优化时就能将解引用优化掉并遵守空引用的承诺 更加明确的提出来这个观点，编译器假定不会出现未定义行为，并以此为前提进行优化，在这个场景可以解释为，由于有指针解引用，编译器就获得了一个信息：这个指针不能为空，因此优化掉解引用运算符也能保证不出现空引用 其他语言的 UB ？似乎只有 C++ 才有 UB，其他高级语言很少提及这个词。这是因为其他高级语言的运行时依赖于该语言的虚拟机，而实现这个虚拟机的目的之一就是消除未定义行为和平台差异，即其他高级语言的虚拟机是 C/C++ 写的，而实现虚拟机也就是尝试使用一个有 UB 的语言/平台去实现一个没有 UB 的理想乡。然而消除 UB 是有代价的，这也是 C++ 允许 UB 存在的一个原因 ","date":"2024-11-10","objectID":"/posts/miniob/:2:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#其他语言的-ub-"},{"categories":null,"content":" 解题思路的简单介绍首先来简单介绍一下 miniob 的设计。和其他数据库相似，miniob 中一条 sql 执行的全流程如下 graph LR 用户输入的sql语句原始字符串 --语法解析--\u003e 结构化的sql语法树 --语义分析--\u003e 携带相关信息的sql语句 --生成逻辑查询计划--\u003e 逻辑算子树 --优化--\u003e 物理算子树 --执行计划--\u003e 输出执行结果 ","date":"2024-11-10","objectID":"/posts/miniob/:3:0","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#解题思路的简单介绍"},{"categories":null,"content":" update从原理上来说，数据库将磁盘物理快读入内存形成缓冲块，任何读取或修改行为都发生在缓冲块上，再注意以下索引更新即可 ","date":"2024-11-10","objectID":"/posts/miniob/:3:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#update"},{"categories":null,"content":" null翻开 DataBase System Concepts 的数据存储结构章节，里面给出了一个存储 null 值一个非常经典的实现，即在记录内存一个bitmap，其中每个比特标记字段是否为 null ","date":"2024-11-10","objectID":"/posts/miniob/:3:2","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#null"},{"categories":null,"content":" text翻开 DataBase System Concepts 的数据存储结构章节，里面提及了一个非常重要的原则：一条记录不能横跨两页，而 text 字段支持的大小可以超过一页，为了避免这个问题，可以参考程序设计中常见的方法，把变长转化为定长，也就是 text 的数据在外部单独存储，而记录内只存储指向这个记录的指针 ","date":"2024-11-10","objectID":"/posts/miniob/:3:3","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#text"},{"categories":null,"content":" vector高维向量的大小可以超过页的大小，所以存储方式类似于 text，也是外部存储数据。向量的索引查询需要通过 10min 的 benchmark 测试，我主要想法在于提高向量查询的性能，以下内容展开说明如何提高性能 ","date":"2024-11-10","objectID":"/posts/miniob/:3:4","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#vector"},{"categories":null,"content":" 提高 sql 执行的性能","date":"2024-11-10","objectID":"/posts/miniob/:4:0","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#提高-sql-执行的性能"},{"categories":null,"content":" 减少 IO 次数首先，数据库最慢的部分是 IO，而基于磁盘的数据库无法避免 IO，所以提高性能的第一步就是如何减少 IO 也许读者早就清楚应该使用缓冲，但我这里想清晰明确的指出为什么需要缓冲，还有为什么数据库都使用了相似的设计：分块缓冲 为什么需要缓冲翻开 Database System Concepts 的数据存储结构章节 这里指出了冯诺依曼架构下数据库的最基本的矛盾：数据库需要持久化，因此将数据存储到非易失存储介质，但 CPU 只能读取内存中的数据，所以读取任何记录都必须先将记录加载到内存，而记录加载到内存后形成的结构，就可以称为缓冲 我希望破除一个固有观点，就是认为只有申请了多少 KB 的内存，然后里面存放了记录，这样才能被称之为缓冲。实际上如果只需要一个读取一个 int 字段，在栈上开辟一个 int 变量（声明函数内的自动变量），然后将数据从磁盘读取到这个变量，也是缓冲。可以认为前者是缓冲的形式而后者是缓冲的本质 为什么要分块缓冲 存储设备按块读写翻开 Database System Concepts 的物理存储系统章节，里面提及了闪存、磁盘、光盘、磁带等非易失存储介质，由于价格、容量、速度、通用性等考量，数据库常常使用闪存或磁盘作为存储介质 对于磁盘，磁盘表面划分为磁道，磁道进一步划分为扇区，而扇区是磁盘读写的最小单元 对于闪存，常用的 NAND 闪存的读写单元也是一个闪存物理快 从 IO 设备划分的角度，常见的非易失存储介质都是块设备，这意味着他们执行一次数据传输的单元是一块数据，而不是一个字符 如果需要读取的数据小于一个存储设备的物理快，实际上硬件仍然会执行整个物理快的读写，即使多读取的数据可能不需要；如果需要写入的数据小于一个物理快，需要先读取需要更新的物理块到内存，完成局部更新后，将更新后的物理快写回存储设备（这一过程也有可能由存储硬件完成） 按块读写速度最快由于存储设备按块读写，读写 1B 的数据和读写一个物理块的数据所花费的时间相差不大 除了这个原因，读写前的准备工作和读写后收尾工作也需要花费时间，而且它们花费的时间随读写数据大小的曲线往往是阶梯形的。 磁盘从发起读写请求到数据开始传输，需要先找到磁道，然后马达控制磁盘旋转直到找到需要读写的扇区。对于磁盘这样传统的设备，机械部分的速度远远低于电子部分的速度，所以寻道和旋转花费的时间实际上比传输时间还要多 外设传输数据到内存需要使用总线，而计算机有许多外设，申请使用总线和释放总线的耗时基本是固定的，如果采取频繁申请总线、单次传输少量数据的策略，申请总线和释放总线的耗时占比将会提升 此外，存储设备的主控单元和操作系统也针对按块读写进行优化，例如存储设备可能会预先读取后续的更多数据，缓存在主控的缓存中。操作系统也会按块读写存储设备，即使用户程序没有发出按块读写的 IO 请求 如何减少IO次数一个非常经典的方法就是将磁盘物理块加载到内存，形成缓冲块，数据库系统使用有限的内存维护若干缓冲块，并在合适的时机释放缓冲块（可能包括写回脏块） 何时、如何释放缓冲块，一个简单的方法是 LRU，但我想提及一点，在数据库场合下，LRU 不一定是最适合的 LRU 有效的前提是对 IO 请求的局部性假设，即 LRU 策略无法知道上层的 IO 请求有什么规律，而只能根据大部分场合做出这种通用的假设。但在数据库场合中，select 算子扫描表时，最新访问的缓冲块反而是未来最少使用的。数据库完全可以根据自己的场合定制一个特化的缓冲区管理策略，不过在 miniob 中不必追求这么高的性能也能通过初赛 ","date":"2024-11-10","objectID":"/posts/miniob/:4:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#减少-io-次数"},{"categories":null,"content":" 减少 IO 次数首先，数据库最慢的部分是 IO，而基于磁盘的数据库无法避免 IO，所以提高性能的第一步就是如何减少 IO 也许读者早就清楚应该使用缓冲，但我这里想清晰明确的指出为什么需要缓冲，还有为什么数据库都使用了相似的设计：分块缓冲 为什么需要缓冲翻开 Database System Concepts 的数据存储结构章节 这里指出了冯诺依曼架构下数据库的最基本的矛盾：数据库需要持久化，因此将数据存储到非易失存储介质，但 CPU 只能读取内存中的数据，所以读取任何记录都必须先将记录加载到内存，而记录加载到内存后形成的结构，就可以称为缓冲 我希望破除一个固有观点，就是认为只有申请了多少 KB 的内存，然后里面存放了记录，这样才能被称之为缓冲。实际上如果只需要一个读取一个 int 字段，在栈上开辟一个 int 变量（声明函数内的自动变量），然后将数据从磁盘读取到这个变量，也是缓冲。可以认为前者是缓冲的形式而后者是缓冲的本质 为什么要分块缓冲 存储设备按块读写翻开 Database System Concepts 的物理存储系统章节，里面提及了闪存、磁盘、光盘、磁带等非易失存储介质，由于价格、容量、速度、通用性等考量，数据库常常使用闪存或磁盘作为存储介质 对于磁盘，磁盘表面划分为磁道，磁道进一步划分为扇区，而扇区是磁盘读写的最小单元 对于闪存，常用的 NAND 闪存的读写单元也是一个闪存物理快 从 IO 设备划分的角度，常见的非易失存储介质都是块设备，这意味着他们执行一次数据传输的单元是一块数据，而不是一个字符 如果需要读取的数据小于一个存储设备的物理快，实际上硬件仍然会执行整个物理快的读写，即使多读取的数据可能不需要；如果需要写入的数据小于一个物理快，需要先读取需要更新的物理块到内存，完成局部更新后，将更新后的物理快写回存储设备（这一过程也有可能由存储硬件完成） 按块读写速度最快由于存储设备按块读写，读写 1B 的数据和读写一个物理块的数据所花费的时间相差不大 除了这个原因，读写前的准备工作和读写后收尾工作也需要花费时间，而且它们花费的时间随读写数据大小的曲线往往是阶梯形的。 磁盘从发起读写请求到数据开始传输，需要先找到磁道，然后马达控制磁盘旋转直到找到需要读写的扇区。对于磁盘这样传统的设备，机械部分的速度远远低于电子部分的速度，所以寻道和旋转花费的时间实际上比传输时间还要多 外设传输数据到内存需要使用总线，而计算机有许多外设，申请使用总线和释放总线的耗时基本是固定的，如果采取频繁申请总线、单次传输少量数据的策略，申请总线和释放总线的耗时占比将会提升 此外，存储设备的主控单元和操作系统也针对按块读写进行优化，例如存储设备可能会预先读取后续的更多数据，缓存在主控的缓存中。操作系统也会按块读写存储设备，即使用户程序没有发出按块读写的 IO 请求 如何减少IO次数一个非常经典的方法就是将磁盘物理块加载到内存，形成缓冲块，数据库系统使用有限的内存维护若干缓冲块，并在合适的时机释放缓冲块（可能包括写回脏块） 何时、如何释放缓冲块，一个简单的方法是 LRU，但我想提及一点，在数据库场合下，LRU 不一定是最适合的 LRU 有效的前提是对 IO 请求的局部性假设，即 LRU 策略无法知道上层的 IO 请求有什么规律，而只能根据大部分场合做出这种通用的假设。但在数据库场合中，select 算子扫描表时，最新访问的缓冲块反而是未来最少使用的。数据库完全可以根据自己的场合定制一个特化的缓冲区管理策略，不过在 miniob 中不必追求这么高的性能也能通过初赛 ","date":"2024-11-10","objectID":"/posts/miniob/:4:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#为什么需要缓冲"},{"categories":null,"content":" 减少 IO 次数首先，数据库最慢的部分是 IO，而基于磁盘的数据库无法避免 IO，所以提高性能的第一步就是如何减少 IO 也许读者早就清楚应该使用缓冲，但我这里想清晰明确的指出为什么需要缓冲，还有为什么数据库都使用了相似的设计：分块缓冲 为什么需要缓冲翻开 Database System Concepts 的数据存储结构章节 这里指出了冯诺依曼架构下数据库的最基本的矛盾：数据库需要持久化，因此将数据存储到非易失存储介质，但 CPU 只能读取内存中的数据，所以读取任何记录都必须先将记录加载到内存，而记录加载到内存后形成的结构，就可以称为缓冲 我希望破除一个固有观点，就是认为只有申请了多少 KB 的内存，然后里面存放了记录，这样才能被称之为缓冲。实际上如果只需要一个读取一个 int 字段，在栈上开辟一个 int 变量（声明函数内的自动变量），然后将数据从磁盘读取到这个变量，也是缓冲。可以认为前者是缓冲的形式而后者是缓冲的本质 为什么要分块缓冲 存储设备按块读写翻开 Database System Concepts 的物理存储系统章节，里面提及了闪存、磁盘、光盘、磁带等非易失存储介质，由于价格、容量、速度、通用性等考量，数据库常常使用闪存或磁盘作为存储介质 对于磁盘，磁盘表面划分为磁道，磁道进一步划分为扇区，而扇区是磁盘读写的最小单元 对于闪存，常用的 NAND 闪存的读写单元也是一个闪存物理快 从 IO 设备划分的角度，常见的非易失存储介质都是块设备，这意味着他们执行一次数据传输的单元是一块数据，而不是一个字符 如果需要读取的数据小于一个存储设备的物理快，实际上硬件仍然会执行整个物理快的读写，即使多读取的数据可能不需要；如果需要写入的数据小于一个物理快，需要先读取需要更新的物理块到内存，完成局部更新后，将更新后的物理快写回存储设备（这一过程也有可能由存储硬件完成） 按块读写速度最快由于存储设备按块读写，读写 1B 的数据和读写一个物理块的数据所花费的时间相差不大 除了这个原因，读写前的准备工作和读写后收尾工作也需要花费时间，而且它们花费的时间随读写数据大小的曲线往往是阶梯形的。 磁盘从发起读写请求到数据开始传输，需要先找到磁道，然后马达控制磁盘旋转直到找到需要读写的扇区。对于磁盘这样传统的设备，机械部分的速度远远低于电子部分的速度，所以寻道和旋转花费的时间实际上比传输时间还要多 外设传输数据到内存需要使用总线，而计算机有许多外设，申请使用总线和释放总线的耗时基本是固定的，如果采取频繁申请总线、单次传输少量数据的策略，申请总线和释放总线的耗时占比将会提升 此外，存储设备的主控单元和操作系统也针对按块读写进行优化，例如存储设备可能会预先读取后续的更多数据，缓存在主控的缓存中。操作系统也会按块读写存储设备，即使用户程序没有发出按块读写的 IO 请求 如何减少IO次数一个非常经典的方法就是将磁盘物理块加载到内存，形成缓冲块，数据库系统使用有限的内存维护若干缓冲块，并在合适的时机释放缓冲块（可能包括写回脏块） 何时、如何释放缓冲块，一个简单的方法是 LRU，但我想提及一点，在数据库场合下，LRU 不一定是最适合的 LRU 有效的前提是对 IO 请求的局部性假设，即 LRU 策略无法知道上层的 IO 请求有什么规律，而只能根据大部分场合做出这种通用的假设。但在数据库场合中，select 算子扫描表时，最新访问的缓冲块反而是未来最少使用的。数据库完全可以根据自己的场合定制一个特化的缓冲区管理策略，不过在 miniob 中不必追求这么高的性能也能通过初赛 ","date":"2024-11-10","objectID":"/posts/miniob/:4:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#为什么要分块缓冲"},{"categories":null,"content":" 减少 IO 次数首先，数据库最慢的部分是 IO，而基于磁盘的数据库无法避免 IO，所以提高性能的第一步就是如何减少 IO 也许读者早就清楚应该使用缓冲，但我这里想清晰明确的指出为什么需要缓冲，还有为什么数据库都使用了相似的设计：分块缓冲 为什么需要缓冲翻开 Database System Concepts 的数据存储结构章节 这里指出了冯诺依曼架构下数据库的最基本的矛盾：数据库需要持久化，因此将数据存储到非易失存储介质，但 CPU 只能读取内存中的数据，所以读取任何记录都必须先将记录加载到内存，而记录加载到内存后形成的结构，就可以称为缓冲 我希望破除一个固有观点，就是认为只有申请了多少 KB 的内存，然后里面存放了记录，这样才能被称之为缓冲。实际上如果只需要一个读取一个 int 字段，在栈上开辟一个 int 变量（声明函数内的自动变量），然后将数据从磁盘读取到这个变量，也是缓冲。可以认为前者是缓冲的形式而后者是缓冲的本质 为什么要分块缓冲 存储设备按块读写翻开 Database System Concepts 的物理存储系统章节，里面提及了闪存、磁盘、光盘、磁带等非易失存储介质，由于价格、容量、速度、通用性等考量，数据库常常使用闪存或磁盘作为存储介质 对于磁盘，磁盘表面划分为磁道，磁道进一步划分为扇区，而扇区是磁盘读写的最小单元 对于闪存，常用的 NAND 闪存的读写单元也是一个闪存物理快 从 IO 设备划分的角度，常见的非易失存储介质都是块设备，这意味着他们执行一次数据传输的单元是一块数据，而不是一个字符 如果需要读取的数据小于一个存储设备的物理快，实际上硬件仍然会执行整个物理快的读写，即使多读取的数据可能不需要；如果需要写入的数据小于一个物理快，需要先读取需要更新的物理块到内存，完成局部更新后，将更新后的物理快写回存储设备（这一过程也有可能由存储硬件完成） 按块读写速度最快由于存储设备按块读写，读写 1B 的数据和读写一个物理块的数据所花费的时间相差不大 除了这个原因，读写前的准备工作和读写后收尾工作也需要花费时间，而且它们花费的时间随读写数据大小的曲线往往是阶梯形的。 磁盘从发起读写请求到数据开始传输，需要先找到磁道，然后马达控制磁盘旋转直到找到需要读写的扇区。对于磁盘这样传统的设备，机械部分的速度远远低于电子部分的速度，所以寻道和旋转花费的时间实际上比传输时间还要多 外设传输数据到内存需要使用总线，而计算机有许多外设，申请使用总线和释放总线的耗时基本是固定的，如果采取频繁申请总线、单次传输少量数据的策略，申请总线和释放总线的耗时占比将会提升 此外，存储设备的主控单元和操作系统也针对按块读写进行优化，例如存储设备可能会预先读取后续的更多数据，缓存在主控的缓存中。操作系统也会按块读写存储设备，即使用户程序没有发出按块读写的 IO 请求 如何减少IO次数一个非常经典的方法就是将磁盘物理块加载到内存，形成缓冲块，数据库系统使用有限的内存维护若干缓冲块，并在合适的时机释放缓冲块（可能包括写回脏块） 何时、如何释放缓冲块，一个简单的方法是 LRU，但我想提及一点，在数据库场合下，LRU 不一定是最适合的 LRU 有效的前提是对 IO 请求的局部性假设，即 LRU 策略无法知道上层的 IO 请求有什么规律，而只能根据大部分场合做出这种通用的假设。但在数据库场合中，select 算子扫描表时，最新访问的缓冲块反而是未来最少使用的。数据库完全可以根据自己的场合定制一个特化的缓冲区管理策略，不过在 miniob 中不必追求这么高的性能也能通过初赛 ","date":"2024-11-10","objectID":"/posts/miniob/:4:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#存储设备按块读写"},{"categories":null,"content":" 减少 IO 次数首先，数据库最慢的部分是 IO，而基于磁盘的数据库无法避免 IO，所以提高性能的第一步就是如何减少 IO 也许读者早就清楚应该使用缓冲，但我这里想清晰明确的指出为什么需要缓冲，还有为什么数据库都使用了相似的设计：分块缓冲 为什么需要缓冲翻开 Database System Concepts 的数据存储结构章节 这里指出了冯诺依曼架构下数据库的最基本的矛盾：数据库需要持久化，因此将数据存储到非易失存储介质，但 CPU 只能读取内存中的数据，所以读取任何记录都必须先将记录加载到内存，而记录加载到内存后形成的结构，就可以称为缓冲 我希望破除一个固有观点，就是认为只有申请了多少 KB 的内存，然后里面存放了记录，这样才能被称之为缓冲。实际上如果只需要一个读取一个 int 字段，在栈上开辟一个 int 变量（声明函数内的自动变量），然后将数据从磁盘读取到这个变量，也是缓冲。可以认为前者是缓冲的形式而后者是缓冲的本质 为什么要分块缓冲 存储设备按块读写翻开 Database System Concepts 的物理存储系统章节，里面提及了闪存、磁盘、光盘、磁带等非易失存储介质，由于价格、容量、速度、通用性等考量，数据库常常使用闪存或磁盘作为存储介质 对于磁盘，磁盘表面划分为磁道，磁道进一步划分为扇区，而扇区是磁盘读写的最小单元 对于闪存，常用的 NAND 闪存的读写单元也是一个闪存物理快 从 IO 设备划分的角度，常见的非易失存储介质都是块设备，这意味着他们执行一次数据传输的单元是一块数据，而不是一个字符 如果需要读取的数据小于一个存储设备的物理快，实际上硬件仍然会执行整个物理快的读写，即使多读取的数据可能不需要；如果需要写入的数据小于一个物理快，需要先读取需要更新的物理块到内存，完成局部更新后，将更新后的物理快写回存储设备（这一过程也有可能由存储硬件完成） 按块读写速度最快由于存储设备按块读写，读写 1B 的数据和读写一个物理块的数据所花费的时间相差不大 除了这个原因，读写前的准备工作和读写后收尾工作也需要花费时间，而且它们花费的时间随读写数据大小的曲线往往是阶梯形的。 磁盘从发起读写请求到数据开始传输，需要先找到磁道，然后马达控制磁盘旋转直到找到需要读写的扇区。对于磁盘这样传统的设备，机械部分的速度远远低于电子部分的速度，所以寻道和旋转花费的时间实际上比传输时间还要多 外设传输数据到内存需要使用总线，而计算机有许多外设，申请使用总线和释放总线的耗时基本是固定的，如果采取频繁申请总线、单次传输少量数据的策略，申请总线和释放总线的耗时占比将会提升 此外，存储设备的主控单元和操作系统也针对按块读写进行优化，例如存储设备可能会预先读取后续的更多数据，缓存在主控的缓存中。操作系统也会按块读写存储设备，即使用户程序没有发出按块读写的 IO 请求 如何减少IO次数一个非常经典的方法就是将磁盘物理块加载到内存，形成缓冲块，数据库系统使用有限的内存维护若干缓冲块，并在合适的时机释放缓冲块（可能包括写回脏块） 何时、如何释放缓冲块，一个简单的方法是 LRU，但我想提及一点，在数据库场合下，LRU 不一定是最适合的 LRU 有效的前提是对 IO 请求的局部性假设，即 LRU 策略无法知道上层的 IO 请求有什么规律，而只能根据大部分场合做出这种通用的假设。但在数据库场合中，select 算子扫描表时，最新访问的缓冲块反而是未来最少使用的。数据库完全可以根据自己的场合定制一个特化的缓冲区管理策略，不过在 miniob 中不必追求这么高的性能也能通过初赛 ","date":"2024-11-10","objectID":"/posts/miniob/:4:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#按块读写速度最快"},{"categories":null,"content":" 减少 IO 次数首先，数据库最慢的部分是 IO，而基于磁盘的数据库无法避免 IO，所以提高性能的第一步就是如何减少 IO 也许读者早就清楚应该使用缓冲，但我这里想清晰明确的指出为什么需要缓冲，还有为什么数据库都使用了相似的设计：分块缓冲 为什么需要缓冲翻开 Database System Concepts 的数据存储结构章节 这里指出了冯诺依曼架构下数据库的最基本的矛盾：数据库需要持久化，因此将数据存储到非易失存储介质，但 CPU 只能读取内存中的数据，所以读取任何记录都必须先将记录加载到内存，而记录加载到内存后形成的结构，就可以称为缓冲 我希望破除一个固有观点，就是认为只有申请了多少 KB 的内存，然后里面存放了记录，这样才能被称之为缓冲。实际上如果只需要一个读取一个 int 字段，在栈上开辟一个 int 变量（声明函数内的自动变量），然后将数据从磁盘读取到这个变量，也是缓冲。可以认为前者是缓冲的形式而后者是缓冲的本质 为什么要分块缓冲 存储设备按块读写翻开 Database System Concepts 的物理存储系统章节，里面提及了闪存、磁盘、光盘、磁带等非易失存储介质，由于价格、容量、速度、通用性等考量，数据库常常使用闪存或磁盘作为存储介质 对于磁盘，磁盘表面划分为磁道，磁道进一步划分为扇区，而扇区是磁盘读写的最小单元 对于闪存，常用的 NAND 闪存的读写单元也是一个闪存物理快 从 IO 设备划分的角度，常见的非易失存储介质都是块设备，这意味着他们执行一次数据传输的单元是一块数据，而不是一个字符 如果需要读取的数据小于一个存储设备的物理快，实际上硬件仍然会执行整个物理快的读写，即使多读取的数据可能不需要；如果需要写入的数据小于一个物理快，需要先读取需要更新的物理块到内存，完成局部更新后，将更新后的物理快写回存储设备（这一过程也有可能由存储硬件完成） 按块读写速度最快由于存储设备按块读写，读写 1B 的数据和读写一个物理块的数据所花费的时间相差不大 除了这个原因，读写前的准备工作和读写后收尾工作也需要花费时间，而且它们花费的时间随读写数据大小的曲线往往是阶梯形的。 磁盘从发起读写请求到数据开始传输，需要先找到磁道，然后马达控制磁盘旋转直到找到需要读写的扇区。对于磁盘这样传统的设备，机械部分的速度远远低于电子部分的速度，所以寻道和旋转花费的时间实际上比传输时间还要多 外设传输数据到内存需要使用总线，而计算机有许多外设，申请使用总线和释放总线的耗时基本是固定的，如果采取频繁申请总线、单次传输少量数据的策略，申请总线和释放总线的耗时占比将会提升 此外，存储设备的主控单元和操作系统也针对按块读写进行优化，例如存储设备可能会预先读取后续的更多数据，缓存在主控的缓存中。操作系统也会按块读写存储设备，即使用户程序没有发出按块读写的 IO 请求 如何减少IO次数一个非常经典的方法就是将磁盘物理块加载到内存，形成缓冲块，数据库系统使用有限的内存维护若干缓冲块，并在合适的时机释放缓冲块（可能包括写回脏块） 何时、如何释放缓冲块，一个简单的方法是 LRU，但我想提及一点，在数据库场合下，LRU 不一定是最适合的 LRU 有效的前提是对 IO 请求的局部性假设，即 LRU 策略无法知道上层的 IO 请求有什么规律，而只能根据大部分场合做出这种通用的假设。但在数据库场合中，select 算子扫描表时，最新访问的缓冲块反而是未来最少使用的。数据库完全可以根据自己的场合定制一个特化的缓冲区管理策略，不过在 miniob 中不必追求这么高的性能也能通过初赛 ","date":"2024-11-10","objectID":"/posts/miniob/:4:1","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#如何减少io次数"},{"categories":null,"content":" 减少系统调用次数系统调用同样很慢，即使系统调用不涉及 IO。如果每次 SQL 语句执行都有许多次系统调用，性能会明显的下降。接下来我将说明为什么系统调用很慢 系统调用涉及 CPU 现场保存和上下文切换，需要大量栈帧读写 系统调用破坏了程序执行的局部性，使得 TLB、高速缓存等诸多基于局部性原理工作的组件性能降低 系统调用结束后程序不一定立刻恢复执行，而是转为就绪态，而何时转为执行态取决于操作系统的进程调度。即系统调用浪费了当前执行轮次获取到的时间片 但减少系统调用是一个非常 low level 的操作，或者说与操作系统打交道本来就是比较 low level 的操作。如果使用高级语言，可以看到从高级语言运行时、libc 一路往下到操作系统，都在围绕着如何减少系统调用，也就是说，这个工作已经由底层开发者完成了大半，作为上层开发者不必太过操心这件事 例如申请一块内存，如果直接找操作系统要一块内存，通常使用 brk 系统调用扩张堆区，或者使用 mmap 系统调用得到一块文件映射的内存。而申请内存是一个非常高频的操作，从 libc 到高级语言运行时的内存管理系统都在尽力减少这个开销，比如维护内存池是为了在用户态满足更多内存请求，减少内存碎片是为了提高内存利用率，减少向操作系统要内存的需求。很幸运的是对于上层开发者，申请内存的成本已经非常低了，对于 glibc，可能几条或者十几条机器指令就能完成了，时间复杂度也降低到了O(1)（最好的情况） 对于上层开发者，不需要在这些 low level 的层级去追求性能（甚至可能导致负优化），牺牲一定的性能去换来可读性都是可以的 ","date":"2024-11-10","objectID":"/posts/miniob/:4:2","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#减少系统调用次数"},{"categories":null,"content":" 使用编译器优化/使用高性能库这可能对于我们来说是最简单也是起效最快的方式，以这次比赛为例，我在 release build 中关闭了所有不需要的功能，例如 sanitizer、glibcxx debug mode、调试支持等，性能肉眼可见的提高了 sanitizer、glibcxx debug mode会在运行时检查一些条件，会影响性能很合理。调试功能也会间接的影响 release build 的性能，例如某些优化规则会使调试功能失效，所以可能会被禁用。此外调试会在生成的 elf 中嵌入调试信息，包括符号名、机器指令与行号的映射等，可能降低程序的空间局部性 此外，使用 C++非常大的一个优点就是性能完全不用担心，有非常多的高性能库可以轻松调用。向量索引题目中，编制索引是一个计算密集型任务，合理的使用多线程能大大加快速度，而我引入的高性能计算库也支持多线程，不过我已经轻松将ann benchmark的时间优化到了 5min (赛题要求 10min 以内)，就不必再抠这点性能了 ","date":"2024-11-10","objectID":"/posts/miniob/:4:3","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#使用编译器优化使用高性能库"},{"categories":null,"content":" 感想与其说是初赛的感想不如说是看完 C++ primer，再经过一个 C++ 项目实践后的感想 我个人非常不推荐大学把 C++ 作为大学生学习的第一门编程语言，也不推荐计算机以外的专业要求学生学习 C/C++。因为 C++涵盖的东西实在太多了，C++ primer 是一本 800-900 页讲解语法特性的书，但看完了这本书，也只是了解了 C++11 的特性的一部分，还有 C++11 - C++23 的新特性，当然也包括废弃的 C++11 特性。以我所了解的领域为例，现代 C++一直在提高其编译期计算的能力，在过去这是通过模板实现的，这也是大学的C++课程会教的内容（也许？），但在更新的标准里，随着constexpr，consteval等 const 系列关键字的引入，concept 的引入，编译期计算领域可以说已经翻天覆地了；C++ 的对象模型，内存模型，内存序也是一个非常大的话题，而且他们还和 C++ 的面向对象、对象生命期、指针等问题纠缠在一起；C++20 前已有许多协程的第三方实现，C++20又引入了 co_wait 和 co_return 关键字，提供了语言内置的协程解决方案； 就算掌握了新标准，理解了 C++ 的各种特性并能够充分运用，只会 C++ 仍然什么也做不到；往左是各大操作系统提供的能力和机制，往右是各种工程化方法，例如如何加快编译？如何组织构建系统？如何保证 ABI 兼容性？ 更不用说现在多少学校教的还是 C++98，而现在生产环境有些已经上 C++20 了。一个很好笑的现状是课程结束后学生基本只学了 C++语法，但连 C++语法都没学完，实际上我直到现在也没学完。如果只是培养计算思维，大可选择 python，java 这样的语言，而不是选择一个极难入门的语言 总结一句话，一入 C++ 就是入了一个大坑，不花个五年十年没法出来的大坑。。。 ","date":"2024-11-10","objectID":"/posts/miniob/:5:0","series":null,"tags":null,"title":"OceanBase 数据库大赛初赛结束之后","uri":"/posts/miniob/#感想"},{"categories":null,"content":"近来也算看了不少别人的博客，有些文章非常优秀，还有一些很无趣。在我看来，一篇好的博文首先不能是官方文档的复读机，也不能让读者完全看不懂，其次，信息来源应该尽量保持一手。从某方面来说，学习知识-输出知识的过程就好比咀嚼或消化。不知道转了多少手的知识好比被多次咀嚼消化后的粘稠状半消化物，多少令人反胃。我曾经也是被百度与CSDN之流坑过，所以看到 csdiy.wiki 中相同的观点时，感同身受。 我希望博客可以介绍解决一个问题的方案，分析问题场景，找出问题本质，再对比几个方案，给出我对它们的评价和偏好；也可以是将网上的回答非常零碎，但别人肯定会遇到的问题进行总结。总之，我希望文章能体现出作者的思考和观点。这篇文章我将输出一些观点和我的一些偏好 ","date":"2024-08-18","objectID":"/posts/week10/:0:0","series":null,"tags":null,"title":"第十周：杂谈与碎碎念","uri":"/posts/week10/#"},{"categories":null,"content":" 实践实习以来，见过公司内部不少的奇技淫巧。因为别人的框架不能满足业务需求，就为自己量身打造了一个新轮子；为了加快上线速度，将JS动态翻译成dart，为flutter接入了动态化能力，见 基于JS的高性能Flutter动态化框架MXFlutter-腾讯云开发者社区-腾讯云；一个仓库同时开发多个产品，跨桌面端移动端，支持私有化部署，同时服务个人用户和企业用户，开放能力给扩展应用，甚至还开放SDK给第三方定制。在公司里看到了他们为了解决问题的热情和努力，对此我的认识是 程序员（虽然比较俗的称呼，但大差不差）的工作简单来说，就是解决硬件以上的、所有的软件的问题 现实是非常复杂的，为了应对复杂的需求，需要不断地修改设计或架构 这里又会掉进一个陷阱，一般来说，设计越复杂，就越能应对复杂的需求。可以认为，设计的复杂性是它能力的一个指标，但增加设计的复杂性应该是被迫的，即增加设计的原因只能是为了应对复杂的需求。简单来说，不要为了复杂而复杂；或者说，认清需求，不要过度复杂 现实是非常复杂而深刻的，虽然人们面临的问题总是相似的，并且总结出了很多范式或通用解法，也发明了不少理论，造出了不少轮子，但很遗憾的是“软件工程没有最终银弹”，为了解决复杂问题，总是需要反范式、发明新理论、重复造轮子 Note: 欧美古老传说中使用银弹可以杀死吸血鬼、狼人或怪兽，因此”最终银弹“引申为解决所有问题的最佳方法 ","date":"2024-08-18","objectID":"/posts/week10/:1:0","series":null,"tags":null,"title":"第十周：杂谈与碎碎念","uri":"/posts/week10/#实践"},{"categories":null,"content":" 再谈分层在前几篇文章中，我已经谈论过分层。简单来说，分层尝试屏蔽底层细节，但它不仅仅不能完全屏蔽，而且还会导致上层只能访问底层共同能力，而无法访问其全部能力。分层是为了减少开发者心智负担，但不代表开发者可以完全不考虑底层、对底层一无所知。如果一个人工作在上层也许可以解决99%的问题，但无论如何，总有一些问题是上层一定无法解决的。如果只工作在上层，使用别人提供的优秀的框架，而不了解其底层原理、机制、概念，这样的人顶多叫做“框架使用者”，而不是“开发者”。很遗憾的是大部分人都是“框架使用者”，熟练使用框架与“熟练使用缝纫机”没有本质区别。我始终认为程序员的工作是一个发明、创造的工作，而不是机械的、流水线的工作。这个话题在reddit已经有讨论: Be an Dev, not a Frameworker ","date":"2024-08-18","objectID":"/posts/week10/:1:1","series":null,"tags":null,"title":"第十周：杂谈与碎碎念","uri":"/posts/week10/#再谈分层"},{"categories":null,"content":" 我的想法以上已经可以看出我的想法了。相比上层，我更倾向底层，从大二到现在，我也是一直在这个方向努力。底层开发者面临着更复杂、更深刻、更广泛的问题，他们的工作成果决定了上层的形状，底层的革新会带来更长久更广泛的进步。如果将底层开发者的工作比作生产各种玩具，那么上层开发者的工作就是将几种玩具打包、装进漂亮包装盒、缠上红缎带，定高价在商场中出售。很明显上层开发者会获得更多的利益，包括名誉、知名度、金钱。也许未来的我会后悔，但至少现在还有热爱与激情支撑 ","date":"2024-08-18","objectID":"/posts/week10/:1:2","series":null,"tags":null,"title":"第十周：杂谈与碎碎念","uri":"/posts/week10/#我的想法"},{"categories":null,"content":" C/C++最近也是打算深入学习一下C/C++了，说来惭愧我连C++ primer都没看完。b乎上关于C++的批评也不少，虽然大部分都是站在高级语言的角度踩一脚C++ 我的反驳理由也非常简单：很多高级语言的解释器、虚拟机都是用C/C++写的，例如Python，java，dart，js等 C/C++可以说是又古老又现代，诞生了不少历史悠久的工程，其中不乏postgresql这样的老牌开源项目，也有windows这样的商业工程。这些工程经过了广泛的实践与验证，即使是C/C++标准大变样，操作系统、软件工程方法长足进步的现在， 它们解决一些问题的方法也是非常具有参考意义的。这些历史可以认为是C/C++的资产，有了这样的资产，开发大型项目时选择C/C++就不奇怪了 此外，C/C++与其他语言最大的优势有两点 操作系统基本是用C/C++写的 所以操作系统的API，即系统调用也往往是以C/C++的形式提供的，因此C/C++能访问操作系统的全部能力 C API已经成了跨语言互操作的公认事实标准 使用其他语言容易陷入一个困局：无法在其他语言中调用，所以其他语言总是需要重复实现一些功能 此外，因为很多高级语言的解释器、虚拟机都是用C/C++写的，所以这些解释器、虚拟机也依赖于C/C++的运行时。然而高级语言的运行时很多时候会造成不少麻烦。很多高级语言的运行时不容易嵌入到其他运行时中，在部署时，还需要带上运行时。C/C++的优点是就体现在这里，因为操作系统基本是用C/C++写的，所以绝大部分操作系统都有C/C++的运行时，基本不用考虑C/C++的运行时问题 ","date":"2024-08-18","objectID":"/posts/week10/:2:0","series":null,"tags":null,"title":"第十周：杂谈与碎碎念","uri":"/posts/week10/#cc"},{"categories":null,"content":" 关于批评很想评价一下b乎的风气了。经过长时间使用b乎，我也是发现b乎用户平均水平了。b乎的计算机话题充斥着不少半吊子毫不客气地批评各种东西。看了这些内容后，我产生了一个观点：没有调查就没有发言权 b乎指知乎 一个框架、语言、系统、产品，诸如这样的东西肯定不是完美的，它从诞生时就有各种问题，但在实践中人们总是会用其他方法来弥补甚至绕过这个问题。只有参与到广泛的实践中，才能真正认识到它的优劣。一个原则就是，如果它已经部署在许多生产环境并创造了价值，那么它一定是有可取之处的，至少轮不到b乎用户来批评 这也让我反思，我过去对windows的评价可以说是非常低了，自从主力切换到archlinux后，虽然在archlinux遇到了数不尽的问题，但还是非常喜欢使用linux，并且如果不从事windows开发，我想我可能都不会主动使用windows开发了。认识到 没有调查就没有发言权 后，我也改变了我的观点。 我现在对windows的观点是，它确实存在不少我非常不喜欢的东西，微软雅黑和新宋体非常丑陋，cmd和powershell不好用，GBK编码特别坑，POSIX不兼容，C/C++开发比linux麻烦得多等等。但作为PC市场的霸主，还有windows server跑在服务器，它能取得成功是有原因的。因此我对windows的意见暂时保留，并且开始学习win32、阅读windows文档、计划阅读windows internals(深入理解windows的目地是为了更好的批评windows) windows有很多老古董，虽然windows的技术栈在不断迭代，但其背后的核心并没有改变。例如 Component Object Model（COM）虽然最开始被使用在ActiveX, IE这样的老古董上，但时至今日，COM仍然是Windows一个非常强大的技术，它间接地解决了C++ ABI问题，让C++开发者之间的协作变得更加容易。即使是2024年的现在，标准委员会也没有要解决C++ ABI问题的意图。linux基本没有解决C++ ABI的问题，在我的认知中，linux是通过以下方式缓解的 linux许多软件包都是源码发行的，只要软件将他们依赖的软件包源码一并编译，就不会遇到ABI问题。而windows商业软件很多，让商业公司重新编译的难度非常高 GNU为了ABI兼容做了许多努力，简单来说，GCC前向兼容跨越了许多个大版本，覆盖了绝大部分linux发行版软件源中gcc版本 导出C接口，避免C++ ABI问题 此外，Windows Side by Side(WinSxS)解决了动态库依赖问题，这样的技术即使现在放到linux也是非常先进的，而且WinSxS居然在Windows 2000就被发明出来了。linux并没有类似的技术解决这个问题，相反，linux通过包管理器、appimage这些手段避免了动态库依赖问题 ","date":"2024-08-18","objectID":"/posts/week10/:3:0","series":null,"tags":null,"title":"第十周：杂谈与碎碎念","uri":"/posts/week10/#关于批评"},{"categories":null,"content":"实习期间摸了不少的鱼，通勤路上在看各种文档，在公司摸鱼时就在看glibc或cpython的源码，花了不少时间总算是理解了部分。所谓内存管理系统充斥着各种指针运算，抽象程度非常高，这篇文章我希望是定性的去描述内存分配系统，因为源码总是枯燥又无聊的，如果不是它出现了问题，我想大部分人都不会去看源码吧 ","date":"2024-08-04","objectID":"/posts/week8/:0:0","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#"},{"categories":null,"content":" 总览glibc作为libc的GNU实现，按照分层的角度，它往下是操作系统，往上是用户代码，它将操作系统的许多能力以C标准规定的形式提供，并且在linux平台，glibc还提供了稳定的系统调用接口 从操作系统的角度，每个进程都有自己的地址空间，当进程需要更多的内存时，有两种方式，可以通过mmap系统调用申请一块可读可写的内存，还可以通过brk系统调用扩张堆区。无论使用哪种方式，操作系统分配内存的最小单位是页，一般是4K 4K是一个非常粗的粒度，从操作系统的角度，4K是为了减少内存管理系统的开销并减少内存碎片的一个权衡结果，但对于用户进程来说，4K还是太大了，因此用户态还需要一个内存管理系统，用于满足用户程序零散、频繁的内存需求 glibc提供了一个内存管理系统，在linux平台，几乎所有进程都会链接到glibc。包括解释语言，诸如shell、python。它们如果需要访问操作系统，也要链接到glibc。因此glibc是用户程序的最底层，简化用户程序与操作系统的交互 如果只使用系统调用的ABI接口，就不必链接到glibc。但需要写内联汇编，而且直接使用系统调用难度高，移植性差 分层并不能解决所有问题，许多用户程序会在glibc提供的内存管理系统之上再实现一个自己的内存管理系统。python在编译时，可以选择是否使用python内置的内存管理系统，如果选择否，就会直接使用libc的内存管理系统。为了性能和开销、这个选项是默认打开的 ","date":"2024-08-04","objectID":"/posts/week8/:1:0","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#总览"},{"categories":null,"content":" 前置知识阅读glibc和python的源码需要不少的指针经验，还需要有从汇编角度理解C代码的能力 C的结构体可以认为是一块内存+各字段的偏移+各字段的数据长度。编译后，结构体成员的访问会变成地址运算+地址访问 许多平台都有数据对齐的要求，数据不对齐轻则读取速度降低，重则无法访问数据 申请一块内存时，这块内存要求是连续的，越大的连续内存申请越难以满足 内存碎片，即由于不规律的索取内存，内存千疮百孔，即使空闲内存总和满足了申请大小，但不存在足够大的连续内存而无法满足内存申请，导致内存使用率低下 ","date":"2024-08-04","objectID":"/posts/week8/:2:0","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#前置知识"},{"categories":null,"content":" Python的内存分配系统Python的语言特性依赖于大量小对象的创建，例如函数传参、本地变量访问、unicode对象等，导致Python的内存需求是大量、频繁、琐碎的。 如果直接使用libc提供的内存分配系统，由于大量小块内存的请求，会产生大量的内存碎片，不仅仅增加了进程的内存使用，而且使用系统调用向操作系统申请内存这个过程很慢，降低了Python解释器运行速度 为了缓解这种现象，Python内置了一个简单的内存分配系统。相比libc，它会尝试占用更多的内存，然后满足大量小块内存申请的同时减少内存碎片的产生。如果可行，它也会将闲置内存归还给操作系统 C typedef struct { /* user context passed as the first argument to the 4 functions */ void *ctx; /* allocate a memory block */ void* (*malloc) (void *ctx, size_t size); /* allocate a memory block initialized by zeros */ void* (*calloc) (void *ctx, size_t nelem, size_t elsize); /* allocate or resize a memory block */ void* (*realloc) (void *ctx, void *ptr, size_t new_size); /* release a memory block */ void (*free) (void *ctx, void *ptr); } PyMemAllocatorEx; 结构体PyMemAllocatorEx相当于一个内存管理系统的接口，只要实现了这个接口，就能将此内存管理系统用于CPython中 此外，C标准规定malloc或calloc在申请内存的大小为零时，其结果未定义。Python为了其跨平台特性，将申请内存大小为零的请求转变为申请内存大小为1的请求，消除了UB Python管理内存分为三个层级：arena，pool，block ","date":"2024-08-04","objectID":"/posts/week8/:3:0","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#python的内存分配系统"},{"categories":null,"content":" arena一个arena大小为1MiB，一个arena包括多个pool C struct arena_object { uintptr_t address; // arena的起始地址，直接使用mmap分配这块内存 block* pool_address; // 指向下一个未初始化的pool uint nfreepools; // 记录该arena中有多少个空闲的pool uint ntotalpools; // 该arena中所有的pool，包括空闲pool和已使用的pool struct pool_header* freepools; // 记录空闲pool的单链表 struct arena_object* nextarena; // 双向链表 struct arena_object* prevarena; }; arena_object只是一个用于book keeping的结构，arena的内存都是额外分配的 Python解释器运行时，存在多个arena，通过一个动态数组管理 C /* Array of objects used to track chunks of memory (arenas). */ static struct arena_object* arenas = NULL; /* Number of slots currently allocated in the `arenas` vector. */ static uint maxarenas = 0; /* The head of the singly-linked, NULL-terminated list of available * arena_objects. */ static struct arena_object* unused_arena_objects = NULL; 动态数组的首地址为arenas，长度为maxarenas，unused_arena_objects之后的数组元素是未使用的arena，并且他们通过单链表连接 ","date":"2024-08-04","objectID":"/posts/week8/:3:1","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#arena"},{"categories":null,"content":" pool一个pool包含多个block，而且一个pool的每个block的大小都是相等的。所以pool有一个大小类别，即sizeclass（sizeclass说明见block） C struct pool_header { union { block *_padding; uint count; } ref; // _padding仅仅用于对齐，count表示该pool分配了多少个block block *freeblock; // 单链表组织空闲block struct pool_header *nextpool; // 指向下一个与同大小类别的pool struct pool_header *prevpool; // 前一个pool，组成双链表 uint arenaindex; // 该pool所属的arena在`arenas`动态数组中的索引 uint szidx; // 大小类别的索引 uint nextoffset; // 距离下一个空闲block的偏移，相对的起始地址为pool首地址 uint maxnextoffset; // 空闲blocks中最大的偏移 }; typedef struct pool_header *poolp; ","date":"2024-08-04","objectID":"/posts/week8/:3:2","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#pool"},{"categories":null,"content":" blockblock的大小有16，32，48，64等等，以16为阶梯大小递增,这是block的大小类别，16的大小类别索引为0，32的大小类别索引为2，以此类推 C /* When you say memory, my mind reasons in terms of (pointers to) blocks */ typedef uint8_t block; block的定义非常有意思，比较考验对C的理解 C一个非常灵活的地方在于，给结构体分配内存时，分配的内存大小不一定是结构体的大小。以结构体 C struct MyStruct{ int a； } 为例，可以给MyStruct分配更多的内存 text +---------------------+ | int a | +---------------------+ | 空 闲 | | | | 空 间 | +---------------------+ 多于的空间可以解释为其他用途的数据 此处block的大小在是由其所在的pool决定的，所以block没必要再记录自身的大小 此外，block的使用中经常出现*(block**)b，实际上block隐含了一个next结构体成员 可以将block的定义改为以下定义 C struct block { struct block* next; } 与原block定义是等价的，*(block**)b也可以改写成b-\u003enext，这样可读性更好 Note: 以上改写基于一个事实：next成员的偏移为零，其地址与结构体首地址相同 block记录了这一小块内存的起始地址，假设该block所属pool的大小类别为16，即block表示的一小块内存的大小为16 block正在被使用时，它表示的16字节的内存完全交给上层使用，block本身不额外占据空间 block闲置时，前8个字节（64位机器的指针宽度）记录了结构体成员变量next，next指向下一个空闲的block 可以认为，一个pool的所有空闲block组成了一个单链表，而pool-\u003enextoffset记录了链表头 pool的内存视图如下 text +-------------------------------------------------------------------+ | pool_header | block1 | block2 | block3 | block4 | block5 | ... | +-------------------------------------------------------------------+ 可以看出，pool_header在分配内存时，也分配了多于pool_header大小的内存（实际上，一个pool大小一般是16KiB） ","date":"2024-08-04","objectID":"/posts/week8/:3:3","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#block"},{"categories":null,"content":" usedpoolsusedpools可以说是整个Python内存管理系统中最精彩、最能体现C奇技淫巧的部分 去掉部分条件编译后如下 C #define PTA(x) ((poolp )((uint8_t *)\u0026(usedpools[2*(x)]) - 2*sizeof(block *))) #define PT(x) PTA(x), PTA(x) static poolp usedpools[2 * ((NB_SMALL_SIZE_CLASSES + 7) / 8) * 8] = { PT(0), PT(1), PT(2), PT(3), PT(4), PT(5), PT(6), PT(7) , PT(8), PT(9), PT(10), PT(11), PT(12), PT(13), PT(14), PT(15) , PT(16), PT(17), PT(18), PT(19), PT(20), PT(21), PT(22), PT(23) , PT(24), PT(25), PT(26), PT(27), PT(28), PT(29), PT(30), PT(31) } usedpools非常巧妙地组织了正在使用的pool，它是分配内存时的快速通道。 Note: 理解usedpools需要画一些草稿辅助 usedpools被视为一个数组，每两个poolp表示数组的一个元素（entry），数组的一个元素即一个链表头，链表头是一个环形双向链表的哨兵节点（哨兵节点不存储数据），数组的索引即大小类别的索引 假设要分配27个字节，首先向上取整到16的倍数，即取整到32，32对应的大小类别的索引为2,于是访问usedpools[2 + 2]，得到一个poolp。在初始化时，usedpools[2 + 2]-\u003enextpool和usedpools[2 + 2]-\u003eprevpool指向的值都是usedpools[2 + 2]的地址，即表示该环形双向链表为空；如果该大小类别已经有pool分配了，usedpools[2 + 2]表示的环形双向链表就会有两个节点（包括哨兵节点） usedpools第一次见时，理解起来很费劲。但理解其意图后，usedpools的用法还是有些可读性。它去除了pool_header结构体中不必要的部分，可以认为是一种索引。usedpools的元素大小越小，cache line就能放下更多的usedpools元素，性能就越高 usedpools已经有一位core dev讲解过 ","date":"2024-08-04","objectID":"/posts/week8/:3:4","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#usedpools"},{"categories":null,"content":" malloc流程python有四套内存管理系统，可以通过编译参数指定使用哪一个 编译参数为--with-pydebug --without-pymalloc，会使用_PyMem_DebugRawMalloc作为malloc入口 编译参数为--with-pydebug，会使用_PyMem_DebugMalloc作为malloc入口 编译参数为--without-pymalloc，会使用_PyMem_RawMalloc作为malloc入口 编译参数无以上提及的两个参数，会使用_PyObject_Malloc作为malloc入口 --with-pydebug的目地是为了开发cpython时，帮助发现内存问题，--without-pymalloc的目地是直接使用libc的内存管理系统 一般来说，python以release模式编译并发行，所以最主要的malloc入口是_PyObject_Malloc，以下定性地阐述其流程 如果申请大小大于一个阈值（512字节），就直接使用_PyMem_RawMalloc分配内存，它将大小为零的内存申请转换为大小为1的内存申请（为了消除UB），然后直接使用libc的malloc，malloc申请的内存直接返回 以下部分的申请大小都小于阈值 将申请内存大小向上取整到16的倍数，并计算其sizeclass的索引 访问usedpools[size + size]，得到该sizeclass对应的pool的环形双向链表 如果链表中存在元素，则从pool-\u003efreeblock中取出一个空闲block 取出后如果pool已满，将该pool从usedpools中移除 如果未满，返回 如果链表中不存在元素，则尝试建立一个新的pool，并从其中取block 如果不存在可用的（非全满）的arena，就创建一个arena，并将其加入arenas表示的动态数组的管理中 至此可以保证一定有一个arena可以分配出一个pool 从arena中取出一个pool，并处理取出pool后arena全满、pool未初始化等情况 从该pool中取出 将取出的pool插入到usedpools[size + size]表示的环形双向链表中 一些细节： 大部分内存请求都是小规模的，会进入python内置的内存管理系统 大部分小规模的内存请求可以通过sizeclass的索引查找usedpools快速满足 arenas表示的动态数组中，会优先使用第一个未满的arena，用满后才会开辟新的arena 从一个pool取block时，优先取地址更大的block，即使存在低地址的block归还给pool。这样可以将查找推迟到该poool的所有block都分配过一次之后 大量使用__builtin_expect，主动提供分支预测信息，加快流水线执行机器指令 ","date":"2024-08-04","objectID":"/posts/week8/:3:5","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#malloc流程"},{"categories":null,"content":" 总结 所有内存请求都规整到16的倍数，一个pool的所有block的大小都是相等的，减少了内存碎片 usedpools按照大小类别快速满足内存请求，体现了“加速大概率事件”这一计算机体系架构的核心思想 优先使用最满的arena，减少内存使用量 ","date":"2024-08-04","objectID":"/posts/week8/:3:6","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#总结"},{"categories":null,"content":" glibc的内存管理系统glibc的内存管理系统非常复杂。也许是因为glibc开发完成于“古代”，源码风格非常乱，花括号缩进可读性非常差，几百行的if else分支随处可见，宏里还会使用局部变量，不推荐阅读 我花费了一些时间阅读malloc实现后，只理解了部分。以下大部分内容都来自于glibc的wiki，但我希望它的内容比wiki更容易阅读 ","date":"2024-08-04","objectID":"/posts/week8/:4:0","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#glibc的内存管理系统"},{"categories":null,"content":" arenaglibc向操作系统索取内存的方式有两种，一种是通过brk扩展堆区，另一种是通过mmap得到映射的一块内存。glibc将通过brk扩展的堆区称为main arena，它是第一个初始化的arena 与MSVC不同，glibc不存在单线程版本和多线程版本。为了实现malloc的线程安全，arena对象有一个互斥锁字段，用于控制互斥访问 为了缓解多线程环境下的互斥时间开销，一个进程可以有多个arena，一个arena可以有一个或多个heap（此处的heap仅仅指连续内存，不是进程的heap），一个heap有多个chunck，chunck是glibc管理内存的最小单位，返回给用户的内存首地址也是chunck的一部分 Note: arena拥有的内存不一定不是连续的，因为只有heap才是连续的，而一个arena可以拥有多个heap arena的结构如下（省略部分），bin相关介绍见下文 C struct malloc_state { __libc_lock_define (, mutex); // 互斥锁用于互斥访问arena int flags; int have_fastchunks; // 记录是否有fastbin mfastbinptr fastbinsY[NFASTBINS]; mchunkptr top; mchunkptr last_remainder; mchunkptr bins[NBINS * 2 - 2]; unsigned int binmap[BINMAPSIZE]; struct malloc_state *next; // 形成单链表 struct malloc_state *next_free; }; ### heap heap的结构如下 C typedef struct _heap_info { mstate ar_ptr; // 指向heap所属的arena struct _heap_info *prev; // 形成单链表 size_t size; // 此heap拥有的连续字节数 size_t mprotect_size; size_t pagesize; // 分配此heap时使用的页大小，一般是4K char pad[-3 * SIZE_SZ \u0026 MALLOC_ALIGN_MASK]; // 用于使后续数据对齐 } heap_info; ","date":"2024-08-04","objectID":"/posts/week8/:4:1","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#arena-1"},{"categories":null,"content":" chunckQ：为什么malloc需要提供申请的内存的大小，而free不需要 A：因为malloc返回的内存是chunck的一部分，而chunck记录了该chunck的大小 chunck是一块长度不固定的内存，两个相邻的chunck可以合并成一个更大的chunck chunck结构如下 C struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size;// chucnk空闲时表示临接的chunck的大小，用于chunck合并 INTERNAL_SIZE_T mchunk_size; // chunck的大小 struct malloc_chunk* fd; // forward的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* bk; // back的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* fd_nextsize; // 指向更大的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 struct malloc_chunk* bk_nextsize; // 指向更小的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 }; 由于需要记录一些元数据，一个chunck会有一些额外的空间开销 规定一个chunck的大小为8字节的倍数，当用户申请的空间+chunck额外开销不足8字节倍数时，需要向上取整。由于chunck的大小是8字节的倍数，mchunk_size字段的低三位一直是零，可以用来记录一些额外的信息 text +-------------+---+---+---+ | mchunk_size | A | M | P | +-------------+---+---+---+ A(0x4) 用于标记该chunc所属的heap是否是通过mmap获得的。增加这一标志后，如果A为0，表示chucnk来自主arena，即进程的堆区，如果A为1，表示chunck来自映射的内存。由于mmmap返回的地址永远是页对齐的，可以通过chunck地址的高位确定它来自的heap M(0x2) 当申请的内存太大时，malloc会直接使用mmap创建一个超大的chucnk，M位标记该chunck是直接使用mmap创建的 P(0x1) 标记前一个邻接的chunck正在被使用，此时mchunk_prev_size字段无效，设置该位会阻止邻接chunck的合并 malloc返回的是分配的chunck的mchunk_size之后的地址，即fd和bk是分时复用的 此外，在chunck结构体之后，还有一个隐含的冗余size字段，它用于保护chunck。当用户不慎使用了错误的指针运算修改了mchunk_size字段时，glibc可以通过冗余的size字段判断出异常，并发出警告 一个arena通过四个链表记录了空闲的chuck，这些链表被称为bins fastbinarena的mfastbinptr fastbinsY[NFASTBINS];字段表示了fastbin，它是一个数组，数组的每个元素都是一个单链表的表头，链表中的所有chunck的大小都是相同的 与python相似，fastbinsY的索引也表示大小类别，通过申请内存的大小可以快速确定索引。fastbin是malloc申请内存的快速通道 fastbin的P位置零，用于阻止chunck合并 unsorted bin释放后的chunck会先进入unsorted bin，随后（触发某个条件后）它们会被排序，然后进入其他bin small binsmall bin是normal bin的一部分，它们通过双向链表组织。normal bin即arena的mchunkptr bins[NBINS * 2 - 2];成员 当unsorted bin排序后，chunck如果足够小，会进入small bin。此时尝试将该chunck与small bin中已有的chunck进行合并，合并后的chunck进入large bin。因此，small bin不存在邻接的chunck 当从small bin中取出chunck时，只需要取出第一个足够大的chunck即可 large bin当unsorted bin排序后，chunck如果足够大，会进入large bin，此外，还可以由small bin中的chunck合并得来 当从large bin中取出chunck时，需要寻找足够大的chunck中最小的一个，此时的chunck可能还是比需要的大小更大，需要将该chunck分为两个chunck，一个chunck可以恰好满足需要的大小，剩下的chunck可以继续使用 ","date":"2024-08-04","objectID":"/posts/week8/:4:2","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#chunck"},{"categories":null,"content":" chunckQ：为什么malloc需要提供申请的内存的大小，而free不需要 A：因为malloc返回的内存是chunck的一部分，而chunck记录了该chunck的大小 chunck是一块长度不固定的内存，两个相邻的chunck可以合并成一个更大的chunck chunck结构如下 C struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size;// chucnk空闲时表示临接的chunck的大小，用于chunck合并 INTERNAL_SIZE_T mchunk_size; // chunck的大小 struct malloc_chunk* fd; // forward的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* bk; // back的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* fd_nextsize; // 指向更大的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 struct malloc_chunk* bk_nextsize; // 指向更小的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 }; 由于需要记录一些元数据，一个chunck会有一些额外的空间开销 规定一个chunck的大小为8字节的倍数，当用户申请的空间+chunck额外开销不足8字节倍数时，需要向上取整。由于chunck的大小是8字节的倍数，mchunk_size字段的低三位一直是零，可以用来记录一些额外的信息 text +-------------+---+---+---+ | mchunk_size | A | M | P | +-------------+---+---+---+ A(0x4) 用于标记该chunc所属的heap是否是通过mmap获得的。增加这一标志后，如果A为0，表示chucnk来自主arena，即进程的堆区，如果A为1，表示chunck来自映射的内存。由于mmmap返回的地址永远是页对齐的，可以通过chunck地址的高位确定它来自的heap M(0x2) 当申请的内存太大时，malloc会直接使用mmap创建一个超大的chucnk，M位标记该chunck是直接使用mmap创建的 P(0x1) 标记前一个邻接的chunck正在被使用，此时mchunk_prev_size字段无效，设置该位会阻止邻接chunck的合并 malloc返回的是分配的chunck的mchunk_size之后的地址，即fd和bk是分时复用的 此外，在chunck结构体之后，还有一个隐含的冗余size字段，它用于保护chunck。当用户不慎使用了错误的指针运算修改了mchunk_size字段时，glibc可以通过冗余的size字段判断出异常，并发出警告 一个arena通过四个链表记录了空闲的chuck，这些链表被称为bins fastbinarena的mfastbinptr fastbinsY[NFASTBINS];字段表示了fastbin，它是一个数组，数组的每个元素都是一个单链表的表头，链表中的所有chunck的大小都是相同的 与python相似，fastbinsY的索引也表示大小类别，通过申请内存的大小可以快速确定索引。fastbin是malloc申请内存的快速通道 fastbin的P位置零，用于阻止chunck合并 unsorted bin释放后的chunck会先进入unsorted bin，随后（触发某个条件后）它们会被排序，然后进入其他bin small binsmall bin是normal bin的一部分，它们通过双向链表组织。normal bin即arena的mchunkptr bins[NBINS * 2 - 2];成员 当unsorted bin排序后，chunck如果足够小，会进入small bin。此时尝试将该chunck与small bin中已有的chunck进行合并，合并后的chunck进入large bin。因此，small bin不存在邻接的chunck 当从small bin中取出chunck时，只需要取出第一个足够大的chunck即可 large bin当unsorted bin排序后，chunck如果足够大，会进入large bin，此外，还可以由small bin中的chunck合并得来 当从large bin中取出chunck时，需要寻找足够大的chunck中最小的一个，此时的chunck可能还是比需要的大小更大，需要将该chunck分为两个chunck，一个chunck可以恰好满足需要的大小，剩下的chunck可以继续使用 ","date":"2024-08-04","objectID":"/posts/week8/:4:2","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#fastbin"},{"categories":null,"content":" chunckQ：为什么malloc需要提供申请的内存的大小，而free不需要 A：因为malloc返回的内存是chunck的一部分，而chunck记录了该chunck的大小 chunck是一块长度不固定的内存，两个相邻的chunck可以合并成一个更大的chunck chunck结构如下 C struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size;// chucnk空闲时表示临接的chunck的大小，用于chunck合并 INTERNAL_SIZE_T mchunk_size; // chunck的大小 struct malloc_chunk* fd; // forward的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* bk; // back的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* fd_nextsize; // 指向更大的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 struct malloc_chunk* bk_nextsize; // 指向更小的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 }; 由于需要记录一些元数据，一个chunck会有一些额外的空间开销 规定一个chunck的大小为8字节的倍数，当用户申请的空间+chunck额外开销不足8字节倍数时，需要向上取整。由于chunck的大小是8字节的倍数，mchunk_size字段的低三位一直是零，可以用来记录一些额外的信息 text +-------------+---+---+---+ | mchunk_size | A | M | P | +-------------+---+---+---+ A(0x4) 用于标记该chunc所属的heap是否是通过mmap获得的。增加这一标志后，如果A为0，表示chucnk来自主arena，即进程的堆区，如果A为1，表示chunck来自映射的内存。由于mmmap返回的地址永远是页对齐的，可以通过chunck地址的高位确定它来自的heap M(0x2) 当申请的内存太大时，malloc会直接使用mmap创建一个超大的chucnk，M位标记该chunck是直接使用mmap创建的 P(0x1) 标记前一个邻接的chunck正在被使用，此时mchunk_prev_size字段无效，设置该位会阻止邻接chunck的合并 malloc返回的是分配的chunck的mchunk_size之后的地址，即fd和bk是分时复用的 此外，在chunck结构体之后，还有一个隐含的冗余size字段，它用于保护chunck。当用户不慎使用了错误的指针运算修改了mchunk_size字段时，glibc可以通过冗余的size字段判断出异常，并发出警告 一个arena通过四个链表记录了空闲的chuck，这些链表被称为bins fastbinarena的mfastbinptr fastbinsY[NFASTBINS];字段表示了fastbin，它是一个数组，数组的每个元素都是一个单链表的表头，链表中的所有chunck的大小都是相同的 与python相似，fastbinsY的索引也表示大小类别，通过申请内存的大小可以快速确定索引。fastbin是malloc申请内存的快速通道 fastbin的P位置零，用于阻止chunck合并 unsorted bin释放后的chunck会先进入unsorted bin，随后（触发某个条件后）它们会被排序，然后进入其他bin small binsmall bin是normal bin的一部分，它们通过双向链表组织。normal bin即arena的mchunkptr bins[NBINS * 2 - 2];成员 当unsorted bin排序后，chunck如果足够小，会进入small bin。此时尝试将该chunck与small bin中已有的chunck进行合并，合并后的chunck进入large bin。因此，small bin不存在邻接的chunck 当从small bin中取出chunck时，只需要取出第一个足够大的chunck即可 large bin当unsorted bin排序后，chunck如果足够大，会进入large bin，此外，还可以由small bin中的chunck合并得来 当从large bin中取出chunck时，需要寻找足够大的chunck中最小的一个，此时的chunck可能还是比需要的大小更大，需要将该chunck分为两个chunck，一个chunck可以恰好满足需要的大小，剩下的chunck可以继续使用 ","date":"2024-08-04","objectID":"/posts/week8/:4:2","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#unsorted-bin"},{"categories":null,"content":" chunckQ：为什么malloc需要提供申请的内存的大小，而free不需要 A：因为malloc返回的内存是chunck的一部分，而chunck记录了该chunck的大小 chunck是一块长度不固定的内存，两个相邻的chunck可以合并成一个更大的chunck chunck结构如下 C struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size;// chucnk空闲时表示临接的chunck的大小，用于chunck合并 INTERNAL_SIZE_T mchunk_size; // chunck的大小 struct malloc_chunk* fd; // forward的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* bk; // back的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* fd_nextsize; // 指向更大的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 struct malloc_chunk* bk_nextsize; // 指向更小的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 }; 由于需要记录一些元数据，一个chunck会有一些额外的空间开销 规定一个chunck的大小为8字节的倍数，当用户申请的空间+chunck额外开销不足8字节倍数时，需要向上取整。由于chunck的大小是8字节的倍数，mchunk_size字段的低三位一直是零，可以用来记录一些额外的信息 text +-------------+---+---+---+ | mchunk_size | A | M | P | +-------------+---+---+---+ A(0x4) 用于标记该chunc所属的heap是否是通过mmap获得的。增加这一标志后，如果A为0，表示chucnk来自主arena，即进程的堆区，如果A为1，表示chunck来自映射的内存。由于mmmap返回的地址永远是页对齐的，可以通过chunck地址的高位确定它来自的heap M(0x2) 当申请的内存太大时，malloc会直接使用mmap创建一个超大的chucnk，M位标记该chunck是直接使用mmap创建的 P(0x1) 标记前一个邻接的chunck正在被使用，此时mchunk_prev_size字段无效，设置该位会阻止邻接chunck的合并 malloc返回的是分配的chunck的mchunk_size之后的地址，即fd和bk是分时复用的 此外，在chunck结构体之后，还有一个隐含的冗余size字段，它用于保护chunck。当用户不慎使用了错误的指针运算修改了mchunk_size字段时，glibc可以通过冗余的size字段判断出异常，并发出警告 一个arena通过四个链表记录了空闲的chuck，这些链表被称为bins fastbinarena的mfastbinptr fastbinsY[NFASTBINS];字段表示了fastbin，它是一个数组，数组的每个元素都是一个单链表的表头，链表中的所有chunck的大小都是相同的 与python相似，fastbinsY的索引也表示大小类别，通过申请内存的大小可以快速确定索引。fastbin是malloc申请内存的快速通道 fastbin的P位置零，用于阻止chunck合并 unsorted bin释放后的chunck会先进入unsorted bin，随后（触发某个条件后）它们会被排序，然后进入其他bin small binsmall bin是normal bin的一部分，它们通过双向链表组织。normal bin即arena的mchunkptr bins[NBINS * 2 - 2];成员 当unsorted bin排序后，chunck如果足够小，会进入small bin。此时尝试将该chunck与small bin中已有的chunck进行合并，合并后的chunck进入large bin。因此，small bin不存在邻接的chunck 当从small bin中取出chunck时，只需要取出第一个足够大的chunck即可 large bin当unsorted bin排序后，chunck如果足够大，会进入large bin，此外，还可以由small bin中的chunck合并得来 当从large bin中取出chunck时，需要寻找足够大的chunck中最小的一个，此时的chunck可能还是比需要的大小更大，需要将该chunck分为两个chunck，一个chunck可以恰好满足需要的大小，剩下的chunck可以继续使用 ","date":"2024-08-04","objectID":"/posts/week8/:4:2","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#small-bin"},{"categories":null,"content":" chunckQ：为什么malloc需要提供申请的内存的大小，而free不需要 A：因为malloc返回的内存是chunck的一部分，而chunck记录了该chunck的大小 chunck是一块长度不固定的内存，两个相邻的chunck可以合并成一个更大的chunck chunck结构如下 C struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size;// chucnk空闲时表示临接的chunck的大小，用于chunck合并 INTERNAL_SIZE_T mchunk_size; // chunck的大小 struct malloc_chunk* fd; // forward的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* bk; // back的缩写，在chuck空闲时用于形成双向链表 struct malloc_chunk* fd_nextsize; // 指向更大的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 struct malloc_chunk* bk_nextsize; // 指向更小的chunck，当chunck较大时用于形成双向链表，chunck较小时不使用 }; 由于需要记录一些元数据，一个chunck会有一些额外的空间开销 规定一个chunck的大小为8字节的倍数，当用户申请的空间+chunck额外开销不足8字节倍数时，需要向上取整。由于chunck的大小是8字节的倍数，mchunk_size字段的低三位一直是零，可以用来记录一些额外的信息 text +-------------+---+---+---+ | mchunk_size | A | M | P | +-------------+---+---+---+ A(0x4) 用于标记该chunc所属的heap是否是通过mmap获得的。增加这一标志后，如果A为0，表示chucnk来自主arena，即进程的堆区，如果A为1，表示chunck来自映射的内存。由于mmmap返回的地址永远是页对齐的，可以通过chunck地址的高位确定它来自的heap M(0x2) 当申请的内存太大时，malloc会直接使用mmap创建一个超大的chucnk，M位标记该chunck是直接使用mmap创建的 P(0x1) 标记前一个邻接的chunck正在被使用，此时mchunk_prev_size字段无效，设置该位会阻止邻接chunck的合并 malloc返回的是分配的chunck的mchunk_size之后的地址，即fd和bk是分时复用的 此外，在chunck结构体之后，还有一个隐含的冗余size字段，它用于保护chunck。当用户不慎使用了错误的指针运算修改了mchunk_size字段时，glibc可以通过冗余的size字段判断出异常，并发出警告 一个arena通过四个链表记录了空闲的chuck，这些链表被称为bins fastbinarena的mfastbinptr fastbinsY[NFASTBINS];字段表示了fastbin，它是一个数组，数组的每个元素都是一个单链表的表头，链表中的所有chunck的大小都是相同的 与python相似，fastbinsY的索引也表示大小类别，通过申请内存的大小可以快速确定索引。fastbin是malloc申请内存的快速通道 fastbin的P位置零，用于阻止chunck合并 unsorted bin释放后的chunck会先进入unsorted bin，随后（触发某个条件后）它们会被排序，然后进入其他bin small binsmall bin是normal bin的一部分，它们通过双向链表组织。normal bin即arena的mchunkptr bins[NBINS * 2 - 2];成员 当unsorted bin排序后，chunck如果足够小，会进入small bin。此时尝试将该chunck与small bin中已有的chunck进行合并，合并后的chunck进入large bin。因此，small bin不存在邻接的chunck 当从small bin中取出chunck时，只需要取出第一个足够大的chunck即可 large bin当unsorted bin排序后，chunck如果足够大，会进入large bin，此外，还可以由small bin中的chunck合并得来 当从large bin中取出chunck时，需要寻找足够大的chunck中最小的一个，此时的chunck可能还是比需要的大小更大，需要将该chunck分为两个chunck，一个chunck可以恰好满足需要的大小，剩下的chunck可以继续使用 ","date":"2024-08-04","objectID":"/posts/week8/:4:2","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#large-bin"},{"categories":null,"content":" tcache为了加快malloc的速度，可以缓存一些空闲的chunck，这些chunck是每个线程都有的（Thread Local Storage），即per thread cache，简称tcache tcache定义如下 C typedef struct tcache_perthread_struct { uint16_t counts[TCACHE_MAX_BINS]; tcache_entry *entries[TCACHE_MAX_BINS]; } tcache_perthread_struct; static __thread tcache_perthread_struct *tcache = NULL; __thread是GCC的私有关键字，用于声明线程局部存储。当一个线程第一次使用malloc时，会触发tcache的初始化流程 tcache表示一个数组，其中每个元素是单链表的表头，但指向的不是chunck首地址而是payload，这样的chunck可以直接返回给用户。每个单链表的所有chunck的大小都是相等的，entries的索引表示大小类别，就像fastbin，可以通过需要申请的大小快速计算出tcache的索引 由于tache是线程局部的，访问tcache不必加锁，比fastbin更快（fastbin可以通过原子操作访问）。当tcache不存在恰好满足的chunck时，会回退到fastbin ","date":"2024-08-04","objectID":"/posts/week8/:4:3","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#tcache"},{"categories":null,"content":" 总结glibc源码非常晦涩，有许多GCC特性，它是一个比较通用的内存管理系统，在空间开销、速度、减少内存碎片三个角度做了充分的权衡。这也导致了它在一些场合下性能不足某些 特化的内存管理系统 ","date":"2024-08-04","objectID":"/posts/week8/:4:4","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#总结-1"},{"categories":null,"content":" python vs glibc相同 使用大小类别使大部分内存请求都在在 O(1) 的时间复杂度内完成 都使用了缓存加快速度（usedpools、tcache） 不同 Python的内存管理系统开销非常大，实际上，Python语言本身就是一个开销比较高的语言 Python的内存管理系统强调规整化内存请求，减少内存碎片。glibc强调通用性 最后，来复习一下计算机系统结构中的8个伟大思想 面向摩尔定律的设计 使用抽象简化设计 Python使用arena、pool、block抽象描述内存分配系统，而glibc使用arena，heap，chunck，使用上述抽象将内存管理系统简化为 操作各个对象 加速大概率事件 Python使用usedpools，glibc使用tcache和fastbin。对于绝大部分内存请求，只需要根据请求的大小类别就可在常数时间内完成内存的分配 通过并行提高性能 glibc提供了多个arena，本质是降低锁的粒度，提高内存管理系统的并发度。此外，glibc还使用了原子操作访问fastbin，甚至使用线程局部的tcache，实现“无锁并发”（实际上操作的数据都不是同一个） python由于GIL的存在，内存管理系统并没有考虑并发 通过流水线提高性能 通过预测提高性能 现代CPU通过分支预测提高流水线的吞吐率，分支预测失败时，需要清空流水线，开销较大。Python和glibc都使用了GNU的__builtin_expect控制分支的汇编代码生成，有利于提高流水线的吞吐率 存储器层次 内存管理系统并没有涉及主存以外的存储器，但从缓存的角度，tcache和usedpools都充当了缓存加快了内存分配速度 此外，usedpools去除了pool_header中无用的其他数据，使得cache line中能存放更多的usedpools元素，有利于使用高速缓存加快速度 通过冗余提高可靠性 glibc通过冗余size字段，实现了一定程度的发现内存错误甚至是修复错误的功能 python由于其内存分配系统的用户是CPyhton和Python C扩展的开发者，CPython提供了_PyMem_DebugMalloc帮助他们发现内存错误。_PyMem_DebugMalloc的实现中实际上包含了一些冗余信息，但不在本文范围之内 ","date":"2024-08-04","objectID":"/posts/week8/:5:0","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#python-vs-glibc"},{"categories":null,"content":" 关于内存分配系统我认为内存分配系统实际上是一个内存分时复用系统。提及分时复用，大部分人也许会想到计算机网络学到的分时复用（Time Division Multiplexing，TDM） 如果将每次的内存申请看作用户请求使用一定的带宽，而进程拥有的所有内存看作线路，就能看出内存分配系统与分时复用系统的相似性 内存分配系统存在的必要基于两个事实 内存不是无限的 进程需要长期运行，如果不分时复用内存，迟早用完所有的物理内存 由此可以推出，某些短期运行的进程，也许可以不手动释放内存，可以依靠进程退出时操作系统释放进程占据的所有页这一手段来释放内存 ","date":"2024-08-04","objectID":"/posts/week8/:6:0","series":null,"tags":null,"title":"努力成为Python core dev的第八周：从libc到python，我要的内存从哪儿来的？","uri":"/posts/week8/#关于内存分配系统"},{"categories":null,"content":"解决了工具链的问题，还只能在命令行完成项目的构建。要使用IDE进行C++开发，除了工具链的知识外，还需要了解其他知识才能配置出一个好用的C++ IDE ","date":"2024-07-27","objectID":"/posts/week7/:0:0","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#"},{"categories":null,"content":" 前置概念 “古代”并没有IDE，或并没有合格的IDE，开发者使用的工具基本等于文本编辑器 “近代”的IDE往往是编译器厂商做的，即IDE的vendor往往也是compiler的vendor，可以认为是一种捆绑销售策略 IDE的很多知识都可以通过配置neovim学习。neovim是vim的分支，相比vim，他有以下优点 支持异步 neovim建立的一个原因就是vim的异步支持太烂，neovim获得成功后，倒逼vim也添加了异步功能 内置LSP支持 提供了一套API供LSP插件调用 使用lua作为配置语言 性能远超vim script etc ","date":"2024-07-27","objectID":"/posts/week7/:1:0","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#前置概念"},{"categories":null,"content":" LSPlanguage server protocol即语言服务器协议，它是由microsoft提出的一个JSON RPC（基于JSON的远程过程调用）协议 microsoft开发的VSCode是一个轻量的IDE，大部分功能都由插件提供。进行某个语言的开发就需要使用到诸如语法高亮，跳转到定义，查找引用等功能，这些功能由对应的语言插件提供，而这些功能就被称为语言服务 由于插件和VSCode的editor是分开的，需要一种机制通信。LSP提出的目的就是作为语言服务器和文本编辑器通信的规范 LSP的提出让IDE支持多种语言变得非常简单。过去一个IDE要支持多个语言就需要分别开发多个语言的语言服务功能，现在只需要提供LSP功能，然后分别启动对应语言的语言服务器即可。它促进了IDE与语言服务的解耦，也促进了分工（IDE厂商和语言服务器厂商各司其职） LSP是一个JSON RPC，语言服务器处于远程，而文本编辑器处于本地。但所谓远程仅仅指逻辑意义上的远程。例如大部分情况下，用户在本地进行开发，语言服务器也运行在用户的计算机中，此时可以使用例如unix socket等高效的信道，避免网络层、链路层、物理层造成的开销。远程开发时，语言服务器就处于远程，通过HTTP协议与文本编辑器通信 Note: 远程有物理和逻辑两种含义，逻辑的远程即相对进程而言，如果使用套接字等方式与本地另一个进程通信，此时可以被称为是逻辑的远程。物理上的远程可以是不处于同一个计算机，或不处于同一个局域网 此外，JSON RPC可以通过HTTP，即作为HTTP协议的上层协议。使用HTTP协议开发非常容易，因为它相当于web后端开发，此外JS操作JSON也非常简单，大大简化了vscode语言插件的开发 ","date":"2024-07-27","objectID":"/posts/week7/:2:0","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#lsp"},{"categories":null,"content":" 语言服务器语言服务器为了提供语言服务，需要一些信息。以python为例，它需要python的安装目录，以读取第三方库的信息，此外，它还需要了解项目的结构，这样才能提供跨文件跳转，相对导入等功能 LSP规定了若干语言服务器可以提供的功能 自动补全 跳转到定义 跳转到声明 鼠标悬停显示文档（hover动作显示宏展开，函数签名，类型定义，文档等） 查找引用 符号重命名 代码折叠范围 Code Action etc 一个语言服务器不必实现全部功能，LSP允许语言服务器告知文本编辑器它所支持的功能，即语言服务器的能力 ","date":"2024-07-27","objectID":"/posts/week7/:3:0","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#语言服务器"},{"categories":null,"content":" clangdC++开发最好用的语言服务器就是clangd了，clangd是clang相关工程的产物，clang相关工程有很多强大的配套工具，我目前只使用过clangd和clang-format，还剩很多工具等待挖掘 参见clangd的文档，为了提供语言服务，它需要知道每个文件的编译命令，编译命令实际上提供了以下clangd需要的信息 头文件搜索路径 用户定义的宏 编译的二进制产物（用于定位外部定义的变量） clangd需要的编译命令可以通过compile_commands.json文件提供。为了使用clangd，只需要想办法根据C++项目配置生成这个文件即可 Makefile工程 使用Bear生成compile_commands.json CMake工程 CMake可以通过打开CMAKE_EXPORT_COMPILE_COMMANDS选项来导出compile_commands.json shell cmake -DCMAKE_EXPORT_COMPILE_COMMANDS=1 注意CMake只有在生成Makefile工程或Ninja工程时，才能导出compile_commands.json This option is implemented only by Makefile Generators and Ninja Generators. It is ignored on other generators. Visual Studio工程 安装Visual Studio的插件clang power tools，Visual Studio打开工程后，右键解决方案，在上下文菜单中点击“Export Compilation Database”即可，参考generate-json-compilation-database clangd是一个非常强大的语言服务器，体验不输各种商业化的语言服务器（其他很多语言的语言服务器基本都是商业的更好用），而且clangd作为clang相关工程的产物，是自由开源软件，可以说是clang给全世界的馈赠 ","date":"2024-07-27","objectID":"/posts/week7/:4:0","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#clangd"},{"categories":null,"content":" debugger不同的工具链都有debuger，例如GNU工具链有gdb，LLVM有LLDB 要能够调试，需要在编译时指示编译器在生成二进制时携带调试信息 调试是一个非常大的话题，以下是我了解的部分 可调试的可执行或库携带调试信息，这些信息包括机器指令与源码文件+行号的映射关系 debugger是另外一个进程，它需要attach上被调试进程 调试需要硬件支持，涉及中断 linux提供ptrace系统调用，供debugger使用 具备以上知识只能在命令行调用debugger，在绝大部分情况下我们都是使用IDE的debug功能。就像LSP，debuger也有协议与文本编辑器通信，这样IDE就不需要自己实现每个语言的调试功能，这个协议为DAP，即Debug Adapter Protocol 有了DAP，debugger就能和IDE分离，debugger可以运行在远程，而IDE运行在本地，这样的调试被成为远程调试 调试时常用功能如下 变量查看 函数调用堆栈查看 执行命令 以gdb为例，常用p命令（打印表达式），x命令（查看任意地址的内容），disass命令（查看反汇编结果），i r命令（查看寄存器） ","date":"2024-07-27","objectID":"/posts/week7/:5:0","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#debugger"},{"categories":null,"content":" 例子一：使用VSCode阅读并调试CPython源码拉取源码，切换到稳定分支（因为主分支可能有不稳定的特性） shell git clone git@github.com:python/cpython.git cd cpython \u0026\u0026 git checkout 3.12 阅读python dev guide，安装依赖（可选） shell sudo apt-get install build-essential gdb lcov pkg-config \\ libbz2-dev libffi-dev libgdbm-dev libgdbm-compat-dev liblzma-dev \\ libncurses5-dev libreadline6-dev libsqlite3-dev libssl-dev \\ lzma lzma-dev tk-dev uuid-dev zlib1g-dev libmpdec-dev 安装扩展C/C++，Makefile Tools ","date":"2024-07-27","objectID":"/posts/week7/:6:0","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#例子一使用vscode阅读并调试cpython源码"},{"categories":null,"content":" 配置扩展设置阅读C/C++扩展的文档，想要让VSCode能够提供C的语言服务，需要配置C/C++扩展的intellisence，配置规则如下 C/C++扩展使用.vscode/c_cpp_properties.json记录Intellisence的配置，可以配置头文件搜索路径，用户定义的宏，C标准等等，详细配置选项见customize-default-settings-cpp C/C++扩展在无主动配置时可以自动生成一个默认的配置，其头文件搜索路径为项目的所有目录（即项目中任何头文件都能被搜索到） + 系统路径，用户定义的宏为空 C/C++扩展的intellisence配置也可以由CMake Tools扩展、Makefile Tools扩展提供 compile_commands.json也能提供足够信息让intellisenc工作 CPython作为一个传统开源项目，使用auto tools + Makefile，对于这样的工程，可以使用Makefile Tools扩展，它识别项目结构，并将intellisence配置提供给C/C++，这样就能在VSCode使用C的语言服务 需要配置以下设置 Makefile路径 pre config脚本（即configure） Makefile Tools扩展会先运行configure，然后dry-run生成的Makefile，最终生成intellisence配置 我在使用以上方案时，发现一些问题 Makefile Tools扩展的pre config无法指定脚本运行路径，无法支持树外构建（可以自己写一个脚本，cd build \u0026\u0026 ../configure） Makefile dry-run太慢，而且日志不直接输出在VSCode窗口内，需要手动查看日志文件 每次用VSCode打开项目，都会重新pre config 然后dry-run，浪费时间 为了避免以上问题，我使用Bear生成compile_commands.json，然后将这个文件提供给C/C++扩展 shell mkdir build \u0026\u0026 cd build ../configure --with-pydebug --prefix=/home/z2z63/src/cpython/build/usr bear -- make 设置C/C++扩展的选项 设置完成后，C/C++扩展会完成项目的扫描，可以通过右下角的状态栏图标确认intellisence的状态 至此已经完成了intellisence的设置，可以正常使用语言服务的功能阅读CPython源码了 ","date":"2024-07-27","objectID":"/posts/week7/:6:1","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#配置扩展设置"},{"categories":null,"content":" 构建CPython在终端输入命令 shell cd build make 即可完成构建 每次都输入命令比较麻烦，VSCode的语言插件可以帮助创建默认的构建任务，但不一定符合需求，由于以上都是自定义的，所以也需要自定义一个构建的任务，任务在.vsocde/tasks.json中定义 点击 Terminal - Configure Tasks 选择Create task.json file from template 模板选择others 这样就创建了一个默认的tasks.json json5 { // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format \"version\": \"2.0.0\", \"tasks\": [ { \"label\": \"echo\", \"type\": \"shell\", \"command\": \"echo Hello\" } ] } 稍加改动即可 json { \"version\": \"2.0.0\", \"tasks\": [ { \"label\": \"build cpython\", \"type\": \"shell\", \"command\": \"make\", \"problemMatcher\": [ \"$gcc\" ], \"options\": { \"cwd\": \"${workspaceFolder}/build\" }, \"group\": \"build\" } ] } 然后将此任务设置为默认的构建任务 通过Ctrl+Shift+B快捷键触发构建时，会执行这个任务 Note: 关于task的文档参见 Integrate with External Tools via Tasks ","date":"2024-07-27","objectID":"/posts/week7/:6:2","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#构建cpython"},{"categories":null,"content":" 调试CPythonCPython是一个解释器，它的主要工作是执行python脚本 创建一个test/fib.py目录，内容如下 python def fib(n): if n \u003c 2: return 0 else: return fib(n-1) + fib(n-2) print(fib(10)) 然后使用gdb进行调试 shell gdb build/python test/fib.py 即可进入gdb调试 C/C++扩展提供了C的调试功能，但需要配置。配置一般来说是通过CMake Tools等扩展提供的，由于以上的配置是自己设置的，C/C++的默认配置也不能满足需求，需要手动配置 创建一个空的launch.json文件 原内容如下 json5 { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [] } 使用C/C++提供的模板，快速填充 裁剪部分内容，最终如下 json { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"(gdb) Launch\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/build/python\", \"args\": [ \"test/fib.py\" ], \"cwd\": \"${workspaceFolder}\", \"externalConsole\": false, \"MIMode\": \"gdb\", } ] } 在Programs/python.c的main函数打上断点，按下F5，即可进入调试 如果想要输入gdb命令，需要在前面加上-exec 如果想要直接运行而不调试，可以按下Shift + F9，或点击 Run - Run Without Debugging Note: 关于launch的文档见 Debugging ","date":"2024-07-27","objectID":"/posts/week7/:6:3","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#调试cpython"},{"categories":null,"content":" 例子二：使用VSCode调试glibc下载源码包，并解压 text wget https://ftp.gnu.org/gnu/glibc/glibc-2.40.tar.gz tar xvf glibc-2.40.tar.gz 补充一个常识，根目录下文件名全大写的文件往往是非常重要的文件，现在常用README.md作为项目的说明，在markdown还没有流行的“近代”或“古代”，往往使用README，此外，C项目往往还会提供INSTALL文件，用来说明如何安装软件 glibc根目录下的INSTLL提及 The GNU C Library cannot be compiled in the source directory. You must build it in a separate build directory 即glibc必须树外构建，而且这种树外构建更复杂，要求源码树和构建目录在两个不同的目录下 调整项目结构 shell mkdir src mv ../glibc src mkdir build 形成的结构如下 text glibc ├── build └── src （原glibc根目录） 进入build目录完成configure shell cd build ../src/configure --prefix=/home/z2z63/src/glibc/build/usr 之后配置C/C++扩展，获得语言服务的步骤同例子一 ","date":"2024-07-27","objectID":"/posts/week7/:7:0","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#例子二使用vscode调试glibc"},{"categories":null,"content":" 调试glibc与python不同，glibc的二进制产物是名为libc的动态库，动态库是不能被直接调试的，需要提供一个可执行，它链接到动态库，然后可执行调用动态库中的函数，就能进入到动态库中了 此外，glibc构建后的二进制产物是不能被链接的，因为文件分布的位置不正确，需要安装 shell make install 然后在项目根目录创建main.c，让它作为入口 c #include \u003cmalloc.h\u003e int main(int argc, char** argv){ int* a = (int*)malloc(sizeof(int)); *a = 10; free(a); return 0; } 然后，只需要让main.c在链接时，链接到刚刚安装的glibc，而不是系统路径的glibc shell gcc main.c -g -Xlinker -rpath=/home/z2z63/src/glibc/build/usr/ -o build/main -Xlinker表示后面的参数传递给链接器，-rpath=/home/z2z63/src/glibc/build/usr/指将/home/z2z63/src/glibc/build/usr/作为rpath嵌入到生成的elf中 rpath是linux动态链接器提供的机制，如果一个可执行动态链接到一些动态库，通常指这个可执行在执行前需要链接到这些库。 Note: 动态库还可以在进程启动后，通过dlopen函数打开，这样的链接被称为运行时动态链接 内核完成elf解析并将相应的段装载至内存后，设置返回的PC为动态链接器的入口地址，退出内核态进入用户态后，动态链接器开始工作，它将需要的动态库加载进内存，并修正GOT（全局偏移表），这样就能够调用其他ELF中的函数，或引用其他ELF中的对象。动态链接器完成bootstrap后，__start开始执行，完成诸如全局变量初始化等工作，最后，main开始执行，至此才进入了用户的入口函数 动态链接器位于/usr/lib/ld-linux-x86-64.so.2，它在加载动态库时，由于默认的/lib和/usr/lib的查找优先级最低，可以被诸如rpath、LD_LIBRARY_PATH等设置覆盖 使用ldd命令验证已经正确链接到了指定的glibc shell $ ldd build/main linux-vdso.so.1 (0x00007509b4e22000) libc.so.6 =\u003e /home/z2z63/src/glibc/build/usr/lib/libc.so.6 (0x00007509b4c37000) /lib64/ld-linux-x86-64.so.2 =\u003e /usr/lib64/ld-linux-x86-64.so.2 (0x00007509b4e24000) 添加.vscode/launch.json文件 json { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"(gdb) Launch\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/build/main\", \"args\": [], \"cwd\": \"${workspaceFolder}\", \"externalConsole\": false, \"MIMode\": \"gdb\", } ] } 然后在main.c的第四行，即 c int* a = (int*)malloc(sizeof(int)); 打上断点，按下F5，再点击Step into或按下F7，成功进入了glibc的malloc实现 ","date":"2024-07-27","objectID":"/posts/week7/:7:1","series":null,"tags":null,"title":"第七周：关于C/C++开发，我了解的一切 —— LSP、debugger与IDE","uri":"/posts/week7/#调试glibc"},{"categories":null,"content":"最近两个月也是基本一直在写C++了，尤其是实习以来，从linux的C++开发切换到windows + visual c++，这其中遇到的问题非常多，也让我不断的思考究竟怎样才是最佳实践。 此外，实习期间摸鱼时，也阅读了不少python源码，为了理解python的内存管理系统，还翻了四五遍glibc的wiki，粗略看了malloc源码，也算是学到了不少知识，为了分享这些知识，我决定先将我从各种项目中学习到的C/C++开发应该了解的知识系统总结一下 ","date":"2024-07-20","objectID":"/posts/week6/:0:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#"},{"categories":null,"content":" 前置概念 C/C++是系统开发语言，绝大部分操作系统的系统调用都是以C/C++的API形式提供的 C++不应该被视为一种语言，而是一个松散的语言联邦。可以认为GNU的C++是gnu-cpp语言，而Microsoft的C++是visual-cpp语言。而这些xxx-cpp语言恰好满足了一个名为C++的语言联邦的约定，于是都称为C++ 接上，以上观点的原因是，不同平台的C++开发区别实在是太大了。Windows的C++开发者和Linux的C++开发者表面上都在开发C++，但是他们的考虑到底层的方式，使用的工具，使用工具的方式都是截然不同的。例如同一个printf，linux的C++开发者会想到文件描述符，会想到tty等等，而Windows的C++开发者会想到Win32 API，会想到回车换行符，会想到控制台主机等等 C++开发者在跨平台时，需要能够跨CPU架构、操作系统、libc++实现、编译器 undefined behavior（UB）,即未定义行为，指C++标准明确规定此行为的结果不确定，UB不是未文档的行为 implementation-defined behavior（IB），即实现定义行为，指C++标准规定此类行为的结果应该由C++实现（通常是编译器vendor）规定 UB，IB的行为往往是根据当前架构，当前实现方式中选取的性能最好的一种行为，即C++跨平台时需要考虑避免UB和IB ","date":"2024-07-20","objectID":"/posts/week6/:1:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#前置概念"},{"categories":null,"content":" 工具链为了将源码转变为最终的二进制，需要编译器、汇编器、链接器、调试器共同工作 此外，往往还需要配套的构建工具例如makefile、cmake等，他们共同组成了C++工具链 工具链往往跟平台有关，linux往往使用GCC工具链中的gcc作为编译器，as作为汇编器，ld作为链接器，gdb作为调试器 此外，一套工具链中的工具是相互协作，共同生成二进制。例如gcc会在编译时，将一些信息嵌入ELF某些段中，指示ld如何工作，因此gcc编译的中间产物不能被其他链接器使用，不同平台的汇编代码也不同，例如GCC的汇编器是GAS(GNU Assember)，其语法与visual c++的汇编器MASM不同。因此，生成二进制产物必须由一套工具链的工具相互协作，不能混用工具链 对于传统开源项目，常常使用GNU的autotools，makeilfe作为构建工具。对于现代C++项目，通常使用CMake作为构建工具，CMake在linux平台往往使用makefile完成最终的构建；而windows可以选择microsoft提供的visual c++工具链，并使用Visual Studio进行开发，Visual Studio往往会调用msbuild或nmake完成构建 ","date":"2024-07-20","objectID":"/posts/week6/:2:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#工具链"},{"categories":null,"content":" 编译参数编译参数即传给编译器的参数。广义的编译参数包括任何字面上传递的参数，狭义的编译参数指一些控制编译器行为的标志，而不包括诸如头文件搜索路径，源文件路径等等 以gcc为例，编译参数一般有一下部分 头文件搜索路径 源文件路径 输出产物路径 优化参数 所谓优化，即将一段代码转为效率更高，但是结果等价的代码 优化参数通常为-f开头，用于控制是否开启某项编译优化手段 此外，还提供了-O0，-O1，-O2，-O3方便使用，会分别批量打开对应的优化开关 -O0表示关闭所有开关，而-O3表示开启所有开关 常使用O2而不使用O3，原因如下 在gcc历史上有段时期O3并不稳定 O3的优化结果的等价性更依赖于无UB，大部分开发者无法避免写出无UB的程序，O3优化容易使得这些程序出现错误 O2已经提供了足够使用的优化 O3优化在进行循环展开时，可能导致循环体超过cache line的大小，反而降低速度 O3优化可能利用当前平台特性，可能导致二进制产物无法在其他平台运行 功能参数 警告参数 通常-W开头，用于单独控制是否对某个行为发出警告 如果抑制警告，通常是-Wno开头 -Wall表示开启所有警告，常用于避免潜在的问题 -Werror表示将警告转为错误，在比较严格的场合下用于强制开发者消除所有警告 语言特定参数 诊断参数 静态分析参数 代码生成参数 用于控制输出的二进制产物，例如-fPIC控制生成地址无关代码，常用于生成共享对象 链接器参数 gcc会在内部调用ld，链接器参数会直接传递给ld 汇编器参数 同理，gcc会在内部调用as，链接器参数会直接传递给as 宏定义参数 部分宏定义需要在编译时传入，以控制程序的行为 ","date":"2024-07-20","objectID":"/posts/week6/:3:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#编译参数"},{"categories":null,"content":" 如何编译大部分场合下，编译时需要指定的编译参数如下 头文件搜索路径 库搜索路径 优化参数 调试参数 宏定义参数 对于一个单文件，可以在shell中输入编译命令，快速完成编译 对于C/C++工程，手动输入编译命令非常繁琐，在“古代”的方法是使用shell脚本记录编译的命令，问题如下 大型项目构建时间非常长，仅仅修改一个文件也需要重新完成整个工程的编译 如果需要传入参数以控制编译行为，脚本就会变得越来越复杂 ","date":"2024-07-20","objectID":"/posts/week6/:4:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#如何编译"},{"categories":null,"content":" MakefileMakefile就是为了解决以上问题而出现的，它可以认为是shell脚本的一种封装 Makefile有以下内容： 规则 规则告诉Makefile如何生成target 规则分为显式规则和隐式规则，显式规则组成如下 target 通常是输出产物的路径名，即一个规则会产生文件，使用伪target可以定义不产生文件的规则 prerequisites 执行规则前应当满足的先决条件 recipe 规则如何执行，会交给shell解释执行 变量定义 其他指令 例如include指令可以引入其他Makefile文件 makefile的隐式规则可以节省非常多的代码，例如 aaa.o如果没有对应的规则可以生成，Makefile会自动应用隐式规则，将aaa.c编译得到aaa.o CC为默认的C编译器，CXX为默认的C++编译器 CFLAGS为默认编译时，传递给CC的编译参数，同理CXXFLAGS是默认传递给CXX的编译参数 ","date":"2024-07-20","objectID":"/posts/week6/:5:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#makefile"},{"categories":null,"content":" autotoolsC的一个特点是利用宏定义和条件编译，可以控制参与编译的代码，做到适应各种平台，例如 跨平台软件实现子进程时，利用条件编译可以在不同的平台调用相应的系统调用 c #ifdef LINUX // fork ... #endif #ifdef WIN32 // CreateProcess... #endif 注意一般只有标准库没有提供的功能才有必要使用这种方法，例如读写文件就可以直接使用标准库 实现一个高性能的HTTP服务器时往往使用epoll，但内核版本比较旧的linux系统没有epoll，可以使用其下位替代select c #ifdef HAVE_EPOLL // epoll... #else // select #endif C标准没有规定如何控制符号导出，为了导出动态库，可以在windows平台使用visual c++的扩展__declspec(dllexport)，在linux平台可以使用GNU扩展__attribute__((visibility(\"default\"))) c #ifdef LINUX #define MYEXPORT __attribute__((visibility(\"default\"))) #endif #ifdef WIN32 #define MYEXPORT __declspec(dllexport) #endif 所以一个C/C++项目在build之前往往还有configure的步骤，configure识别当前平台、工具链，并允许设置一些功能开关，供用户裁剪功能，configure的产物是一堆用户定义的宏和变量，用于传入构建系统。autotools完成的就是configrue的工作 autotools非常复杂，基于非常原始的文本替换，而且只能在linux平台使用，并不推荐学习autotools，只需要掌握如何使用autotools的configure即可 autotools给编译者（一般区别于开发者）提供的接口为configure，它是一个在项目根目录的具有执行权限的脚本，一般用法如下 shell CFLAGS=-O2 -g ../configure --prefix=/home/arch/xxx configure提供的开关由开发者定义，需要使用../configure --help查看支持的所有开关 CFLAGS通常作为环境变量传入configure，随后configure将参数嵌入生成的Makefile中 --prefix一般用于指定安装目录，默认安装目录/usr/local需要root权限，也可以手动指定一个无特权目录 autotools虽然本身的概念非常晦涩，从设计上来说也不好用，但许多大型开源项目都使用了autotools，原因如下 大部分使用autotools的项目都是历史悠久的老牌开源项目，当时只有autotools可选 autotools是GNU三板斧之一，GNU认为自由软件构建所需的工具链也得是自由的 ","date":"2024-07-20","objectID":"/posts/week6/:6:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#autotools"},{"categories":null,"content":" 树外构建大部分构建工具都会缓存构建中间产物以加快构建速度，套用本博客的文章《第二周：败者树、范式与反范式》的观点，构建中间产物是cache，它违反了唯一事实原则。其后果是在某些情况下，中间产物可能不是最新的，这时需要强制清空所有构建产物，执行一次干净的构建。因此，构建工具往往提供clean的功能 如果将源文件在文件系统中的分布看作源码树，那么直接在项目根目录进行构建，构建的中间产物就会和源码树混杂在一起，这样的构建被称为树内构建，在clean时，需要深入源码树每个层级，精准删除构建中间产物而不删除源文件。Makefile的clean目标一般是使用find命令实现的 构建的中间产物就会和源码树混杂在一起后，会产生如下问题 使得clean操作变得复杂（甚至部分项目无法保证彻底clean，例如glibc） 开发时大量无关文件和源文件混杂，影响效率 鉴于树内构建的问题，通常使用树外构建，即创建一个目录（通常为build），进入此目录进行构建。构建后，输出的构建中间产物和最终产物都在build目录内，clean时不必担心误删源文件 autotools + Makefile的树外构建流程如下 新建一个目录用于构建并进入该目录 shell mkdir build cd build 完成configure shell ../configure 构建 shell make ","date":"2024-07-20","objectID":"/posts/week6/:7:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#树外构建"},{"categories":null,"content":" CMake前文提及的autotools + Makefile在许多老牌开源项目中被使用，但它也有很多问题 只能在linux平台使用 命令式语法，经常需要重复处理一些琐碎细节 支持多种工具链的心智负担大 CMake是相比Makefile更优的做法，它使用CMakeLists.txt文件管理工程，CMake完成的是configure的过程，它本身并不负责构建，而只负责生成构建配置。 CMake核心概念是target，target可以通过add_executable，add_library，add_custom_target产生 add_executable会使输出的二进制中增加对应的可执行 add_library可以输出动态库，静态库，也可以是接口库，接口库是CMake的概念，相比其他库，接口库没有构建的过程 add_custom_target用于执行任意命令 target可以携带属性，可以通过set_target_properties设置属性，通过get_target_property访问属性，例子： 可执行可以携带WIN32_EXECUTABLE 属性，这样的可执行在windows平台运行时，是窗口程序，不需要控制台主机或windows terminal作为宿主，可以显示Win32的窗口，其入口函数为WinMain 库可以携带属性，控制其输出产物，例如SHARED输出共享库，STATIC输出静态库，MODULE输出不参与链接其他target，可供dlopen在运行时动态链接的库 ","date":"2024-07-20","objectID":"/posts/week6/:8:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#cmake"},{"categories":null,"content":" CMake的跨平台特性CMake在不同的平台有不同的行为 CMake会自动调整输出产物的格式，在windows平台输出exe、dll、lib，在linux平台输出可执行（无扩展名）、so（共享库）、a（静态库） CMake在不同平台生成对应的工程，例如在linux平台默认生成Makefile工程，在windows平台默认生成Visual Studio工程，在MacOS平台默认生成XCode工程 find_pacakge时，在不同平台采用不同的搜索策略，符合这些平台组织软件包的方式 ","date":"2024-07-20","objectID":"/posts/week6/:8:1","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#cmake的跨平台特性"},{"categories":null,"content":" 第三方库CMake大大简化了C++项目使用第三方库的过程，经过实践，我认为find_package和ExternalProject_Add是非常方便的功能 find_package在linux平台，许多C++第三方库可以通过包管理器安装，只要第三方库支持CMake，就会将Find\u003cPackageName\u003e.cmake或\u003cPackageName\u003eConfig.cmake或相似名称的CMake文件安装到/usr/lib/cmake/\u003cpackage-name\u003e/下 Note: 在Linux平台，安装指的是带权限的复制。man描述install命令为“install - copy files and set attributes” find_package在linux平台会搜索此目录，并执行其中的CMake文件，执行的结果通常包括设置了头文件搜索路径变量，添加了若干库；随后只需使用target_include_directories添加头文件搜索路径，使用target_link_libraries链接到此库即可 ","date":"2024-07-20","objectID":"/posts/week6/:8:2","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#第三方库"},{"categories":null,"content":" 第三方库CMake大大简化了C++项目使用第三方库的过程，经过实践，我认为find_package和ExternalProject_Add是非常方便的功能 find_package在linux平台，许多C++第三方库可以通过包管理器安装，只要第三方库支持CMake，就会将Find.cmake或Config.cmake或相似名称的CMake文件安装到/usr/lib/cmake//下 Note: 在Linux平台，安装指的是带权限的复制。man描述install命令为“install - copy files and set attributes” find_package在linux平台会搜索此目录，并执行其中的CMake文件，执行的结果通常包括设置了头文件搜索路径变量，添加了若干库；随后只需使用target_include_directories添加头文件搜索路径，使用target_link_libraries链接到此库即可 ","date":"2024-07-20","objectID":"/posts/week6/:8:2","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#find_package"},{"categories":null,"content":" ExternalProjectExternalProject是一个非常强大的功能，可以说是C++第三方库的最终银弹。 find_package在Linux平台的一个缺点是，它默认使用系统的软件包，而linux系统的软件包版本一般无法选择，由发行版软件源控制。许多项目使用的第三方库的版本比系统软件包的版本旧。linux软件包大部分也使用语义化版本（参考《第五周：CI/CD、git workflow与软件发行》）。如果主版本号不一致，一般是无法使用的。 此外，使用find_package的前提是第三方库提供了诸如Find\u003cPackageName\u003e.cmake这样的文件，然而还有些时候第三方库没有提供 以上问题都能通过ExternalProject解决，它提供了丰富的选项，支持使用HTTP下载，使用git拉取源码包，支持自定义configure、build、install 无论第三方库是如何组织软件包的，想要能够被别人调用，最终都需要提供两个信息：头文件搜索路径、库搜索路径。软件包在安装时，也通常是安装头文件和库，以及一些文档。通常使用ExternalProject拉取指定版本的第三方库源码，完成configure、构建、安装，然后手动配置其头文件搜索路径和库搜索路径 以AnyQ为例，以下是AnyQ引入指定版本的libcurl的配置 cmake include(ExternalProject) SET(CURL_PROJECT \"extern_curl\") SET(CURL_URL \"https://curl.haxx.se/download/curl-7.60.0.tar.gz\") SET(CURL_SOURCES_DIR ${THIRD_PARTY_PATH}/curl) SET(CURL_DOWNLOAD_DIR \"${CURL_SOURCES_DIR}/src/\") ExternalProject_Add( ${CURL_PROJECT} ${EXTERNAL_PROJECT_LOG_ARGS} DOWNLOAD_DIR ${CURL_DOWNLOAD_DIR} DOWNLOAD_COMMAND wget --no-check-certificate ${CURL_URL} -c \u0026\u0026 tar -zxvf curl-7.60.0.tar.gz DOWNLOAD_NO_PROGRESS 1 PREFIX ${CURL_SOURCES_DIR} CONFIGURE_COMMAND cd ${CURL_DOWNLOAD_DIR}/curl-7.60.0 \u0026\u0026 ./configure --prefix=${THIRD_PARTY_PATH} --without-ssl BUILD_COMMAND cd ${CURL_DOWNLOAD_DIR}/curl-7.60.0 \u0026\u0026 make INSTALL_COMMAND cd ${CURL_DOWNLOAD_DIR}/curl-7.60.0 \u0026\u0026 make install UPDATE_COMMAND \"\" ) 由于ExternalProject可以完全控制configure，可以在configure时，传入编译参数、功能开关等，实现第三方库携带调试符号，根据项目需求裁剪第三方库功能等需求。例如AnyQ就去掉了libcurl自带的ssl功能，在不需要HTTPS的场合下可以大大减小二进制大小 ","date":"2024-07-20","objectID":"/posts/week6/:8:3","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#externalproject"},{"categories":null,"content":" FetchContentFetchContent也能用来将其他C++项目集成进来，但这个项目必须也使用CMake 以上我并没有使用“第三方库”这样的字眼，因为FetchContent会将其他CMake工程的所有target全部添加到本CMake工程内，容易会造成名称冲突 相反，ExternalProject将第三方库转变成了一个target，并且能够指定target的名称，就不会出现名称冲突的情况 The ExternalProject_Add() function creates a custom target to drive download, update/patch, configure, build, install and test steps of an external project: ","date":"2024-07-20","objectID":"/posts/week6/:8:4","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#fetchcontent"},{"categories":null,"content":" CMake缺点写了这么多CMake的优点，终于轮到吐槽CMake了。没错，CMake本身的问题实在是太多了，但苦于CMake已经成了C++项目的事实标准，很多时候并没有更好的选择 所有指令都是无返回值的，任何输出都是输出到一个变量上，非常不符合大部分编程语言的习惯 不仅仅无返回值，很多指令的行为依赖于各种变量的定义，也就是输入不明显，行为依赖于执行到此指令时各种变量的值 甚至if else还有这种逆天语法 cmake if(\u003ccondition\u003e) \u003ccommands\u003e elseif(\u003ccondition\u003e) # optional block, can be repeated \u003ccommands\u003e else() # optional block \u003ccommands\u003e endif() 字符串操作可读性也非常不好 cmake string(REPLACE \u003cmatch-string\u003e \u003creplace-string\u003e \u003cout-var\u003e \u003cinput\u003e...) string(REGEX MATCH \u003cmatch-regex\u003e \u003cout-var\u003e \u003cinput\u003e...) 配合无返回值的设计，非常考验眼力 CMakeLists.txt一旦写长了，非常难以阅读。而了解一个项目最快的方式就是去阅读CMake配置，了解其构建流程 还有generator expression这种逆天设计 cmake # WRONG: New lines and spaces all treated as argument separators, so the # generator expression is split and not recognized correctly. target_compile_definitions(tgt PRIVATE $\u003c$\u003cAND: $\u003cCXX_COMPILER_ID:GNU\u003e, $\u003cVERSION_GREATER_EQUAL:$\u003cCXX_COMPILER_VERSION\u003e,5\u003e \u003e:HAVE_5_OR_LATER\u003e ) 此外，许多第三方库提供的Find\u003cPackageName\u003e.cmake等文件，并没有文档说明它添加了哪些库，设置了哪些变量。官网文档大部分不会提及如何使用find_package引入他们的库，在Find\u003cPackageName\u003e.cmake文件开头写段注释已经算是\"well documentated\"的做法（相信大部分人都不会去看这个文件里面的注释吧） CMake的文档也是又臭又长，许多指令的行为很复杂，因为传参很多，还能依赖于各种变量（通常是CMAKE开头）的定义，读文档非常考验耐心。CMake Tutorial写的也是又臭又长的风格，当然这也是C++项目的通病了 ","date":"2024-07-20","objectID":"/posts/week6/:8:5","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#cmake缺点"},{"categories":null,"content":" 分层配置如果在源码树中非常深的位置想要git不追踪某个文件，可以在项目的根目录写下这个文件相对根目录的路径 .gitignore aaa/bbb/ccc/ddd/eee/fff/ggg/a.out 然而这种做法并不优雅，git提供了更优的方法 在aaa/bbb/ccc/ddd/eee/fff/ggg/目录下创建一个.gitignore文件，其中写下 .gitignore a.out 优点是忽略这个文件的配置和这个文件距离很近，上下文关联强 同理，Makefile和CMake也支持这样的分层配置 Makefile可以通过Include指令添加子目录的Makefile，CMake可以通过include_subdirectory引入CMake子工程 以Paddle为例，源码树的每一层都有CMakeLists.txt text ➜ paddle git:(develop) fd CMakeLists.txt | tree --fromfile . ├── cinn │ ├── adt │ │ ├── CMakeLists.txt │ │ └── print_utils │ │ └── CMakeLists.txt │ ├── ast_gen_ius │ │ └── CMakeLists.txt │ ├── auto_schedule │ │ ├── analysis │ │ │ └── CMakeLists.txt │ │ ├── CMakeLists.txt │ │ └── search_space │ │ ├── auto_gen_rule │ │ │ └── CMakeLists.txt │ │ └── CMakeLists.txt │ ├── backends │ │ ├── CMakeLists.txt │ │ ├── llvm │ │ │ └── CMakeLists.txt │ │ └── nvrtc │ │ └── CMakeLists.txt │ ├── CMakeLists.txt │ ├── common │ │ └── CMakeLists.txt │ ├── hlir │ │ ├── CMakeLists.txt │ │ ├── dialect │ │ │ ├── CMakeLists.txt │ │ │ ├── operator │ │ │ │ ├── CMakeLists.txt │ │ │ │ ├── ir │ │ │ │ │ └── CMakeLists.txt │ │ │ │ └── transforms │ │ │ │ └── CMakeLists.txt ... 这样的配置可以将编译逻辑下放到源码树的末梢，并减少上层CMake工程变更，上层CMake工程关注整体架构，下层CMake工程关注编译细节，还能减少git协作时上层CMake配置变更冲突的情况 ","date":"2024-07-20","objectID":"/posts/week6/:9:0","series":null,"tags":null,"title":"第六周：关于C/C++开发，我了解的一切 —— 编译器、构建工具","uri":"/posts/week6/#分层配置"},{"categories":null,"content":"git相关文章在各种技术论坛、博客都能找到不少，可以说讲git已经是烂大街的文章了，这篇文章虽然跟git有关，但我希望避开各种无聊而且每篇文章都在谈论的话题，输出一些我从各种角落中积累的知识 Note: 如果想学习git，可以看《pro git》 ","date":"2024-07-14","objectID":"/posts/week5/:0:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#"},{"categories":null,"content":" CI/CD一个大型软件往往都有CI/CD系统，以我在实习中即将参与开发的一个产品来说，该产品（以下简称app）有以下需求 定期发布新版本 每次发布需要在多个平台同步发布，具体而言： Windows, Android, iOS, MacOS，iPad, Android平板，Linux等平台 在官网、Android各厂商的应用商店，app store，各种电脑管家提供的软件下载中心等平台发布 需求完成后需要交给测试同学完成测试，测试同学需要在相应平台安装app进行测试，此时的app是不对外公布的测试版本，在内部某个git分支上构建产生 以上需求需要长期、频繁地构建app，CI/CD系统完成的就是这种重复工作 ","date":"2024-07-14","objectID":"/posts/week5/:1:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#cicd"},{"categories":null,"content":" semverSemantic Versioning，即语义化版本，是软件包的一个约定，semver.org如是说 Given a version number MAJOR.MINOR.PATCH, increment the: MAJOR version when you make incompatible API changes MINOR version when you add functionality in a backward compatible manner PATCH version when you make backward compatible bug fixes 即： 版本号主要由主版本号.次版本号.修订号组成 同一个主版本号内保证不出现不兼容的改动 增加与前版本兼容的功能只需要增加次版本号 紧急bug，安全漏洞的修复可以通过增加修订号快速发布 semver面对的背景如下 软件包存在依赖关系 软件包需要持续迭代，不断增加功能并修复bug 上层软件希望它依赖的软件包是稳定的，不出现dependency break 下层软件希望上层软件包不断更新其依赖，使最新的特性被使用，并结束旧版本的支持 它解决了以下问题 下层软件可以不断迭代而不必担心其更新导致现有项目无法运行 历史遗留系统在部署时不出现dependency break 安全漏洞的修复可以最快地应用于生产环境的项目 semver在许多软件包发布系统中都有应用，例如linux众多发行版的软件源，pypi，npm等；当然也有很多不遵守的例子 linux内核 chromium PotoShop Visual studio matlab 不遵守semver的最直接的原因是，这些软件包并不存在直接的被依赖关系 ","date":"2024-07-14","objectID":"/posts/week5/:2:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#semver"},{"categories":null,"content":" semver的应用一个合格的包管理器往往集成了semver，npm和python都提供了版本标记语法，例如 ~5.0.0表示安装5.0.0并接受补丁 ^5.0.0表示安装5.0.0并接受兼容的功能更新 此外，也有特殊情况不遵守semver，一个合格的包管理器还应当具有锁版本的功能，即同一份配置文件在重新安装依赖时，一定产出一样的依赖以及依赖的依赖，保证依赖不发生任何变动 以cmake的ExternalProject为例，它提供了丰富的功能以完全控制一个第三方依赖 下载软件包 支持http下载、git下载、subversion下载、自定义命令下载 configure 可以在此阶段传入编译参数控制软件包的行为 build 可以自定义编译命令，完全控制构建过程和输出的产物 install 可以自定义安装命令，控制安装的位置 其中使用下载软件包支持下载指定分支、指定标签、指定hash，可以轻松控制软件包的版本。如果使用http下载，通常填入官网提供的release版下载链接，版本号通常在会出现在url中，也能控制软件包的版本 ","date":"2024-07-14","objectID":"/posts/week5/:3:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#semver的应用"},{"categories":null,"content":" semver与CI/CD与git前文提及CI/CD一般是在某个分支上（一般是main或master或release）构建出软件包，开发者只需要提交或合并，使分支发生更新，就能触发CI/CD git的每次提交都会产生hash，一般来说hash是整个仓库唯一的，在某次提交中构建出的软件包，可以以hash作为版本号的一部分 git还能给某次提交打上标签，针对这次提交构建出的软件包，可以将标签名作版本号的一部分。更进一步，实际上可以将版本号作为标签名，当分支上出现新的标签时，会触发CI/CD，并触发后续的发布流程 以上提及的流程是软件开发者只维护最新版本的情况，实际上，同时维护多个版本的情况是非常常见的，尤其是软件包已经作为依赖进入了生产环境 假设python2还没有停止支持，python开发者同时维护python2.x和python3.x，python2.x虽然不会出现功能更新，但仍然接受安全修复。更进一步，假设现在python3.12已经发布，而正在开发的是python3.13，此时python3.12发现一个漏洞需要立刻修复，此时使用一个分支作为CI/CD构建的分支是不够的。常见的做法是，python2.x使用release/2.x作为分支名，而python3.x使用release/3.x作为分支名，而release/目录下的所有分支都能触发CI/CD ","date":"2024-07-14","objectID":"/posts/week5/:4:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#semver与cicd与git"},{"categories":null,"content":" git workflowapp的开发部门有上百名开发者，git仓库每时每刻都有可能发生推送，为了实现百名开发者的协作，app采用了以下流程 release分支作为发布使用，在任何时刻release分支构建出来的软件包都是可以对外公布的包。release分支不接受推送，只接受master分支的合入 master分支拉出其他所有分支，不接受推送，只接受feature系列分支和bugfix分支的合入， feature系列分支具有实现需求的代码，不接受推送，只接受feature_dev系列分支合入。一次版本更新包括多个需求，会产生对应的feature分支 feature_dev系列分支是开发者个人使用的分支。一个需求一般对应一个feature分支，而一个需求往往由几个开发者合作完成，每个开发者分别在自己的feature_dev分支上开发 bugfix系列分支具有修复某个bug或某个安全漏洞的代码，完成修复后合入master 可以看出合并的顺序，或者从开发者敲下一行代码，到最终进入产品的过程如下 flowchart LR feature_dev --合入--\u003e feature feature --合入--\u003e master master --合入--\u003e release release --CI/CD--\u003e发布 buffix --合入--\u003emaster 使用这样一个流程，原因如下 app是一个2C的产品，只维护最新版本 大部分冲突在feature_dev合入feature时解决（一般冲突范围小，而且与同一个需求相关，容易解决），其次由feature合入master分支时解决 线上出现问题时，修复代码可以通过bugfix分支快速进入产品中 合入的过程无法在本地完成，必须在git平台完成，合入需要对应分支的负责人完成codereview并批准 此外，feature_dev合入feature时，由对应的开发者完成本地自测，feature合入master时，由CI/CD系统构建出测试用的app，并交由测试同学完成测试。所有feature分支合入master分支后，需要运行一个完整的全面的测试，视bug数量和影响程度决定是否进入后续的发布流程 ","date":"2024-07-14","objectID":"/posts/week5/:5:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#git-workflow"},{"categories":null,"content":" 常见概念 nightly build 常见于大公司的大型开源项目中，大公司有许多开发者负责项目的开发，每天推送代码后，开发者下班回家，此时基本不会发生推送，CI/CD系统开始运行，从当天最新代码中构建出最新的软件包，得名于一般在每天晚上构建 nightly build因为频繁更新，稳定性欠佳，但因为具有最新的特性，某些情况下可以使用nightly build的软件包以快速得到修复或体验新特性 灰度 新版本的软件包在部分用户完成灰度测试，收集日志和灰度用户的反馈，判断软件包的质量，以决定是否全量发布。如果将产品上线认为是黑，未上线是白，那么仅推送给部分用户就是灰度 灰度用户的比例往往较小，而且灰度用户无感知，因为灰度软件包往往是静默完成的更新 构建号 因为CI/CD重复、频繁的构建，需要一种id来确定软件包来源于哪次构建 CI/CD系统往往需要填写一些secrets，例如访问token，数据库密码等，使用不同的secrets，就能将软件包部署到不同的环境。此外还能填写国家代号、区域代号，实现一份代码构建出不同的软件包给不同国家或区域的用户使用。 因为不同国家的法律要求不同，软件包往往会在某些国家屏蔽部分功能以合规。以app为例，有专门的法务部研究市场所在国家的法律，并将消息同步给开发部门。法务部门不仅仅需要研究哪些功能是不合规的，还需要判断哪些行为具有合规风险 以上原因导致无法通过构建基于的提交的hash来唯一确定软件包来源于哪次构建，所以使用构建号来区分 以windows系统为例，系统版本号中就带有构建号 Version Servicing option Availability date Latest revision date Latest build 22H2 General Availability Channel 2022-10-18 2024-07-09 19045.4651 21H2 General Availability Channel 2021-11-16 2024-07-09 19044.4651 未完待续。。。 ","date":"2024-07-14","objectID":"/posts/week5/:6:0","series":null,"tags":null,"title":"第五周：CI/CD、git workflow与软件发行","uri":"/posts/week5/#常见概念"},{"categories":null,"content":" About meUSTB 的计算机专业大四学生，即将进入互联网公司的准社畜 我的portfolio: z2z63.dev ","date":"2024-07-12","objectID":"/about/:1:0","series":null,"tags":null,"title":"About","uri":"/about/#about-me"},{"categories":null,"content":" 技能对什么感兴趣就会学一下，许多技术都了解但了解不多 linux 平台的 C/C++开发 主要的努力方向 前端 HTML CSS(TailwindCSS) JS(vue react next.js) 配合 vercel 和 cloudflare 能快速做一个好玩的小玩意 java python rust go dart(flutter) … 主要用生态强势框架 技术方向比较靠近 OS，DB 之类比较 low level 的东西，虽然本科生也没啥机会做这些东西，笑 ","date":"2024-07-12","objectID":"/about/:2:0","series":null,"tags":null,"title":"About","uri":"/about/#技能"},{"categories":null,"content":" 业余看各种书(不是小说)，技术的非技术的、推 galgame (同好务必加我) ","date":"2024-07-12","objectID":"/about/:3:0","series":null,"tags":null,"title":"About","uri":"/about/#业余"},{"categories":null,"content":" 写在前面博客新增了许多功能，包括作者资料，友链，样式优化，社交链接等等，其中Steam社交链接格式不正确，我给博客主题的作者提了一个 pull request，这是我的第一个pr，只修改了一个单词，很幸运地被merge了， 如果你也在使用DoIt主题，那么说不定其中某行代码就是我写的😋 博客也增加了RSS功能，欢迎订阅！ 最近回家后琐事明显增多了，基本没什么产出，就来拷打一下之前遇到的一些东西吧 ","date":"2024-07-01","objectID":"/posts/week3/:1:0","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#写在前面"},{"categories":null,"content":" 小程序大概一个月前帮一位同学做了一个很简单的小程序，只有一个按钮，这其中我遇到了小程序的不少槽点 先简单介绍一下小程序是什么，小程序和web页面很像，但小程序的JS执行线程和渲染线程是分开的，这是最大的区别，也造成了很多麻烦的东西 小程序的逻辑层和渲染层是分开的，逻辑层运行在 JSCore 中，并没有一个完整浏览器对象，因而缺少相关的DOM API和BOM API。这一区别导致了前端开发非常熟悉的一些库，例如 jQuery、 Zepto 等，在小程序中是无法运行的' 官方称将JS线程和渲染线程分开的目地是为了提高页面渲染性能，避免性能不足的移动设备出现卡钝、动画生硬等问题 以下是我的批评 ","date":"2024-07-01","objectID":"/posts/week3/:2:0","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#小程序"},{"categories":null,"content":" 没有完整DOM自绝于npm庞大的生态，而且造成了不必要的麻烦 ","date":"2024-07-01","objectID":"/posts/week3/:2:1","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#没有完整dom"},{"categories":null,"content":" 运行环境环境割裂宣传口径中，小程序的一个优点是不需要让用户安装app，android和ios用户都能使用。然而小程序的运行环境非常割裂 运行环境 逻辑层 渲染层 iOS,iPadOS, MacOS JavaScriptCore WKWebView 安卓 V8 基于 Mobile Chromium 内核的微信自研 XWeb 引擎 windows Chromium 内核 Chromium 内核 小程序开发者工具 NWJS Chrome WebView 可以看到以上平台基本把各种环境来了一个排列组合，然而开发者不一定有这么多设备可以测试。即使有足够多的设备，小程序写好后还需要在不同平台测试，检查平台差异，徒增工作量 WXSS 渲染表现不一致：尽管可以通过开启样式补全来规避大部分的问题，还是建议开发者需要在各端分别检查小程序的真实表现。 ","date":"2024-07-01","objectID":"/posts/week3/:2:2","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#运行环境环境割裂"},{"categories":null,"content":" DOM API混乱以上已经提及DOM不完整，此外因为JS环境割裂，导致不同平台的DOM API不仅仅是不完整的，而且每个平台的DOM API支持情况也不相同 这导致了开发者不确定某个DOM API在其他平台是否可用，最后干脆都不使用了(小程序到底可以使用哪些DOM API，官方并没有文档说明) 最坑的情况是，在小程序开发者工具中可用，但在真机不可用（因为小程序开发者工具的JS环境跟真机也不相同） 以上似乎还是比较合理的，但实际使用下来就会发现小程序非常坑的一点 我开发的小程序是对接阿里云的某个API，涉及加密，URL参数处理等。加密直接从网上找了一个函数实现，剩下的字符串处理被小程序坑了两次 atob，btoaatob和btoa这两个函数是DOM API提供的将base64和二进制数据相互转换的配套函数 我使用的场合很简单，只需要将一个普通的字符串使用base64编码即可，这种情况下应该使用atob 小程序并没有atob，但讽刺的是它有btoa。发现这一事实后我相当的愤怒，因为atob和btoa 只是简单的字符串处理函数而已，小程序的JS环境对这两个配套的函数，居然能作出只支持其中一个的行为。此外， 即使JS环境就是这么随意，小程序官方也完全可以提供一个JS实现的btoa，并在小程序执行前动态绑定到DOM上，避免给开发者造成 不必要的麻烦 有人可能会说，既然btoa只是一个简单的字符串处理函数，为什么开发者不能自己造一个轮子呢？ 因为base64编码是一种标准，涉及诸多细节，例如查码表，位数补齐等等，所以实现一个符合标准的btoa是一个简单但琐碎的工作，这种工作一般是由标准库完成，而不是由开发者完成 URLSearchParamsURLSearchParams表示url的查询参数，我使用这个函数将参数组装成查询字符串，简单来说，有一些参数 JS const params = { a: 1, b: \"aaa\" } 组装成a=1\u0026b=aaa的格式，看起来很简单，但查询字符串需要符合URL标准，即只能使用URL安全的字符，也就是某些URL不安全的字符需要转义，所以这也是一个简单但琐碎的工作 毫不意外地，小程序没有提供这个API，于是我在确认查询参数中不存在URL不安全字符后，造了一个非常简陋的轮子 甚至我找到一篇问答抱怨URLSearchParams的支持情况，其中的部分回答 都快2024了还不支持……………….. 懂不懂就说背锅，这么基础的东西都不支持 以上原因，导致一个非常简单的需求，我都花了几小时实现，开发体验极差。简单的字符串处理函数都不支持，我开发后的感想就是，小程序官方无作为。。。 ","date":"2024-07-01","objectID":"/posts/week3/:2:3","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#dom-api混乱"},{"categories":null,"content":" DOM API混乱以上已经提及DOM不完整，此外因为JS环境割裂，导致不同平台的DOM API不仅仅是不完整的，而且每个平台的DOM API支持情况也不相同 这导致了开发者不确定某个DOM API在其他平台是否可用，最后干脆都不使用了(小程序到底可以使用哪些DOM API，官方并没有文档说明) 最坑的情况是，在小程序开发者工具中可用，但在真机不可用（因为小程序开发者工具的JS环境跟真机也不相同） 以上似乎还是比较合理的，但实际使用下来就会发现小程序非常坑的一点 我开发的小程序是对接阿里云的某个API，涉及加密，URL参数处理等。加密直接从网上找了一个函数实现，剩下的字符串处理被小程序坑了两次 atob，btoaatob和btoa这两个函数是DOM API提供的将base64和二进制数据相互转换的配套函数 我使用的场合很简单，只需要将一个普通的字符串使用base64编码即可，这种情况下应该使用atob 小程序并没有atob，但讽刺的是它有btoa。发现这一事实后我相当的愤怒，因为atob和btoa 只是简单的字符串处理函数而已，小程序的JS环境对这两个配套的函数，居然能作出只支持其中一个的行为。此外， 即使JS环境就是这么随意，小程序官方也完全可以提供一个JS实现的btoa，并在小程序执行前动态绑定到DOM上，避免给开发者造成 不必要的麻烦 有人可能会说，既然btoa只是一个简单的字符串处理函数，为什么开发者不能自己造一个轮子呢？ 因为base64编码是一种标准，涉及诸多细节，例如查码表，位数补齐等等，所以实现一个符合标准的btoa是一个简单但琐碎的工作，这种工作一般是由标准库完成，而不是由开发者完成 URLSearchParamsURLSearchParams表示url的查询参数，我使用这个函数将参数组装成查询字符串，简单来说，有一些参数 JS const params = { a: 1, b: \"aaa\" } 组装成a=1\u0026b=aaa的格式，看起来很简单，但查询字符串需要符合URL标准，即只能使用URL安全的字符，也就是某些URL不安全的字符需要转义，所以这也是一个简单但琐碎的工作 毫不意外地，小程序没有提供这个API，于是我在确认查询参数中不存在URL不安全字符后，造了一个非常简陋的轮子 甚至我找到一篇问答抱怨URLSearchParams的支持情况，其中的部分回答 都快2024了还不支持……………….. 懂不懂就说背锅，这么基础的东西都不支持 以上原因，导致一个非常简单的需求，我都花了几小时实现，开发体验极差。简单的字符串处理函数都不支持，我开发后的感想就是，小程序官方无作为。。。 ","date":"2024-07-01","objectID":"/posts/week3/:2:3","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#atobbtoa"},{"categories":null,"content":" DOM API混乱以上已经提及DOM不完整，此外因为JS环境割裂，导致不同平台的DOM API不仅仅是不完整的，而且每个平台的DOM API支持情况也不相同 这导致了开发者不确定某个DOM API在其他平台是否可用，最后干脆都不使用了(小程序到底可以使用哪些DOM API，官方并没有文档说明) 最坑的情况是，在小程序开发者工具中可用，但在真机不可用（因为小程序开发者工具的JS环境跟真机也不相同） 以上似乎还是比较合理的，但实际使用下来就会发现小程序非常坑的一点 我开发的小程序是对接阿里云的某个API，涉及加密，URL参数处理等。加密直接从网上找了一个函数实现，剩下的字符串处理被小程序坑了两次 atob，btoaatob和btoa这两个函数是DOM API提供的将base64和二进制数据相互转换的配套函数 我使用的场合很简单，只需要将一个普通的字符串使用base64编码即可，这种情况下应该使用atob 小程序并没有atob，但讽刺的是它有btoa。发现这一事实后我相当的愤怒，因为atob和btoa 只是简单的字符串处理函数而已，小程序的JS环境对这两个配套的函数，居然能作出只支持其中一个的行为。此外， 即使JS环境就是这么随意，小程序官方也完全可以提供一个JS实现的btoa，并在小程序执行前动态绑定到DOM上，避免给开发者造成 不必要的麻烦 有人可能会说，既然btoa只是一个简单的字符串处理函数，为什么开发者不能自己造一个轮子呢？ 因为base64编码是一种标准，涉及诸多细节，例如查码表，位数补齐等等，所以实现一个符合标准的btoa是一个简单但琐碎的工作，这种工作一般是由标准库完成，而不是由开发者完成 URLSearchParamsURLSearchParams表示url的查询参数，我使用这个函数将参数组装成查询字符串，简单来说，有一些参数 JS const params = { a: 1, b: \"aaa\" } 组装成a=1\u0026b=aaa的格式，看起来很简单，但查询字符串需要符合URL标准，即只能使用URL安全的字符，也就是某些URL不安全的字符需要转义，所以这也是一个简单但琐碎的工作 毫不意外地，小程序没有提供这个API，于是我在确认查询参数中不存在URL不安全字符后，造了一个非常简陋的轮子 甚至我找到一篇问答抱怨URLSearchParams的支持情况，其中的部分回答 都快2024了还不支持……………….. 懂不懂就说背锅，这么基础的东西都不支持 以上原因，导致一个非常简单的需求，我都花了几小时实现，开发体验极差。简单的字符串处理函数都不支持，我开发后的感想就是，小程序官方无作为。。。 ","date":"2024-07-01","objectID":"/posts/week3/:2:3","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#urlsearchparams"},{"categories":null,"content":" 质疑我对小程序的质疑如下 如果它真的是一个先进的技术，为什么我至今没看到国外有使用？ 很多APP都有小程序，他们提供的平台能力也不一样（例如微信小程序和支付宝小程序），为微信开发的小程序没法在支付宝使用 接上，为了解决小程序的“跨平台”问题（跨平台这个词真是讽刺），有uniapp这样解决方案，但uniapp本身就是一个不逊于小程序的大坑 小程序由一家商业公司维护，而web有W3C维护标准，一群巨头浏览器厂商竞争，我为什么要开发小程序而不开发web？ chrome没有将渲染和JS执行分成两个线程，但chrome在移动设备上的表现也不低于小程序，将渲染和JS执行分开是否有必要？ ","date":"2024-07-01","objectID":"/posts/week3/:2:4","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#质疑"},{"categories":null,"content":" webview前文拷打的小程序，我认为它出现的一个原因是android的webview非常割裂，新机型和老机型的webview版本相差太多，以至于微信选择了另一条与web标准并立的方式，让许多老机型也能 正常使用web 私以为，webview割裂的一个原因是，国内android无法使用google框架，所以也无法使用google play这个在安卓生态中占据统治地位的应用商店， 所以系统自带的webview只能依靠国产安卓vendor提供更新 然而很多老机型，国产android厂商很久，或者根本不推送更新了，也就导致老机型的webview永远停留在了一个很旧的版本，这样的机型早已被日新月异的Web标准抛弃 此外，国内很多移动互联网用户并没有经历桌面互联网时代，而微信占据了国内移动互联网的绝大部分流量，自然有能力另起一套方案与占据了互联网大部分入口流量的google竞争， 可以顺理成章地得出，小程序只是微信为了圈住流量，将微信成为流量入口的一个工具而已。 ","date":"2024-07-01","objectID":"/posts/week3/:2:5","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#webview"},{"categories":null,"content":" polyfill前文提及小程序的DOM API不完整，实际上小程序对ECMA Script标准的支持也不完整，对于这种情况，可以使用一种被成为pollyfill的技术，即使用已有的东西去模拟出缺失的东西 微信小程序内置了core.js，但因为时间有限我并没有搞明白怎么使用。相反，我发现有一个开源项目polyfill.io，只需要引入它的一个JS文件，它的服务器会自动根据UA判断出缺失的功能， 并只发送能够polyfill这些缺失的功能的JS脚本 在这篇文章写下的几天前，polyfill.io被发现向千万个站点返回了恶意JS脚本，现在其仓库polyfillpolyfill/polyfill-service 已经被github封禁，polyfill.io也无法访问 这个现实非常可怕，因为我曾经也尝试过使用polyfill.io（虽然最终并没有使用），也让我产生另一个对小程序官方不作为的批评：小程序官方不提供足够的polyfill，导致开发者寻求第三方解决方案，但第三方不一定是安全的 实际上，以上提到的很多问题也许都能通过脚手架或框架避免，但我的观点仍然同polyfill，小程序不提供足够的能力，而将工作交给开发者，这造成了以下问题 个人开发者：花费精力寻找并对比合适的脚手架 企业：花费精力确认脚手架的安全性，稳定性 ","date":"2024-07-01","objectID":"/posts/week3/:2:6","series":null,"tags":null,"title":"第三周：来拷打一下小程序","uri":"/posts/week3/#polyfill"},{"categories":null,"content":" Friends Nelson Boss - 「🌊一直游到海水變藍」 214 - 「貳壹肆の博客」 Soulter - 「让我们一同在星空下」 ","date":"2024-07-01","objectID":"/links/:1:0","series":null,"tags":null,"title":"Links","uri":"/links/#friends"},{"categories":null,"content":" 欢迎交换友链 mailto: virtualfuture@gmail.com 下方gittalk评论 ","date":"2024-07-01","objectID":"/links/:1:1","series":null,"tags":null,"title":"Links","uri":"/links/#欢迎交换友链"},{"categories":null,"content":" 厉害的博客(单向链接) CatCoding - 「coding and writing, don’t panic」 Reorx’s Forge - 「Crafting tools and products to help people think and create.」 ","date":"2024-07-01","objectID":"/links/:2:0","series":null,"tags":null,"title":"Links","uri":"/links/#厉害的博客单向链接"},{"categories":null,"content":"新内容的博客主题并不明显，基本是最近学习到的知识，平日突然浮现在头脑中的随想，或者很久以前遇到过的一些事情 ","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#"},{"categories":null,"content":" 归并排序与败者树上篇文章提到的归并排序，经过两次重构已经很完善了，最终的结果是一个归并排序类ExternalMergeSorter，通过一个头文件引入external_merge_sort.h, 非常优雅地隔离了归并排序的细节，只需要给sorter提供记录，然后指示sorter开始排序，最后依次从sorter中取出记录，取出的记录已经是有序的了 ","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#归并排序与败者树"},{"categories":null,"content":" IO关于IO的方式也考虑了很多，mmap，read， fread，std::fstrean都能实现需要的功能，最终选择了std::fstream mmap 效率很高，读入文件时，相比read少了一次内核数据复制 read时： 外存中的文件 –\u003e 内核维护的缓冲区 –\u003e 进程维护的缓冲区 mmap时： 外存中的文件 –\u003e 内核分配给进程的页 mmap分配的页是惰性分配的，mmap调用返回时，分配的页仍然是用户地址空间非法的页，进程第一次访问时，陷入内核态（因为访问了非法的页），然后内核完成页的分配，并填入正确的数据 此外，mmap分配的页也会正常的换出换入内存，实际内存使用量不会很高 Q：为什么read读取文件时有内核维护的缓冲区和进程维护的缓冲区？ A: 内核维护的缓冲区是对进程隐藏的，进程无法访问（在进程的地址空间中不存在），这是为了防止恶意进程破坏操作系统 部署数据库的服务器可能会关闭内存交换功能，此时操作系统不会将近期不使用的页换出内存 不过缺点也很明显，需要手动维护读写指针，而且如果设置了每次mmap的页（不是操作系统的页）的大小，还需要再实现大文件分页，包括不满一页，刚好满一页，满n页不满n+1页各种corner case，并需要给corner case写测试，非常繁琐 read read和mmap都是linux的系统调用，使用read时操作系统会帮我们维护读写指针，但仍然需要自己处理分页 fread libc提供的IO函数，内部会自动维护缓冲，读写指针，如果设置了缓冲区大小，也相当于有了分页的功能 std::fstream libc++的IO函数，fread已经能满足要求了，但使用std::fstream是一种\"when in cpp do as the cpper do\"的做法 ","date":"2024-06-25","objectID":"/posts/week2/:1:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#io"},{"categories":null,"content":" k路归并排序归并排序处理大规模数据时，会形成多个文件，假设为k个，最终将k个已排序块合并的过程，就是k路归并排序 k路归并时，每次取出k个已排序块中最小的记录，如何确定哪个记录是最小的，可以简单的遍历k个记录，找出其中最小的一个，也可以使用胜者树、败者树加快归并的过程 遍历k个记录，可以被称为暴力查找，时间复杂度是$$O(k)$$ 而胜者树、败者树的时间复杂度为$$O(\\log k)$$ k值一般不会很大，经典值有8，16。虽然k很小，但因为取出每条记录都需要经过归并，此处的算法优化效果是非常可观的，我测试的情况是64M规模排序，使用暴力查找耗时5min，使用败者树耗时大约5s ","date":"2024-06-25","objectID":"/posts/week2/:2:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#k路归并排序"},{"categories":null,"content":" 胜者树胜者树的思想是，假设有八个选手A，B，C，D，E，F，G，H参与比赛，他们两两配对并参与比赛，比赛的胜者参与下一轮比赛，只需要三轮比赛就能比出冠军 text 第三轮比赛的胜者 A 第二轮比赛的胜者 A H 第一轮比赛的胜者 A D E H 参赛选手 A B C D E F G H 八个选手中A胜出，胜者树记录了A通过比赛不断“上升”的过程 现在假设因为某种原因，原来的冠军A被替换成A1，而A1的排名未知，需要重新确定冠军 A1与B比赛，如果A1胜，则A1作为胜者进入下一轮比赛，如果B胜，则B作为胜者进入下一轮 设A与B比赛的胜者为X1(X1 = A1 | B)， X1与D比赛， 产生的胜者X2进入下一轮 X2与H比赛，产生的胜者即为冠军 胜者树的算法思想是动态规划，八个选手比赛的过程中，有很多重复的子问题，例如，A的排名需要重新确定时，C和D的胜负关系是不会改变的，所以C和D没必要再比赛，同理E和H也没必要再比赛，胜者树这样的数据结构在归并过程中维护了最优子结构，避免了重复完成子问题 ","date":"2024-06-25","objectID":"/posts/week2/:3:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#胜者树"},{"categories":null,"content":" 败者树将胜者树中的节点的值换成这轮比赛中的败者，其他不变，就形成了败者树 败者树的一个缺点就是不直观，因为节点记录了败者，但参赛的仍然是胜者，事实上，在构建败者树的过程中仍然需要构建胜者树。 败者树相比胜者树的优点是，重新确定冠军时，当前参赛选手需要和上次当轮比赛的败者比赛（例如第一轮比赛中，X1需要和D比赛），胜者树需要从兄弟节点获取败者，而败者树可以直接从父节点获取败者 败者树的另一个理解是，败者树的节点中存储的是左右子树两胜者中比赛产生的次胜者，而优胜者进入下一轮比赛。例如败者树中存储了D的节点，D来源于第一轮比赛中A和D比赛，其中A是优胜者，D是次胜者 text 冠军 A 第三轮比赛的败者 H 第二轮比赛的败者 D E 第一轮比赛的败者 B C F G 参赛选手 A B C D E F G H 此外败者树的根节点记录的是败者，所以还需要额外记录一个冠军 ","date":"2024-06-25","objectID":"/posts/week2/:4:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#败者树"},{"categories":null,"content":" 实现我使用堆模拟了败者树，败者树也是一种二叉树，堆模拟二叉树的优点如下 内存碎片小 节点在内存中是紧邻的，能充分利用高速缓存的性能，cache友好 此外，堆模拟的二叉树中访问父节点，兄弟节点也非常简单，可以使用位运算 假设堆的大小为16，第一个元素不使用，模拟的二叉树如下 text 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 其中的数组表示节点的编号，或节点在堆中的索引 假设当前节点为x，其父节点为x \u003e\u003e 1，兄弟节点为 x ^ 1，左子节点为x \u003c\u003c 1，右子节点为(x \u003c\u003c 1) + 1 其中第一个未使用的元素在败者树中刚好用来存储冠军，非常巧妙 堆模拟败者树有两个坑点： 分清节点编号和选手编号（在这篇文章中我特意使用字母ABC表示选手编号，而使用数字123表示节点编号，但实现时，使用的都是数字类型） 堆模拟的败者树消除了败者树的优势：直接从父节点获取败者，因为堆访问兄弟节点非常方便，而且没有额外的空间开销。此外败者树非常不直观，如果使用堆模拟，可以考虑胜者树 ","date":"2024-06-25","objectID":"/posts/week2/:5:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#实现"},{"categories":null,"content":" corner case外部归并排序中产生多少个辅助排序文件，一般是不可控制的，选手数量往往不是2的幂 此时增加若干个哑节点(dumb node)，使选手数量达到2的幂，哑节点参与比赛一定败北 最终实现见external_merge_sort.h，在木兰宽松许可证下开源 ","date":"2024-06-25","objectID":"/posts/week2/:5:1","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#corner-case"},{"categories":null,"content":" exit在对比fread，fwrite和std::fstream时，看到有篇回答提及，如果程序异常退出，std::fstream可能来不及把缓冲区的内容落盘 cpp #include \u003cstdlib.h\u003e #include \u003cfstream\u003e using std::ofstream; int main() { ofstream ofs(\"hello.txt\"); ofs \u003c\u003c \"Hello world\\n\"; exit(0); } 这里又涉及一个问题，std::fstream需要手动关闭吗？ ","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#exit"},{"categories":null,"content":" fstream自动关闭答案是可以不手动关闭，因为fstream会在析构时自动关闭。见cppreference对basic_fstream的析构函数的说明 destructs the basic_fstream and the associated buffer, closes the file 然后来翻源码证实一下 首先看一下cppreference对fstream，ifstream，ofstream的说明 basic_istream最终实例化为ifstream，basic_ostream最终实例化为ofstream，basic_iostream最终实例化为fstream，所以fstream相当于ifstream和ofstream的父类 以ofstream举例，它的析构函数在glibc的头文件fstream中 cpp /** * @brief The destructor does nothing. * * The file is closed by the filebuf object, not the formatting * stream. */ ~basic_ofstream() { } 看来关闭文件的工作是交给filebuf完成的，此处的filebuf指的是basic_ofstream的成员变量_M_filebuf 实现如下 cpp /** * @brief The destructor closes the file first. */ virtual ~basic_filebuf() { __try { this-\u003eclose(); } __catch(...) { } } 那么自动关闭和手动关闭的区别在哪里呢？ ofstream的close方法实现如下 cpp /** * @brief Close the file. * * Calls @c std::basic_filebuf::close(). If that function * fails, @c failbit is set in the stream's error state. */ void close() { if (!_M_filebuf.close()) this-\u003esetstate(ios_base::failbit); } 它也是调用了filebuf的close方法，除了错误处理有所不同，其他完全一样 初学时总被反复提醒ofstream打开了一定要关闭，但实践不一定需要完全遵循，举几个例子 一个很短的函数内打开ofstream，可以不关闭，函数退出时自动关闭 一个很长的函数内打开ofstream，为了尽快释放资源可以手动关闭，也可以利用对象离开作用域立刻销毁的特性，额外创建一个作用域，让ofstream提前销毁，这也是更符合C++的RAII的做法 cpp { std::ofstream file(\"output.txt\"); // 写入文件 } // 此处已经关闭 这个特性在其他语言中很少出现，因为C++无GC，对象销毁时机是完全确定的，而GC语言即使提供了析构函数，因为无法确定对象销毁时机，实现某些对销毁时机非常敏感的特性（例如RAII的锁）时，会出现很多无法预料的情况 libc在进程退出和exit时会自动将所有FILE缓冲区残留的数据落盘，并释放缓冲区 linux在进程exit系统调用时会自动关闭进程未关闭的文件，并释放进程的内存 ","date":"2024-06-25","objectID":"/posts/week2/:1:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#fstream自动关闭"},{"categories":null,"content":" 无法自动关闭的特殊情况fstream的关闭依赖于其析构函数的调用，只需要绕过析构函数即可，绕过方法其一就是exit函数 前文提及libc的exit函数会关闭所有打开的FILE，关闭的过程包括缓冲区残留的数据落盘和释放缓冲区，但exit函数不会关闭ofstream，因为ofstream自己维护了一个缓冲区，而没有使用FILE对象的缓冲区 首先确定一点，ofstream会自动分配缓冲区，也可以由用户手动设置缓冲区 ofstream的open方法实现如下 cpp template\u003ctypename _CharT, typename _Traits\u003e typename basic_filebuf\u003c_CharT, _Traits\u003e::__filebuf_type* basic_filebuf\u003c_CharT, _Traits\u003e:: open(const char* __s, ios_base::openmode __mode) { __filebuf_type *__ret = 0; if (!this-\u003eis_open()) { _M_file.open(__s, __mode); if (this-\u003eis_open()) { _M_allocate_internal_buffer(); // 省略... } } return __ret; } _M_allocate_internal_buffer函数完成了缓冲区的自动分配，实现如下 cpp template\u003ctypename _CharT, typename _Traits\u003e void basic_filebuf\u003c_CharT, _Traits\u003e:: _M_allocate_internal_buffer() { // Allocate internal buffer only if one doesn't already exist // (either allocated or provided by the user via setbuf). if (!_M_buf_allocated \u0026\u0026 !_M_buf) { _M_buf = new char_type[_M_buf_size]; _M_buf_allocated = true; } } 使用默认内存分配器申请了一块内存用于缓冲区，可以看到并没有把这块内存交给FILE管理 libc和libc++的实现都会随着版本迭代而变化，具体实现一般都对用户隐藏，而只暴露必要的接口，libc和libc++需要保持彼此独立所以也不能使用对方的非公开API 至此已经能回答之前的问题，为什么fstream在调用exit后数据没有落盘？因为数据残留在fstream内部维护的缓冲区中，没有同步到外存，而exit不负责为fstream清理残局 ","date":"2024-06-25","objectID":"/posts/week2/:2:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#无法自动关闭的特殊情况"},{"categories":null,"content":" 范式与反范式","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#范式与反范式"},{"categories":null,"content":" 分层纵观整个计算机体系，分层的思想从底层到上层都在不断的使用。有句名言：计算机中的一切问题都能使用分层解决 分层解决实际问题的例子 计算机网络仅仅使用五层就实现了世界上规模最大最复杂的网络 通过增加域名这一层，使得32bit的ip拥有了树状结构，符合人类社会的组织规律（国家区域顶级域名，用途特定域名gov,edu等），使得负载均衡，代理等灵活的技术成为可能 分层的工作是，使用当前层提供的原语，屏蔽当前层的细节，向上层提供更简单更强大的原语 以上是教科书内容，分层思想很伟大，但在实践中有时会违背分层的思想。分层是范式，所以理所当然有其反范式，例如NAT NAT实现了网络地址的转换，它维护一个外网端口号：内网端口号+内网ip的映射，有关NAT的批评其一就是它违反了计算机网络中分层的思想，因为NAT工作在网络层，而它会修改端口号，而端口号属于传输层。即NAT修改了上层报文内容 这体现了分层往往存在的问题：分层尝试屏蔽底层细节，但无法完全屏蔽。所以计算机科学从业者就需要对整个计算机体系的每一层具有足够的了解，才能解决复杂的问题。例子 即使使用C写操作系统，也不得不写汇编指令，因为C没有提供在C层面调用某些汇编指令的能力 跨平台尝试抹平平台差异，但也会限制平台原生能力的使用，所以跨平台往往还需要写平台原生插件 linux的VFS向上层提供了一致的文件模型，屏蔽了底层资源、文件系统、硬件等差异，但数据库开发中还是需要考虑计算机的存储设备的硬件情况，例如磁盘读写时间包括了寻道时间，旋转延迟， 传输时间。而其中寻道时间和旋转延迟占了大部分时间，所以数据库会在内存中分块缓存修改后的文件内容，积累一段时间后再写回。数据库使用的IO策略立足于存储设备硬件现实 此外，分层也无法解决全部的问题，分层体系中，往往能找出一些上层重复实现底层功能的例子 例如 操作系统提供了IO缓冲，而libc还要在实现一遍 操作系统提供了LRU的页置换策略，而数据库还需要再实现一遍。数据库有时候甚至需要绕过操作系统这一层(前文提及“部署数据库的服务器可能会关闭内存交换功能”) libc提供了内置的内存分配器，而postgresql也实现了自己的内存分配器 libc提供了许多标准库中的函数，例如字符串处理函数，memcpy等，这些在postgresql中也有重复实现 对这一现实，我的理解如下 操作系统访问外存速度很慢，所以操作系统尝试缓冲IO，但进程进行系统调用的过程也很慢，所以libc提供IO缓冲，减少系统调用的次数，提高性能 libc的内存分配器和memcpy，考虑的是通用场景，而特定场景下的性能可能不如数据库的实现。例如内存分配器的一个功能是尽可能减少内存碎片，而每次需要分配的内存有多大是由用户随意决定的。如果数据库完全掌握内存使用情况，就能使用针对数据库场景优化的内存分配器，减少内存碎片 LRU置换策略，理由同上。数据库能针对各种算子专门优化，而操作系统无法知道进程何时需要访问页面，只能基于局部性原理进行假设 libc提供的字符串处理函数安全性不够，实际上很多大型项目都会重新造一遍字符串处理函数，为了解决诸如缓冲区溢出，零结尾等问题 ","date":"2024-06-25","objectID":"/posts/week2/:1:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#分层"},{"categories":null,"content":" 关系型数据库六范式关系型数据库的六范式的作用是减小数据冗余，消除插入异常，删除异常等，但在实践中，往往不会完全遵循六范式，因为划分实体和关联的工作非常复杂，只有领域专家才有可能做到。一般往往只遵循到第三范式 此外，关系型数据库的范式会使越拆越小，在查询时需要做大量的连接操作，连接操作可以使用索引，使用归并连接，使用哈希等方式加快连接速度，但对时间复杂度的减小效果有限，数据量极大时仍然非常耗时。大数据和NoSQL就完全违反了关系型数据库的范式，但换来了非常快的查询速度 ","date":"2024-06-25","objectID":"/posts/week2/:2:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#关系型数据库六范式"},{"categories":null,"content":" 唯一事实原则如果一个人有很多钟，反而无法确定时间，因为不同钟显示的时间不一样。在工程实践中为了避免这种问题，往往遵循single source of truth，即唯一事实原则，例如 将一些参数提升为配置，其他要使用参数的地方只能引用参数，不能内联 JS的ORM框架prisma使用prisma.schema作为唯一事实，并使用这一事实同步数据库和生成的类型 然而唯一事实原则也有其反范式，而且使用非常广泛，即cache 此处cache指CPU提供的高速缓存，它和内存共同维护了一个数据的两个副本，非常明显的反范式，后果就是需要额外维护cache和内存的一致性 cache有脏数据，而内存中的数据是干净的：需要将脏数据写回，而且需要选择写回时机 内存中有脏数据，而cache中的数据是干净的，需要同步到cache 此外cache的存在对DMA非常不友好，让DMA变得更加复杂了，因为DMA能在不经过CPU的情况下读写内存 ","date":"2024-06-25","objectID":"/posts/week2/:3:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#唯一事实原则"},{"categories":null,"content":" buffer vs cache最近突发奇想，使用另一个角度理解缓冲与缓存 首先，我认为缓存的译名不准确，因为缓存的“缓”，在字典中是“慢”的意思，而缓存明显是用来加快速度用的，参考cache的台湾译名“快取” 有两个系统A和B，它们通过接口相连，然而A和B的速度是不匹配的（A速度远大于B）。基于以上事实，才有必要使用buffer或cache，这也是现实中非常常见的情况 两个速度不匹配的系统为了能够一起工作，必定还有其他条件，否则认为这两个系统不应该相互连接 如果两个系统不应该连接，此时有两种方案改进 使用性能更好的B1， 提高系统整体性能 使用性能低但更便宜的A1，降低系统的造价 ","date":"2024-06-25","objectID":"/posts/week2/:0:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#buffer-vs-cache"},{"categories":null,"content":" 附加条件：A猝发生产而B持续消费此时使用buffer，即缓冲 网络流量往往是猝发的，而操作系统或用户程序无法保证立马响应，所以网卡往往有缓冲区 用户读写文件的操作往往是猝发的（例如一个文本编辑器，用户随时按下按键输入字符），libc维护缓冲区，延迟写入外存，提高IO性能 操作系统为外设IO提供缓冲，因为外设产生数据是猝发的 在加入少量的酸或碱时，溶液的PH值发生突变（扩散作用很快），而缓冲液可以在这个情况下减小溶液PH值变化速度和范围（化学反应速度比扩散作用慢）。缓冲剂往往远多于酸或碱的量（使用滴管加入的）。如果酸或碱的量太多，缓冲液的效果就不好 ","date":"2024-06-25","objectID":"/posts/week2/:1:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#附加条件a猝发生产而b持续消费"},{"categories":null,"content":" 附件条件：A反复消费相同数据此时使用cache，即快取 许多包管理器都有cache的功能，因为用户往往重复下载相同的软件包 CPU有cache，因为程序往往在一段时间内重复访问一块区域的内存，具有时间局部性和空间局部性 浏览器会缓存部分文件，因为用户每次访问页面，都需要下载相同内容的文件 为了加快访问速度，网站可以把静态资源放到CDN ","date":"2024-06-25","objectID":"/posts/week2/:2:0","series":null,"tags":null,"title":"第二周：败者树、范式与反范式","uri":"/posts/week2/#附件条件a反复消费相同数据"},{"categories":null,"content":"最近关于博客的内容考虑了很多，怎样让博客的内容更有价值、怎样输出内容等等。也考虑了未来如果内容做好了，可以开始做SEO等等。因为我认为博客还是一种比较轻松的阅读内容，如果选择输出干货，一来读者不一定了解这方面的知识，二来读者如果非常了解这方面的知识，这篇文章也没有价值；如果想加深对某领域的了解，完全可以看一些经典的书籍，他们的内容比博客好多了，于是我决定改变博客的内容。希望我的博客是启发性的，读者看完后能够对某个小领域有个大致的理解，或者看完后产生兴趣，去阅读更专业的书籍、文档等等。换而言之以后的文章相比深度更倾向广度，比起话题更像随谈。另外我能力也不足以输出深度足够的文章。 ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#"},{"categories":null,"content":" 外部归并排序最近打数据库比赛，我负责的一道题是归并连接 需要使用归并排序算法，准确的说是external merge sort，即在内存有限的情况下，利用外存辅助排序，其核心思想是一种经典的算法：分治法（分而治之，divide-and-conquer） 假设内存只能使用1G（大致范围，不考虑细枝末节），而需要排序10G的记录，归并排序的步骤是 将10G内存分十次读取到内存，在内存中完成1G记录的排序（可以使用常见的排序算法，例如快速排序），排序结果写入总共10个文件 将10个文件分别读取一块到内存（假设读取100M，总共使用1000M，没有超过1G限制） 从每块的第一个记录中选择最小的一个，取出，输出（每块中最小的记录肯定是第一个，因为块内已经排好序了） 重复3，如果某块使用完，就从对应文件读取下一块 10个文件的内容全部使用完毕，完成排序 算法不难理解，然而实现起来就会遇到各种各样的问题， 如果有10.1G的记录，按照上述办法，就会有一个0.1G的文件 如果一块大小是80M，该文件的最后一块就是64M 如果记录只有900M，算法也应该能正常处理，而且最好不使用外存（但在数据库场合下，前一个算子执行时输出多少记录是不可能预先知道的，例如select算子，可以携带where语句的条件，实际输出的记录数量只能确定范围而无法具体知道其数量） 文件应该保存在哪里（放在tmpfs就不满足要求了，因为tmpfs就是使用内存实现的） 文件IO怎么做（直接用read，write系统调用？使用带缓冲的libc？使用mmap？） 于是实现这样一个外部归并排序，从最开始的查找资料，理解算法，到选择实现路径，再到动手实现、抽象，重构，分离，加上各种错误处理，考虑各种corner case，已经非常复杂了 另外再考虑使用google test写测试，怎样才能写出一个好的测试，把问题都找出来（自己写测试找bug比写了一堆代码，提测时才发现问题快多了！） 再考虑借鉴一下现成的算法实现，有例如stxxl这样非常全面系统的大数据处理库，也有github上十几颗星星，一两个文件的实现，还有使用其他语言实现的，等等。怎样保证正确的同时控制复杂度，可以看出从理论到实践的差距非常大，实践的内容已经远超理论的内容了，而我理论的内容也只是了解了部分，只能说希望未来的我能轻松做到吧… ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#外部归并排序"},{"categories":null,"content":" object header所谓object header就是一个对象的头部，在许多高级语言中对象都有object header。从理论上也能推导出一定需要一个额外的区域保存一些信息，不一定叫做object header，也可以是object footer 面向对象的一个特点是多态，多态可以理解为子类对象能够完美的嵌入到需要父类的地方，而如何知道该调用父类方法还是子类方法，只能在运行时确定，所以OOP一定要把类型信息带入运行时，这也是OOP的一个overhead（开销） 然而cpp比较特殊，虽然它也是OOP语言，但cpp的大部分（？）对象都是没有object header的，可以做一个简单的实验验证一下 我的猜测是，cpp首先favour zero cost abstraction(青睐零开销抽象)，让每个对象仅仅因为OOP的需要就带上一个绝大多数场合下都不会使用的object header，是不可接受的 其次，cpp相比其他传统OOP语言，有很多不同的地方 cpp的对象和原始类型不存在鸿沟，反而是可以密切配合的，对象可以轻易取其地址，malloc和new的区别也仅仅是new相比malloc多做了类的构造函数，而传统OOP语言，对象和原始对象存在鸿沟，互操作时需要包装类，例如java需要使用繁琐的wrapper box，而JS会自动完成原始类型和对象的转换 cpp的对象和原始类型可以随意放在堆上或者栈上，而传统OOP则将对象放在堆上而原始类型放在栈上 cpp的多态必须使用指针，并且必须有虚拟类 结合以上原因，我猜测也许虚拟类的子类的对象会有类似object header的东西，否则从理论上推导，cpp就无法完成多态了 ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#object-header"},{"categories":null,"content":" runtime上文出现的两个运行时，分别使用了两个不同的含义。 含义一：程序的时态 程序的时态，可以包括开发时，编译时，链接时，装载时，运行时等等，这也是从字面意义上理解runtime 含义二：runtime system的缩写 runtime system提供了程序运行的环境。就算是汇编语言也需要相应的环境才能运行，C的运行时提供以下运行时支持 栈 在操作系统启动时就已经准备好了，因为操作系统主要是C编写的，也需要栈的环境 libc 包含C标准定义的函数，有与操作系统交互的函数，也有字符串处理函数 dynamic linker 动态链接器用于将多个目标文件中的代码段，数据段等链接起来，于是在运行时能够调用其他目标文件中的函数，linker完成了elf装载完成后bootstrap的过程，bootstrap先于__start函数的执行，而__start函数先于main函数的执行 多线程支持 例如线程私有变量，线程安全版本的函数，多线程环境下的exit 内存分配系统 C标准中提供的malloc系列函数，提供了内置的内存分配系统，用于管理堆区 IO缓冲 libc在操作系统IO操作原语基础上，提供了带缓冲的IO，例如fread,fwrite等等，并提供了三种缓冲选项（无缓冲，行缓冲，全缓冲），用于在大部分场合下，提高应用程序IO速度，并减小开发者心智负担 NOTE: 如果对以上内容感兴趣，参见《程序员的自我修养——链接、装载与库》 ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#runtime"},{"categories":null,"content":" exec的极限在给上文提及的external merge sort写测试的时候，我最开始使用了非常烂的参数，导致测试程序在一个目录下大量的创建了辅助排序用的文件，它们使用mkstemp创建，模板为aux_sort_fileXXXXXX，mkstemp会自动将末尾的X替换成随机的字母，并创建、打开该文件，这样就不必考虑为文件起一个不会重复的名字 为了删除这些文件，我最开始使用的命令是rm aux*，然而shell报错\"Too many arugments\" 然后我使用的命令是fd 'aux*' --exec rm {}，fd是find的加强版，这个命令相当于find . -name 'aux*' -exec rm {} \\; 那么\"Too many arugments\"是为什么呢？ Linux系统许多地方都是有限制的，例如hostname（主机名）长度不能超过某个值，路径长度不能超过某个值等等，这是因为动态长度的东西很难处理，内核实现中为了简单，往往会规定一个limit，并定义超过limit后的行为（一声不吭？报错？自动截断？） 决定\"Too many arugments\"的limit是ARG_MAX，即命令行的最长参数长度，因为rm aux*中的*是shell的wildcard（通配符）, shell将aux*替换成所有文件名开头为aux的文件，然后执行命令（内核不会特殊对待*，*是shell层面的feature），当文件特别多时（当时也许有几千或几万个文件），就有可能触发limit ARG_MAX起作用的范围是exec系统调用，libc提供的exec系列函数（包括execl,execlp,execle等等）只是exec系统调用的封装，ARG_MAX限制了exec能传入的参数的长度。而shell本质上只是exec系统调用的一个封装，自然也会受到ARG_MAX的限制（参考一些简易shell的实现，只涉及管道，fork，exec） linux是类unix系统，在unix发展历史上，因为过多vendor(厂商)分别开发和维护自己的unix系统，导致unix分裂，于是若干大头（IEEE，美国政府等）牵头指定了若干标准，有POSIX和Single Unix Specification，它们对以上提及的各种limit都有详细的定义，提倡unix系统提供的limit应该至少大于某个值，即标准规定的至少应该满足的值 此外，POSIX和Signle Unix Specification有若干版本，以及各自的扩展，例如XSI就是POSIX.1的扩展。unix是使用C开发的，C在历史上也有分裂的时期，于是人们也成立ISO/IEC制定了C的标准，这些标准是语言层面的，不会单独为Unix考虑，更多地考虑中立，但也影响了Unix，例如long应该有多长，INT最大值是多少等等 举一些例子说明ISO C, POSIX, Signle Unix Specification如何相互影响 ISO C定义了FILENAME_MAX，但随后POSIX定义了NAME_MAX和PATH_MAX作为FILENAME_MAX更好的替代 read系统调用原来的接口是 c int read(int fd, char* buf, unsigned nbytes); ISO C要求泛型数据应该使用void*，于是char* buf被改成了void* buf POSIX.1 引入了size_t表示数据的大小，于是unsigned bytes变成了size_t nbytes 此外POSIX.1还引入了ssize_t作为size_t的有符号版本，以支持负数，read的返回值类型也被改成ssize_t 最终的版本 c ssize_t read(int fd, void* buf, size_t nbytes); 为了使自己的程序能够在迁移到POSIX兼容机上，以上标准提供了一系列的机制以供开发POSIX兼容的程序 limit分为编译时limit，运行时limit，编译时limit是编译时常量，可以在编译时期通过引入诸如\u003climit.h\u003e获取，运行时limit可以由诸如配置文件，命令行，系统调用等方式动态的改变，需要在运行时动态获取 涉及的函数有sysconf, pathconf, fpathconf 不同系统对POSIX的支持程度不一样，POSIX提供一系列Feature test macros供开发者检测POSIX特性的支持，并对不同的支持情况作出反应（使用#ifdef条件编译），这种方法只能处理编译时limit ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#exec的极限"},{"categories":null,"content":" 标准与扩展Unix，C/C++，Web都是多家vendor，一个标准。vendor往往为了自己的利益，或者自己的需要，提供超过标准要求的功能，并推进这些功能加入标准 这一方面是因为标准往往为了中立而非常谨慎，甚至有时候可以说是不作为，导致标准提供的功能不足以覆盖部分需求，另一方面，编译器的vendor往往也是操作系统的vendor，例如Microsft的Windows和Visual c++，Apple的iOS,MacOS和clang，以及GNU与Linux。造操作系统是一个非常艰巨的任务，vendor往往也会造自己的编译器以满足开发操作系统的需求 举一个我打数据库比赛时遇到的情况，我希望对记录进行排序，记录为一块内存，大小在运行时获得，比较函数取出记录中的属性（基址+偏移，数据类型长度）然后比较属性大小，要使用哪个属性参与比较，也是运行时动态取得的 ，考虑cpp提供的std::sort，它的数据长度依赖于类型，而类型是编译常量，所以无法做到。考虑来自C的std::qsort，它的原型如下 c void qsort(void base, size_t nmemb, size_t size,int (*compar)(const void , const void )) 因为比较函数compar是函数指针，无法使用lambda函数捕获外部变量，也就是说每次sql执行时，compar函数行为都是一样的，这肯定不能满足需求，不能实现比较任意属性 我最终使用的是qsort_r c void qsort_r(void base, size_t nmemb, size_t size,int (*compar)(const void, const void , void *),void *arg); 这是glibc提供的C标准的GNU扩展，也就是说只有glibc才有，换而言之只能在linux使用（关于OS, libc以后有机会单独讲） 这个函数传入一个额外的void *arg，然后它将arg作为第三个参数传入compar，就能实现动态的比较属性 如何使用qsort_r？ 因为qsort_r是GNU扩展，man手册如是描述 Feature Test Macro Requirements for glibc (see feature_test_macros(7)): qsort_r(): _GNU_SOURCE 要使用qsort_r，首先要定义_GNU_SOURCE，然后引入声明了qsort_r的头文件\u003cstdlib.h\u003e 然后查看gcc预定义的宏 text ➜ bin git:(p6-merge-join) ✗ echo | g++ -dM -E -x c++ - | grep _GNU_SOURCE #define _GNU_SOURCE 1 可以看到我的gcc已经定义了，也就是默认启动了GNU扩展，所以直接引入\u003cstdlib.h\u003e即可，无需额外操作 然而其他版本的gcc也许没有预先定义，最优解法是在编译时通过命令行参数定义 以上例子可以看出标准往往是保守的，从Visual C++的各种_s版本函数可以也看出来这点 Visual C++的_s系列函数，例如scanf_s，strcpy_s,sprintf，是标准库对应函数的安全版本(security)，主要解决了buffer overflow问题，这些函数是visual c++的独占特性（或windows的独占特性），但是作为C标准的扩展进入了C标准，开发者可以在只引入标准库提供的头文件的情况下使用他们，在将别人的程序迁移至其他平台时造成了不少的麻烦！ NOTE: 如果对以上内容感兴趣，参见APUE(《Unix环境高级编程》) ","date":"2024-06-17","objectID":"/posts/week1/:0:0","series":null,"tags":null,"title":"第一周：归并排序，运行时与标准","uri":"/posts/week1/#标准与扩展"},{"categories":null,"content":"最近发现身边有些同学并不知道在我看来入门级别的浏览器小技巧，所以专门写一篇文章介绍和总结一下我使用的浏览器小技巧 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#"},{"categories":null,"content":" Ctrl+F 搜索Ctrl+F弹出的搜索框会自动聚焦，我的常用流程是 鼠标选中文本 Ctrl + C复制文本 Ctrl + F 唤起搜索框 Ctrl + V (不需要鼠标点击搜索框，因为自动focus) enter 下一项，shift + enter 前一项 这样的流程在第一次选中文本后就不再需要鼠标，非常快捷 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#ctrlf-搜索"},{"categories":null,"content":" 超链接点击检索信息时遇到的超链接往往希望在另一个tab页中打开，然而有些页面的超链接由于没有设置target=\"_blank\"，点击后会在当前tab页打开，导致无法同时查看两个页面 可以按住Ctrl然后点击超链接，不论超链接如何设置target属性，都会在新tab页中打开 相对的还有按住Shift然后点击超链接和按住Alt点击超链接，分别是在新窗口打开页面和下载页面 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#超链接点击"},{"categories":null,"content":" Tab页切换实际上绝大部分带tab的应用程序，都可以使用Ctrl+Tab切换tab页，而且长按和短按有不同的效果 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#tab页切换"},{"categories":null,"content":" 快速进入常用网站chrome的搜索栏会记忆访问的网站，在地址栏输入链接的部分，可以补全，相当于缩写网站链接，非常实用的功能 例如最近打数据库比赛，输入仓库名的开头三个字符就能快速访问仓库 这个功能也能在收藏的网站中搜索，例如收藏了xv6实验的网站后就能快速补全 搜索bookmark是根据收藏时给bookmark起的名字搜索的，默认的bookmark名是网站的标题，所以中文也能搜索 因为地址栏的补全实在太强大， 需要有意识的维护常用缩写，包括 常用网站主动使用缩写，增加缩写使用频率 不常用的网站不使用缩写，不在地址栏输入google search的关键词 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#快速进入常用网站"},{"categories":null,"content":" 快速导航至浏览器功能Ctrl + H(History)打开历史页面，可以快速找到之前关闭的页面 Ctrl + Shit + N打开无痕模式，因为无痕模式相当于使用另一个Profile，不会使用已经有的cookie，而且浏览器扩展默认设置为禁止在无痕模式下工作，可以满足以下需求 不想被网站跟踪 查看未登录时网页的情况 一个站点登录两个帐号 快速临时禁用浏览器扩展，排除扩展引起的问题 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#快速导航至浏览器功能"},{"categories":null,"content":" 缩放网页字体太小，或者留白太多时，可以使用缩进增强视觉体验 快捷键Ctrl + 滚轮 大部分网站都能在应用110%或125%的缩放时仍然保持良好观感，同时由于增加了字体大小，可以有效避免字体和按钮边缘毛刺、割裂的情况 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#缩放"},{"categories":null,"content":" 地址栏显示的内容很重要","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#地址栏显示的内容很重要"},{"categories":null,"content":" 反映资源id地址栏显示的当前url，可以反映出资源id 例如github的仓库名由两个部分组成，分别是用户名和仓库名，分别唯一标识了不同的实体 又例如bilibili的视频链接格式/video/BVxxxxx，说明了视频由BV号唯一标识 有些资源id不会直接显示给用户，但有可能出现在url中 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:1:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#反映资源id"},{"categories":null,"content":" 文章段落定位url末尾可以接上诸如#abce这样的部分，它被称为hash，HTTP协议会忽略#之后的所有内容，但这样的内容可以被浏览器用于打开页面后滚动至对应的段落，原理是#后接的是页面元素的id，然后浏览器在页面中找到具有这个id值的页面元素，然后滚动使其进入视口并位于顶部 在大部分具有传统的文章概念的页面中，鼠标悬停标题可以看到一个小图标，点击这个小图标就能定位到这个元素，此时地址栏显示的url的末尾也出现了hash 例如github 又例如python包常用的文档托管网站readthedocs.io 知道了段落定位的原理后，可以自己根据页面元素id生成带hash的url，不仅仅可以在不支持段落定位的网站使用，还可以定位段落以外的页面元素 为什么说文章段落这个词汇，是因为web页面虽然已经非常复杂多彩，但仍然保留着Document这样的概念，从HTML语义化标签和HTML元素的布局模式也可以看出这一点。\u003carticle\u003e，\u003cheader\u003e,\u003caside\u003e等语义化标签强化Document和视觉中心的存在；默认布局模式下元素从左向右排列，如果横向空间不够就换行，详情请参见《CSS: The Definitive Guide: Web Layout and Presentation》（CSS权威指南第五版） ","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#文章段落定位"},{"categories":null,"content":" 避免被追踪众所周知在京东淘宝并夕夕这样的网站点击复制分享链接后，复制的链接特别长，后面有一堆?a=b\u0026c=d等参数，事实上这些参数都是url parameters，删掉他们也能正常打开页面，不删掉他们反而会被跟踪，当分享给朋友，朋友再点开链接时，服务提供方可以认为你跟这个朋友有相似的爱好，这样的信息可以用于基于协同过滤的推荐系统实现，原理可以参考推荐系统简单介绍这篇文章 此外，链接很短也不代表是安全的，因为可能是使用了短链，短链可以30x重定向或者由JS操作window.location跳转到一个很长的链接 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:3:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#避免被追踪"},{"categories":null,"content":" 前往任何页面用户在页面中导航有两种方式，一个是手动输入url，另一个是通过与页面的超链接、按钮等元素，在网站的引导下前往页面，这种引导可以是内容服务提供方简化用户导航过程，帮助其快速找到想要的内容，也可以是充满了内容服务提供方利益诉求的“诱导” 以著名的深度学习平台anaconda为例 用户为了使用anaconda而打开它的官网时，被一个显著的 Sign in 按钮吸引，而旁边就是 Free Download 然后来到下载页面，页面显示提供邮箱，除此之外并没有找到其他跟下载有关的按钮或者超链接 在输入了自己的邮箱地址后，anaconda公司会将真正的下载地址发送到邮箱中 然而只需要仔细观察，就能发现刚刚引导用户登录的页面是https://www.anaconda.com/download，而邮箱中的链接是https://www.anaconda.com/download/success 由于刚刚的流程并没有注册和登录，所以anaconda网站无法知道访问者是谁，这样的链接很难让人不怀疑是不是没有登录墙保护，Ctrl+Shift+N进入无痕模式，尝试直接输入/download/success访问，居然也能成功 可见这样的页面组织只是为了收集使用者信息，方便anaconda公司宣传产品，所以刻意阻止用户直接下载anaconda而离开页面 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:4:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#前往任何页面"},{"categories":null,"content":" 根据域名快速判断内容可信度当使用搜索引擎进行信息检索时，需要在搜索引擎提供的一系列结果中筛选。除了网页标题，域名也是判断内容可信度的一个非常重要的依据 点名批评百度，不仅仅广告排第一位而且不显示域名，极力误导小白用户，破坏简中互联网 例如一个小白用户下载steam的流程：打开百度搜索steam 然而点击第一个超链接 而如果能提前知道这个网站域名是game.pengchengxinxi.cn，就能快速判断出不是steam ","date":"2024-06-07","objectID":"/posts/browser_tricks/:5:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#根据域名快速判断内容可信度"},{"categories":null,"content":" 进阶使用","date":"2024-06-07","objectID":"/posts/browser_tricks/:0:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#进阶使用"},{"categories":null,"content":" 长截图长截图从技术原理上来说比截图复杂得多，甚至有些从原理上是无法长截图的，比如自绘UI，而只能从某些角度近似的实现长截图的功能 浏览器也是非常经典的自绘UI，但它提供了一个很方便的长截图功能 首先打开dev tool，找到相应元素，右键捕获截图即可 寻找元素的技巧如下 语义化标签，例如github的仓库主页，有main标签可以快速定位 需要长截图是因为一个元素的高度大于视口高度，找到这样的元素即可 不断寻找父元素直到其内容覆盖整个屏幕 某些页面布局很难甚至无法找到这样的元素 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:1:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#长截图"},{"categories":null,"content":" 我就要复制","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#我就要复制"},{"categories":null,"content":" 解法1: 打开dev tools复制简单的场合下，仅仅是监听事件然后阻止了复制事件的默认行为，在dev tools中复制即可，因为JS无法控制dev tools ","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:1","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#解法1-打开dev-tools复制"},{"categories":null,"content":" 解法2: 禁用JS前文提及阻止复制是JS实现的，所以只要打开dev tools禁止页面加载JS脚本，然后刷新页面即可 在不考虑各种浏览器扩展，油猴脚本的情况下，可以简单的使用JS的DOM接口实现 原理是找到包含文本的HTML元素，访问其innerText属性即可这个元素渲染出的的文本 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:2","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#解法2-禁用js"},{"categories":null,"content":" 解法3: innerText 由于这样的元素中的文本被HTML标签分隔，需要依次选中每段文本然后复制，非常麻烦 可以使用HTML元素的innerText属性，它表示该元素内渲染的文本 要访问innerText属性，必须先获得这个元素的引用，将其保存在JS的变量中，此处不需要使用xpath或CSS selector等选择器，直接使用dev tool提供的快捷功能获取其引用 dev tools将这个元素绑定到temp1变量上，然后访问其innerText属性即可 此处获取到的文本是转义过的，而我们明显不想复制\\n，使用console.log打印出来即可 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:2:3","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#解法3-innertext"},{"categories":null,"content":" 清除cookie众所周知bing的中国特供版有些功能并没有，而大陆用户能访问的“国内版”和“国际版”，实际上都是中国特供版，而不是真正的国际版。 绕过区域限制中的一个步骤就是清除cookie，即使没有登录，网站也可以设置cookie用于追踪用户。只要第一次在大陆网络环境访问bing，被设置了相应cookie，即使下次通过国际网络访问，也会因为之前设置的cookie而被认为是大陆用户 解决方案就是打开dev tool，依次点击Application - Cookies - https://xxx.com，逐个删除cookie即可 ","date":"2024-06-07","objectID":"/posts/browser_tricks/:3:0","series":null,"tags":null,"title":"浏览器小技巧总结","uri":"/posts/browser_tricks/#清除cookie"},{"categories":null,"content":"这篇文章讨论了哈希函数的安全问题和python的哈希实现 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:0:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#"},{"categories":null,"content":" Hash DOS所谓Hash DOS即利用hash碰撞增加服务器负担、使其无法响应正常用户的请求的情况，以下说明为什么可以利用哈希碰撞发起DOS攻击 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:0:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#hash-dos"},{"categories":null,"content":" 哈希碰撞不可避免哈希是一种摘要算法而非加密算法，它将任意长度的比特序列映射成一个固定长度的比特序列，根据抽屉原理/鸽笼原理：“n+1个苹果放到n个抽屉中，至少有一个抽屉里放了两个及两个以上的苹果”，哈希函数将具有无穷种情况的任意长度比特序列映射到有穷种情况的固定长度比特序列，所以必定存在一些比特序列，他们经过哈希运算后得到的值相等，即哈希碰撞 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:1:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#哈希碰撞不可避免"},{"categories":null,"content":" 哈希碰撞容易发生假设哈希表中有365个桶，那么往其中插入23个随机的数据，发生哈希碰撞的概率有多少? 实际上，概率高达50% ！将随机数据换成每个人的生日，这就是生日悖论 这说明，哈希碰撞发生的概率远超我们的预期 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:2:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#哈希碰撞容易发生"},{"categories":null,"content":" hash DOS的原理以上说明了哈希碰撞容易发生，但这并不能解释为什么哈希碰撞能用于发起DOS攻击 哈希表在理想状况下，插入、查找、删除都是在常数时间内完成（时间复杂度O(1)），在最坏的情况下，时间复杂度是O(n)。大部分时候我们都认为哈希表的时间复杂度就是O(1)， 因此将哈希表用于系统关键处用于提高性能，然而由于哈希碰撞的不可预测性，哈希表的时间复杂度实际上是在O(1) ~ O(n)中摇摆，这就为系统关键处带来了不确定性。 设想现在系统关键处的哈希表由于发生了大量哈希碰撞，性能急剧下降，那么整个系统的性能也会急剧下降 假设有一个服务器维护一个哈希表，键是用户名字符串，值是用户的各种信息组成的对象，这个哈希表有一百万个桶，攻击者如果想要通过蛮力使哈希表性能恶化，鉴于一百万的量级，可能需要发起非常多操作才能达到预期。然而假设攻击者知道了服务器使用的哈希函数，例如服务器使用了一个不安全的哈希函数 c long hash(char* username){ long hash = 0; for (int i = 0; username[i] != '\\0'; i++) { hash += username[i]; } return hash; } 这样的哈希函数可以轻松构造出哈希值相同的不同字符串，例如\"zhansan\"和\"zhansbl\"。于是攻击者精心构造了一千个这样的字符串然后发起了一百次操作，每次操作服务器就会遇到这一千个发生碰撞的键值对，逐个比较时间复杂度为O(n)，n为碰撞规模，精心构造的字符串极大地放大了每次操作的效果 ","date":"2024-04-10","objectID":"/posts/hash_dos_and_python_hash/:3:0","series":null,"tags":null,"title":"Hash_dos_and_python_hash","uri":"/posts/hash_dos_and_python_hash/#hash-dos的原理"},{"categories":null,"content":"rime是一个开源、高度可定制、多平台支持的输入法框架，然而在配置fctix5-rime的配色方案时我又踩了坑，记录一下解决方案 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#"},{"categories":null,"content":" fctix5不支持rime配色网上许多rime教程都是用的鼠须管或者小狼毫，分别是rime的macOS和windows发行版，中州韵很少遇到，此外即使遇到了中州韵，往往也是用的ibus， 然而在2024年的今天，fctix5明显是一个更优的选择 fctix5和ibus的一个不同点就是，配色方案不是rime的，而是fctix5的，另外在fctix5是主题（theme）而不是rime的配色方案（color style），所以网上抄的各种配色方案都不会生效，例如我抄了一个仿微信输入法的配色方案，然后试了无数次都无法生效！ ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#fctix5不支持rime配色"},{"categories":null,"content":" 正确的做法首先参考arch wiki，在github我找到了一个看起来不错的仿macOS的主题 使用步骤见此仓库的README，将主题文件复制到~/.local/share/fcitx5/themes下即可 然后打开KDE的system setting KDE会自动识别~/.local/share/fcitx5/themes下的所有主题文件，并显示在多选框中 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#正确的做法"},{"categories":null,"content":" 主题微调使用前文提及的仿macOS主题时又遇到一个问题，候选词间距太大了，然而只要查看过~/.local/share/fcitx5/themes的主题文件，能够很清楚的知道主题是怎么指定的。 不同主题在以其名字命名的目录下，这个目录下有一个文件theme.conf，它是ini格式的配置文件，可读性较好，而且我找到的主题还贴心的给每个配置加上了中文注释。于是 我修改了一下内容 ini [InputPanel/Background/Margin] # 左侧边距 Left=10 # 右侧边距 Right=10 # 顶部边距 Top=8 # 底部边距 Bottom=8 [InputPanel/Highlight] # 背景图片 Image=highlight.svg [InputPanel/Highlight/Margin] # 高亮区域左边距 Left=10 # 高亮区域右边距 Right=10 # 高亮区域上边距 Top=8 # 高亮区域下边距 Bottom=8 [InputPanel/TextMargin] # 候选字对左边距 Left=10 # 候选字对右边距 Right=10 # 候选字向上边距 Top=8 # 候选字向下边距 Bottom=8 就达到了我想要的效果 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#主题微调"},{"categories":null,"content":" 效果展示 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#效果展示"},{"categories":null,"content":" Tipsrime的配置逻辑是，用户修改xxx.custom.yaml文件用于覆盖或重写rime的默认配置文件xxx.yaml，所以当不确定xxx.custom.yaml中的xxx是什么时，可以查看 /usr/share/rime-data/有哪些文件，假设有一个文件名字为abc.yaml，那么能够覆盖它的文件名为abc.custom.yaml rime的windows发行版名字为小狼毫，对应的配置文件为squirrel.yaml，macOS发行版为鼠须管，对应配置文件为weasel.yaml，linux发行版名字为中州韵,然而比较坑的是，我并没有发现中州韵对应的配置文件名，相反，在我的fcitx5-rime上对应的配置文件为fcitx5.yaml 我的fcitx5-rime在用户配置错误时，不会报错，而是直接完全使用rime的默认配置，使人不知所措，此外官网上提及的日志文件/tmp/xxx，我并没有找到 ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#tips"},{"categories":null,"content":" 我的rime配置使用了很长时间，自认为还是比较好用，不过在中文模式下输入中文标点符号这点还是比较不方便 default.custom.yaml yaml patch: \"switcher/option_list_separator\": '|~ \"switcher/caption\": \"[方案列表]\" \"switcher/hotkeys\": - Control+grave \"switcher/save_options\": \"schema_list\": - schema: double_pinyin_flypy # - schema: luna_pinyin \"key_binder/bindings\": - {when: always, accept: Control+space, toggle: ascii_mode} - {when: has_menu, accept: minus, send: Page_Up} - {when: has_menu, accept: equal, send: Page_Down} 主要配置了唯一一个输入法即小鹤双拼（朋友评价为防止别人用我电脑…），ctrl+空格 切换中英文（不知道为什么还是能通过shift切换中英文）， 加减号翻页 double_pinyin_flypy.custom.yaml yaml patch: schema/name: 小鹤双拼 switches: - name: ascii_mode reset: 1 states: [中文, 西文] - name: full_shape reset: 0 states: [半角, 全角] - name: simplification reset: 1 states: [繁体, 简体] - name: ascii_punct reset: 0 states: [ \".,\", \"。，\" ] engine/processors: - ascii_composer # - recognizer - key_binder - speller - punctuator - selector - navigator - express_editor 配置了默认使用英文输入法，半角简体，这里配置非常简单，主要目地是覆盖默认的大量配置 可以看出即使rime被称为最强输入法，但我几乎没有定制它的功能… ","date":"2024-03-30","objectID":"/posts/fcitx5_rime_color_style/:0:0","series":null,"tags":null,"title":"fctix5-rime设置配色方案","uri":"/posts/fcitx5_rime_color_style/#我的rime配置"},{"categories":null,"content":"这是APUE（Advanced Programming in the UNIX Environment，UINX环境高级编程）阅读笔记系列文章 首先参考一个简单的类UINX操作系统实现——xv6，了解操作系统是如何组织文件资源的 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#"},{"categories":null,"content":" xv6的File IO实现","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#xv6的file-io实现"},{"categories":null,"content":" File是操作系统管理的底层资源在xv6中，file结构体是对管道，inode（表示常规文件），设备的抽象。xv6没有内核内存分配器，只是静态分配了一个固定大小的file数组，用于存放内核打开的所有file ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#file是操作系统管理的底层资源"},{"categories":null,"content":" file descriptor是File的引用file descriptor(简称fd)在xv6中，是通过PCB（进程控制块）中的一个固定大小的数组存储的，这表明了两点： fd是process local的，表示进程对内核资源的引用 一个进程能够打开的文件是有最大数量限制的 fd和windows的handler很相似，它是为了避免直接使用指针引用内核数据，优点如下 避免内核数据结构暴露在进程中 如果直接将file结构体的指针交给进程使用，进程就能知道file的内存地址，虽然进程一般无法读写这块地址，但不代表这是足够安全的 防止恶意进程提供错误指针误导内核 假设进程提供的指针是非法指针，并不指向file结构体，这种情况在xv6中能够通过判断指针是否在数组中越界来确定 然而，如果进程提供的指针指向其他进程打开的文件，就有机会滥用其他进程的资源 换而言之，指针是全局的，而fd是process local的 向进程屏蔽file结构体的实现细节 众所周知随着内核版本的迭代，内核使用的某些数据结构会发生改变，例如添加新功能，需要在原有的结构体上添加新的字段 这样的细节对进程是无用的，还会导致编译后的二进制依赖于某个特定版本的内核实现 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:2:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#file-descriptor是file的引用"},{"categories":null,"content":" stdin, stdout, stderror只是约定通常一个程序开始运行时，已经有三个文件打开了：0，1，2，分别表示stdin, stdout, stderror 在xv6的实现中，内核并没有对0,1,2特殊处理，因为它只是shell的约定。xv6在用户态下提供了一个shell程序，片段如下 c if(open(\"console\", O_RDWR) \u003c 0){ mknod(\"console\", CONSOLE, 0); open(\"console\", O_RDWR); } dup(0); // stdout dup(0); // stderr 可以看出shell打开了终端设备文件，并通过dup使得0，1，2指向同一个终端设备文件。而在shell中运行的程序fork自shell程序，所以继承了shell程序的0，1，2文件描述符 换而言之，一个程序运行时，0，1，2不一定是已经打开的文件！！！ ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#stdin-stdout-stderror只是约定"},{"categories":null,"content":" 文件打开，关闭","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#文件打开关闭"},{"categories":null,"content":" openopen函数打开一个文件，返回fd c int open (const char *__file, int __oflag, ...) 参数名 说明 __file 文件路径 __oflag 打开方式，通过比特掩码传递flags mode 只有在创建文件时才会使用，用于设置创建的文件的权限，类型为mode_t 返回 文件描述符，-1表示打开失败，并设置erron，其他情况返回文件描述符 返回的fd总是未使用的fd中最小的一个，利用这个特性可以重定向标准输入，标准输出，标准错误 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#open"},{"categories":null,"content":" oflag常用oflag 宏 说明 O_RDONLY 只读 O_WRONLY 只写 O_RDWD 可读可写 O_EXEC 执行 O_APPNED 写入内容附加到末尾 O_CLOEXEC 执行exec系列函数时自动关闭，防止子进程继承到父进程的该文件 O_CREATE 如果文件不存在，自动创建 O_EXCL 和O_CREATE配合使用，如果文件存在，则返回错误 O_TRUNC 如果文件能够以可读方式打开，则将文件大小设置为0 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:1","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#oflag"},{"categories":null,"content":" close c int close (int __fd) 进程结束时，操作系统会自动关闭进程打开的文件，所以在一些场合下，可以不调用close关闭文件 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:2:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#close"},{"categories":null,"content":" creat vs open考虑creat函数 c int creat (const char *__file, mode_t __mode) 相比open，只能创建文件 打开文件时，如果需要自动创建文件，有两种方式 使用open带O_CREATE 使用open带O_CREATE|O_EXCL判断文件是否存在，如果不存在则使用creat创建。之后再打开文件 这两种方式的不同在于，在并发环境下，先判断一个条件是否成立再执行某个操作，这样的流程是线程不安全的，有可能在判断条件成立后，内核剥夺CPU，重新被调度时条件已经不成立。 使用open带O_CREATE，判断文件是否存在和创建文件两个步骤是原子操作，保证不会出现竞态条件 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#creat-vs-open"},{"categories":null,"content":" 文件操作xv6实现中，file字段有一个属性，用于记录文件偏移 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#文件操作"},{"categories":null,"content":" read c ssize_t read (int __fd, void *__buf, size_t __nbytes) 参数 说明 fd 必须是可读的文件描述符，可以是常规文件，终端设备，网络套接字等 __buf 进程准备的缓冲数组，内核会将读取到的文件内容存放到这里 __nbytes 进程期望一次最多读取的字节数量 返回 实际读取的字节数，-1表示遇到错误，0表示遇到EOF 如果实际读取的字节数小于__nbytes,表明发生了如下情况 如果读取常规文件，则表示读取__nbytes个字节时遇到了EOF 如果从终端设备中读取，通常一次读取一行，返回这一行的字节数 如果从网络套接字中读取，网络缓冲可能导致小于__nbytes个字节读取 如果从管道中读取，而管道中剩余字节数小于__nbytes etc… 读取后，文件偏移向前移动实际读取的字节数 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#read"},{"categories":null,"content":" write c ssize_t write (int __fd, const void *__buf, size_t __n) 参数 说明 fd 同read __buf 进程准备的缓冲数组，内核会读取这个缓冲数组中的字节并写入文件 __nbytes 进程期望一次最多写入的字节数量 返回 大部分情况下等于__nbytes 如果返回值不等于__nbytes，表明错误发生，可能是磁盘已满，或者用户磁盘使用超过配额 读取后，文件偏移向前移动实际写入的字节数 为了提高IO性能，内核不会立刻将数据写入磁盘，而是先写入内存中的IO缓冲区，随后（保证一定时间内）写入磁盘 如果打开文件时使用了O_SYNC，会阻塞直到数据落盘 如果打开文件时使用了O_APPEND，会先将文件偏移移动到文件末尾，再写入 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:2:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#write"},{"categories":null,"content":" lseeklseek函数用于修改文件偏移 c __off_t lseek (int __fd, __off_t __offset, int __whence) 参数 说明 __fd 文件描述符 __offset 新的文件偏移 __whence 宏，表示相对位置 返回 lseek调用后的文件偏移 __whence使用的宏 SEEK_SET，相对文件开头寻址 SEEK_CUR，相对当前位置寻址 SEEK_END，相对文件末尾寻址 lseek中的l表示long integer，在引入__off_t前，lseek返回类型是long off_t是有符号数，在极特殊情况下可能是负数，而返回-1又代表错误，所以应该使用==-1判断是否出现错误而不是\u003c0 不是所有类型的文件都能使用lseek，对管道，套接字，FIFO使用lseek会返回-1表示错误 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#lseek"},{"categories":null,"content":" lseek常见用法 判断文件是否可寻址 c if (lseek(fd, 0 ,SEEK_CUR) != -1) { // ... } 获取当前文件偏移 c off_t pos = lseek(fd, 0 ,SEEK_CUR); 获取文件大小 c off_t size = lseek(fd, 0 ,SEEK_END); lseek只修改文件偏移，不会产生IO操作，可以使用lseek获取大文件的大小 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:1","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#lseek常见用法"},{"categories":null,"content":" 文件打洞lseek允许将文件偏移设置到EOF之后，随后调用write，就能在文件中间打一个洞 文件打洞后，空洞范围内使用read读取到的值是0（'\\0'），空洞不会增加文件大小，部分文件系统不会存储空洞中重复的数据 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:3:2","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#文件打洞"},{"categories":null,"content":" dup系列函数dup系列函数用于实现file对象的共享，也就是两个fd指向同一个资源，因此，也会共享file对象的属性，比如file标志位，文件偏移等等 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:4:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dup系列函数"},{"categories":null,"content":" dup c int dup (int __fd) 参数 说明 __fd 文件描述符 返回 一个新的文件描述符，和__fd指向相同的资源 dup返回的fd总是未使用的fd中最小的一个 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:4:1","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dup"},{"categories":null,"content":" dup2 c int dup2 (int __fd, int __fd2) 参数 说明 __fd 文件描述符 __fd2 期望dup文件描述符的位置 如果__fd2是已经打开的文件描述符，则自动关闭，然后再执行dup操作 如果__fd == __fd2，则直接返回__fd 如果__fd2未使用，则dup2执行完毕后，__fd2的FD_CLOEXEC标志位被清除，方便与fork配合实现管道通信 dup2 vs close-open重定向标准输入，也就是在0处打开其他文件，有两种做法 1. c close(0); open(\"path/to/file\", O_RDONLY); c int fd = open(\"path/to/file\", O_RDONLY); dup2(fd, 0); 区别是，使用dup2可以明显地表达意图，可读性更好 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:4:2","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dup2"},{"categories":null,"content":" dup2 c int dup2 (int __fd, int __fd2) 参数 说明 __fd 文件描述符 __fd2 期望dup文件描述符的位置 如果__fd2是已经打开的文件描述符，则自动关闭，然后再执行dup操作 如果__fd == __fd2，则直接返回__fd 如果__fd2未使用，则dup2执行完毕后，__fd2的FD_CLOEXEC标志位被清除，方便与fork配合实现管道通信 dup2 vs close-open重定向标准输入，也就是在0处打开其他文件，有两种做法 1. c close(0); open(\"path/to/file\", O_RDONLY); c int fd = open(\"path/to/file\", O_RDONLY); dup2(fd, 0); 区别是，使用dup2可以明显地表达意图，可读性更好 ","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:4:2","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dup2-vs-close-open"},{"categories":null,"content":" sync系列函数","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:5:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#sync系列函数"},{"categories":null,"content":" fcntl函数","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:6:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#fcntl函数"},{"categories":null,"content":" ioctl函数","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:7:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#ioctl函数"},{"categories":null,"content":" /dev下的文件","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:0:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#dev下的文件"},{"categories":null,"content":" /dev/fd/*","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:1:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#devfd"},{"categories":null,"content":" /dev/std**系列文件","date":"2024-02-11","objectID":"/posts/apue-chapter1-fileio/:2:0","series":null,"tags":null,"title":"APUE第三章总结：文件IO","uri":"/posts/apue-chapter1-fileio/#devstd系列文件"},{"categories":null,"content":"许多新语言(2000之后发明的语言)大多有一个偏好：类型后置 rust: rust let x : i32 = 1; go: go var a []string kotlin: kotlin var language : String = \"French\" TypeScript: TS let x : number = 1; 在我看来，有以下几个原因 ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:0:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#"},{"categories":null,"content":" 动态类型不可取说到动态类型不得不提JS和python，从它们的发展过程来看动态类型存在很多问题 ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:0:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#动态类型不可取"},{"categories":null,"content":" JSECMAscript规定它是动态类型，弱类型的语言，使得JS非常灵活，但也带来很多问题。不提ES2015之前的JS，JS写下一个变量不知道它的类型，它的类型可以在运行时随意改变，甚至ECMAscript规定JS可以自动转型，例如 JS 1 + \"1\" JS发现类型不匹配后，会自动将1转型以执行+运算符 html \u003cdiv id=\"myoutput1\"\u003e\u003c/div\u003e \u003cdiv id=\"myoutput2\"\u003e\u003c/div\u003e \u003cscript\u003e(()=\u003e{ document.querySelector(\"#myoutput1\").innerText = 1 + \"1\" document.querySelector(\"#myoutput2\").innerText = 1 - \"1\" })(); \u003c/script\u003e 在线HTML执行后输出为 text 11 0 这样灵活的JS为前端工程化带来了很大的麻烦，于是microsoft提出了Typescript，实现了静态类型约束。不过TS也带来了一些新的问题，比如经常被调侃为做‘类型体操’ ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:1:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#js"},{"categories":null,"content":" pythonpython和JS的定位都是脚本语言，自然也是动态类型的语言，不过相比JS，python是强类型的，不会自动转型。不过pyton同样因为过于灵活，开发大型项目时力不从心。大型项目更需要的是严谨刻板，茴香豆的茴即使有四种写法，也会规定只能使用一种。 从python3.5开始，逐渐引入了type hint。有了type hint，不仅language server能从其中受益，开发者也能使用像pyright, mypy这类静态类检查器来检查代码中潜在的错误，不过python引入type hint是渐进的，目前（python3.12）type hint虽然支持了许多功能，但仍然有很多第三方库没有提供type hint或者没有提供完整的type hint，此外python的静态类型检查器也并不完善，有些时候还是只增加许多琐碎的代码来通过静态类型检查，或者在某处禁用静态类型检查 ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:2:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#python"},{"categories":null,"content":" 静态类型的痛从JS和python的发展历程可以看出动态类型的问题很严重，虽然天生泛型，但是一门面向工业面向生产的语言，必须选择静态类型，不过静态类型也有一些问题 语言更繁琐 需要实现泛型 从JS和python所处的年代，那时选择动态类型是很合理的，被C++折磨太多，突然抛弃类型就会非常轻松。 对于静态类型带来的疼痛，新语言往往使用了对应的’止痛药‘：省略类型 所谓类型推导，也就是编译器提供了强大的类型推导能力，能够在很多时候省略掉类型声明，减少静态类型带来的疼痛，例如rust在大部分时候都不需要声明类型，编译器会自动根据右值推导，例如根据数值范围推导是i32还是i64，根据函数返回类型推导， 甚至还能根据return语句自动推导函数返回类型。这反映出编译技术的不断进步，给开发者带来了不少便利，开发者再也不需要像以前使用C/C++时到处写类型了 于是类型在大部分时候可以省略，一个变量的声明中类型成了可选，如果不写类型，怎么知道这个语句到底是声明还是赋值呢？ 有两种方案 类型前置，使用auto，var等在省略类型时占位 C++11后可以使用auto让编译器推导类型，java也可以使用var省略类型 另外，同样是新语言的dart采用了var 类型后置，使用let，var等标志变量声明 TS，rust，kotlin都采用这种方式省略类型 那么为什么选择类型后置呢，大概是为了整齐，众所周知C++有这种风格 C++ int a = 1; std::string s = \"xxxx\"; 这是为了避免类型名称长度不一致，长短交错，增加阅读难度 如果使用类型后置 rust let url :String = \"https://google.com\"; let res :Response = reqwest::get(url).await?; let body :String = res.text().await?; // 以上类型都可以省略 更加整齐 此外还有一个因素，如果使用IDE的virtual text功能，可以在let url = \"https://google.com\"的url | =光标所在的位置增加一个虚拟文本，标注出类型，就能避免大量省略类型造成类型不清晰 ","date":"2024-01-25","objectID":"/posts/type-move-to-right/:0:0","series":null,"tags":null,"title":"逐渐向右移动的类型——静态类型成为新语言的趋势","uri":"/posts/type-move-to-right/#静态类型的痛"},{"categories":null,"content":"所谓空安全，也就是null safety，它是部分现代语言具有的新特性，如dart和kotlin，既然它是现代语言才具备的特性，说明之前的语言往往没有，例如java ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#"},{"categories":null,"content":" java的空值不安全众所周知，java只有原始类型和引用类型，而所有引用类型都是Object类的子类或Object类它自己，而java的空值不安全，也就出现在引用类型上。 java的引用类型本质上就是指针，而作为深受C++影响的语言，它的引用类型也继承了C++的指针的问题——空指针问题 在java中定义的任何一个类，都是Obecjt的子类，任何一个类的对象，都可以为空，也就是为null，也就是说，引用类型包含了null! 所谓‘包含’，这又涉及一个概念，可以把一个类型看作一个集合，而这个类型的任何一个值看作这个集合中的一个元素，例如： int类型表示集合 $\\Set{ x | x \\in Z \\land -2^{31} \\le x \\le 2^{31} - 1 } $ ，即所有int值的集合 float类型表示的集合比较复杂，首先float是离散的，能表示的值范围有限而且精度有限，而且不是等间距的，还包括了IEEE定义的inf，-inf，以及NaN Object类型表示的集合更复杂，但可以任何是程序运行过程中可能创建的所有Obejct对象以及它的子类的对象 而null值可以作为任意引用类型的对象的值，这在数学上造成了一个漏洞，造成了以下问题 null值属于什么类型？ 因为null可以作为任意引用类型的对象的值，所以null是任何引用类型的一个实例或它的子类的实例，但很明显这样的值是不能存在的 在类中定义的方法和属性，在类的实例（对象）上不一定可用 java的Object对象有一个方法toString()，然而你不能在null上调用这种方法，否则会抛出异常，严格来说，在使用toString()前应该先判断这个对象是否为null 这样的漏洞都可以使用引用类型来解释，因为引用类型的所有值都代表对某个对象的引用，所以这个值可以为空，表示没有引用任何对象 ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#java的空值不安全"},{"categories":null,"content":" C++的空值安全？C++的空值安全比较复杂，分为指针和引用两种类型 指针很明显空值不安全，java的空值不安全本质上还是指针的空值不安全 引用最大的优点就是，不存在空引用，也就是说，它缓解了C++的空指针问题，在合适的场合使用引用代替指针，可以减少空指针出现的情况 ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#c的空值安全"},{"categories":null,"content":" python的空值安全python相比java和JS，有一个很明显的特点：一切皆对象，也就是说，python中的所有值都是对象，也就是object类的实例，自然None也是object的实例 然而，None是NoneType类的直接对象，也就是说，任何NoneType类以外的对象，都不可能为None，这么看来，python的空值设计比较合理 graph TD object --\u003e NoneType --唯一实例--\u003e None object --\u003e str object --\u003e int object --\u003e ... 但问题在于，python是动态类型语言，也就是说变量运行时类型可以随意改变，在使用type hint之前，python并不能从空值安全的设计中受益 如果使用type hint，并引入严格的静态类型检查，python就是空值安全的。 假设你需要使用一个字符串变量，并且它可能为None，就应该写成 python x : str | None = \"....\" 如果你需要使用字符串的strip方法： python x.strip() 这样的写法并不会通过诸如mypy这样的静态类型检查器，需要使用’type guard’保证x的类型为str而不是str | None python assert x is not None x.strip() # 或 assert isinstance(x, str) x.strip() # 或 if isinstance(x, str): x.strip() 假设你需要使用一个字符串，而且它不可能为空，应该写成 python x : str = \"....\" 尝试给它赋值None，可以运行但是无法通过静态类型检查 python x : str = None # mypy报错 # 或 x : str = \"....\" x = None # mypy报错 ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#python的空值安全"},{"categories":null,"content":" dart的类型安全dart3.0引入了一个新特性：空值安全 dart也是一切皆对象，而dart只有两类类型，一个是Null类，一个是Object类。从语言的底层设计就能看出dart对空值的态度 如果一个变量不能为空 dart String x = \"....\" // 不能为空的变量必须在声明时赋初值，如果是类的属性，则必须在构造函数中赋值 如果可能为空 dart String? x; // 可空的变量，默认初值为null String?不是任何传统的类型，而是两种类型的组合，类似python的str | None，如果使用前文提及的集合的观点，这种类型属于String类型和Null类型的集合并集，只不过dart并没有提供使用class关键字定义这个类的语法能力 此外dart是静态类型的语言，还拥有强大的类型推断能力(type inference)，又提供了null相关的语法糖，能够避免写下很多琐碎的类型断言（例如python的assert x is not None） null相关语法糖使用了 !和?，并和dart其他特性配合，组合出非常多的使用方式，例如在级联操作符中使用，在pattern中使用等等，例如 null-aware dart String? notAString = null; print(notAString?.length); 如果notAString为null，不报错，表达式返回null null-aware短路 dart showGizmo(Thing? thing) { print(thing?.doohickey.gizmo); } 如果thing为null，不会评估表达式后面的部分，直接返回，避免写下thing?.doohickey?.gizmo这样繁琐的表达式 null-aware与下标运算符 dart receiver?[index]; null-aware与级联运算符 dart receiver?..method(); null assert dart String toString() { if (code == 200) return 'OK'; return 'ERROR $code ${error!.toUpperCase()}'; } 一旦error的运行时类型为null，就会出现转型错误（cast error），抛出运行时异常 与pattern配合 dart String? maybeString = 'nullable with base type String'; switch (maybeString) { case var s?: // 's' has type non-nullable String here. } dart List\u003cString?\u003e row = ['user', null]; switch (row) { case ['user', var name!]: // ... // 'name' is a non-nullable string here. } dart (int?, int?) position = (2, 3); var (x!, y!) = position; dart的null safety有一个特点：一个变量，只要编译器确定了它不为空，那么它永远不可能为null，这种特性被称为sound null safety ","date":"2024-01-25","objectID":"/posts/null-safety/:0:0","series":null,"tags":null,"title":"现代语言的空安全","uri":"/posts/null-safety/#dart的类型安全"},{"categories":null,"content":"这篇文章描述了如何在KDE桌面环境使用一个名为pano的音频可视化widget 效果图 ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:0:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#"},{"categories":null,"content":" KDE如何安装widget占坑 ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:0:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#kde如何安装widget"},{"categories":null,"content":" 如何安装panopano仓库见https://github.com/rbn42/panon，仓库已经两年没有更新了，在比较新的系统上可能会出现一些问题，所以必须手动修改部分源码再重新编译 ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:0:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#如何安装pano"},{"categories":null,"content":" 安装依赖 shell sudo pacman -S qt5-websockets \\ python-docopt python-numpy python-pyaudio python-cffi python-websockets 其他发行版见README ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:1:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#安装依赖"},{"categories":null,"content":" 解决一个bug因为python的collection.Iterable在3.10弃用，移动到了collection.abc.Iterable，导致pano在python系统解释器版本比较高的情况下会出现无法显示音频的情况， 详见https://github.com/rbn42/panon/pull/108#issuecomment-1568908093 先拉取pano源码 shell git clone https://github.com/rbn42/panon.git cd panon git submodule update --init 然后修改./third_party/SoundCard/soundcard/pulseaudio.py，将所有使用到collection.Iterable的部分换成collection.abc.Iterable diff -import collections +import collections.abc - if isinstance(self.channels, collections.Iterable): + if isinstance(self.channels, collections.abc.Iterable): - if isinstance(self.channels, collections.Iterable): + if isinstance(self.channels, collections.abc.Iterable): 然后构建widget shell # Build translations (optional) mkdir build cd build cmake ../translations make install DESTDIR=../plasmoid/contents/locale cd .. # To install kpackagetool5 -t Plasma/Applet --install plasmoid ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:2:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#解决一个bug"},{"categories":null,"content":" 安装后的设置将pano放到任务栏后，需要设置采集音频的来源 对于比较新的linux，基本使用pulseaudio提供音频服务，pulseaudio有很多前端可以快速的配置一些音频的选项，这里使用pavucontrol shell sudo pacman -S pavucontrol pavucontrol提供一个简单的GUI前端，打开application launcher搜索pulseaudio，设置ALSA plugin-in的采集来源，如果设置为麦克风，则pano会显示麦克风录音的音频， 然而正常情况下应该是采集耳机中播放的音乐的音频然后可视化 pano默认的特效有点丑，可以选择其他的特效，最终就能达到上述的效果 ","date":"2023-12-23","objectID":"/posts/linux-desktop-widget-pano/:3:0","series":null,"tags":null,"title":"KDE桌面部件pano","uri":"/posts/linux-desktop-widget-pano/#安装后的设置"},{"categories":null,"content":"这篇文章是数据库系统原理课程的任务“阅读postgresql源码“的报告 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#"},{"categories":null,"content":" 如何编译首先声明一点，网上大部分的教程都不太合理，因为对环境的影响太大，权限约束不够严格 作为开源自由软件，pg使用GNU工具链编译，包括autoconf,makefile，gcc等 进入pg项目，在build目录下编译 shell mkdir build \u0026\u0026 cd build # 完成configure，指定-g编译参数,禁用优化，指定安装路径 ../configure --enable-debug CFLAGS=\"O0\" --prefix=/home/arch/src/postgres/build # 路径需要使用build目录的绝对路径 # 编译安装 make \u0026\u0026 make install 安装到build目录是比较合理的！因为默认的安装位置/usr/local需要root权限才能写入，没必要给root权限，也完全没必要安装到这个地方 执行完之后，可能需要设置LD_LIBRARY_PATH环境变量 shell set LD_LIBRARY_PATH=/home/arch/src/postgres/build/lib # 指定build/lib目录，同样需要绝对路径 LD_LIBRARY_PATH告诉linux在哪里找动态链接库，以上方式设置后，只在当前终端生效。没有必要写入~/.bashrc 可以使用ldd命令查看一个可执行需要加载哪些动态库 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#如何编译"},{"categories":null,"content":" 调试的方法首先，在使用configure时，指定参数--enable-debug，以-g选项编译pg make命令生成的可执行有多个，需要确定调试的可执行，以及它的入口函数main所在的位置 启动pg后，通过ps aux | grep postgres可以看到，pg有多个进程协作 text ➜ postgres git:(master) ✗ ps aux | grep postgres arch 140029 0.0 0.1 205168 21652 ? Ss 22:04 0:00 /home/arch/src/postgres/build/bin/postgres -D data arch 140202 0.0 0.0 205316 8276 ? Ss 22:05 0:00 postgres: checkpointer arch 140203 0.0 0.0 205300 7764 ? Ss 22:05 0:00 postgres: background writer arch 140225 0.0 0.0 205336 10588 ? Ss 22:05 0:00 postgres: walwriter arch 140226 0.0 0.0 206844 8156 ? Ss 22:05 0:00 postgres: autovacuum launcher arch 140227 0.0 0.0 206788 7644 ? Ss 22:05 0:00 postgres: logical replication launcher arch 140264 0.0 0.0 207788 11612 ? Ss 22:06 0:00 postgres: arch test [local] idle 可以看出， arch test [local] idle是pg为处理客户端的连接而创建的进程，所以可以知道一条sql语句执行的全部流程都在这个进程中完成。 在linux上，进程是通过fork系统调用创建的。gdb对fork有一个限制，fork执行结束后，有一个父进程和子进程，然而gdb只能跟踪一个进程。 gdb默认跟踪父进程，导致无法进入子进程调试，可以通过set follow-fork-mod child改变这种行为。 然而，这种方式我在使用时发现会导致gdb立刻退出，而pg进程还在后台运行 于是，我尝试使用gdb的attach功能调试 arch test [local] idle进程 首先，要让gdb能够attach上pg的进程，需要修改ptrace的安全策略 shel sudo bash -c 'echo 0 \u003e /proc/sys/kernel/yama/ptrace_scope' 然后，在arch test [local] idle进程执行的代码中打上断点，attach上这个进程，成功进入这个进程开始调试 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#调试的方法"},{"categories":null,"content":" pg的其他特性","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#pg的其他特性"},{"categories":null,"content":" 内存管理常规的程序使用C标准库提供的malloc和free函数管理内存，如下 c OBJ* o = malloc(sizeof(OBJ)); // ... 一些操作 free(o); 这种方式的缺点有 需要跟踪大量小对象的生存期，心智负担大，不仅容易忘记释放内存，还降低了性能 必须保持申请的内存的引用，否则将永远无法回收内存 pg使用MemoryContext管理内存，所有需要在一定时间后才能释放对象的都使用MemoryContext机制。它的优点是 能够满足大量小块内存的情况，又能一次性释放，不必跟踪每一个对象的生存期 不必保持申请的内存的引用 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#内存管理"},{"categories":null,"content":" pg使用的数据结构pg在对sql语句处理的各个阶段都需要存储一些数据，使用的是一种被称为List的数据结构，然而这个称呼实际上不准确，是历史遗留的称呼，因为pg最开始有一部分是用Lisp语言写的，那时使用的是Lisp的cons-cell list，相当于链表 在使用C重写原来的Lisp部分时，由于性能问题，在经过多次重构后，最终使用了动态数组实现了这种可以动态增长的线性表结构，而List这种称呼就遗留了下来 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:2:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#pg使用的数据结构"},{"categories":null,"content":" 一条sql语句执行的全过程单条SQL语句在exec_simple_query函数完成执行的过程，见src/backend/tcop/postgres.c graph LR A[客户端/应用程序] --SQL语句--\u003e B[解析器] B --查询树--\u003e C[重写器] C --重写后的查询树--\u003e D[规划器] D --执行计划--\u003e E[执行器] E --执行结果--\u003e F[客户端/应用程序] 或者 graph LR A[客户端/应用程序] --原始字符串--\u003e B subgraph 核心 B[\"解析（parse）\"] --\u003e C[\"`prepared statement`\"] C --\u003e D[\"bind（绑定）\"] D --\u003e E[\"`portal`\"] E --\u003e F[执行] end F --结果--\u003e G[客户端/应用程序] ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#一条sql语句执行的全过程"},{"categories":null,"content":" 解析解析有三个过程，词法解析，语法解析，分析 解析由pg_parse_query函数完成，见src/backend/tcop/postgres.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#解析"},{"categories":null,"content":" 词法解析flex完成词法解析，只需要定义TOKEN(词法单元)，flex会自动生成C代码完成词法解析的任务。词法解析完成后，词法信息存储在词法树中，并准备传递给语法解析器 flex可以快速定义一个词法解析器，可以使用表则表达式，还能指定匹配优先级 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:1","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#词法解析"},{"categories":null,"content":" 语法解析bison完成语法解析，通过定义生成式，可以精确的描述各种复杂的语法结构（更多语法解析的知识参见编译原理） bison非常灵活，可以将语法定义和动作结合在一起，并支持多种描述语法的方式，例如上下文无关文法（Context-Free Grammar，CFG），扩展巴克斯范式（Extended Backus-Naur Form，EBNF）等 bison将定义语法的源文件转换成C代码，编译后可以得到一个语法解析器。 最终，pg通过调用flex和bison，得到了一个解析树（Parse Tree），这样的结构方便后续对它进行操作。任何错误的SQL语法都会在语法解析阶段被检测并处理 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:2","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#语法解析"},{"categories":null,"content":" 分析检查SQL语句中是否出现了非语法错误，例如试图查询一个不存在的表，或者不存在的字段，这个过程将解析树转换成查询树(Query Tree) 查询树由Query结构体表示(见src/include/nodes/parsenodes.h)，它包括了一次查询的所有信息，例如语句类型，from子句的列表， group by子句的列表，是否有with语句等等 分析由parse_analyze_fixedparams函数完成，见src/backend/parser/analyze.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:3","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#分析"},{"categories":null,"content":" 重写根据预先制定的规则对查询树进行重写 同一个目地的查询，它的关系代数表达式有很多种，然而他们的执行效率是不同的，执行效率高的关系代数表达式具有某些特征。 重写的规则就是执行效率高的关系代数表达式的特征 Postgres支持视图(View)，任何对视图的查询都会在这个阶段被重写成对基表(Base Table)的查询 工具类的语句不会被重写 常见的重写规则有 视图展开（View Expansion） 谓词下推（Predicate Pushdown） 连接消除（Join Elimination） 常量折叠（Constant Folding） 子查询优化（Subquery Optimization） 列裁剪（Column Pruning） 重写由pg_rewrite_query函数完成，见src/backend/tcop/postgres.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:2:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#重写"},{"categories":null,"content":" 规划规划查询器会根据已有的信息估计每条路径的成本，选择成本最低的路径，生成执行计划 例如一个SELECT语句，有两条路径可以到达相同的目标，一是全表扫描，二是利用索引。这时规划查询器会估计每个路径的成本 索引并不是在任何情况下都能加快查询，在查询结果在全表中占比较大时，使用索引的成本更高，因为对于每条记录，利用索引都需要多次IO 规划由pg_plan_query函数完成，见src/backend/tcop/postgres.c 其中，查找所有路径由subquery_planner函数完成，见src/backend/optimizer/plan/planner.c subquery_planner返回了一个PlannerInfo结构体，它表示了规划路径时生成的所有信息 随后，get_cheapest_fractional_path从其中选择出成本最低的路径，见src/backend/optimizer/plan/planner.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:3:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#规划"},{"categories":null,"content":" 执行器执行器拿到执行计划后，构造一个对象，叫做portal，它表示了一次准备好了的执行。对于SELECT语句，它相当于一个打开的游标 准备portal的过程包括 根据查询计划构造portal，由PortalDefineQuery完成 开启portal，由PortalStart完成 设置返回结果的格式，由PortalSetResultFormat完成 打开并设置接受结果的通道 随后，调用PortalRun函数完成最终的执行，见src/backend/tcop/pquery.c ","date":"2023-12-21","objectID":"/posts/postgresql_source/:4:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#执行器"},{"categories":null,"content":" 连接管理pg是一个支持多种操作系统的软件，不同操作系统的对异步IO的支持程度不同，在较新的linux上，它会使用epoll机制 linux的IO机制主要的进化过程如下 graph LR A[常规阻塞IO] --\u003e B[select] B --\u003e C[poll] C --\u003e D[epoll] epoll是一个现代的异步IO机制，它是高性能服务器必不可少的一部分 简单来说，epoll机制有三个主要的函数 c int epoll_create (int __size); // 创建epoll对象，返回一个文件描述符指向epoll实例 // 对监听的文件描述符集合进行操作，可以增加，修改，删除 int epoll_ctl (int __epfd, int __op, int __fd, struct epoll_event *__event); // 调用时阻塞直到监听的文件描述符集合中有事件发生，返回发生事件的文件描述符集合 extern int epoll_wait (int __epfd, struct epoll_event *__events,int __maxevents, int __timeout) pg主进程启动时，会创建一系列的辅助进程，包括后台写进程，压缩进程等等，随后它会创建一个epoll实例，然后进入循环，不断等待epoll事件发生、 处理事件、继续等待 当pg从epoll_wait中返回时，它会处理发生的所有事件，如果是客户端的连接，它会通过BackendStartup函数创建一个进程处理客户端的请求 采用这样的模型，在没有客户端连接时，pg主进程长时间阻塞，几乎不占用CPU，在高负载时，epoll_wait一次能返回多个事件，性能也非常好 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#连接管理"},{"categories":null,"content":" 总结","date":"2023-12-21","objectID":"/posts/postgresql_source/:0:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#总结"},{"categories":null,"content":" C的缺点在pg这个项目中可以看出很多C的缺点，然而有些缺点是编译型语言的，所以这里只列出了相比C++，以及Rust的缺点 抽象程度不及C++，虽然C也有一定的抽象，但是还是不能屏蔽足够的细节，在一个有140万行源码的项目中体现非常明显 缺少命名空间机制，在一个140万行源码中的项目考虑一个不会重复的函数难度还是有点高的，其次导致了标识符的名字普遍非常长 异常处理机制太过原始，使用sigsetjmp和siglongjmp，本质上只是全局goto，不易调试和理解 语言没有常见数据结构的标准库，导致开发一个大型项目的一个必不可少的工作就是重新造轮子 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:1:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#c的缺点"},{"categories":null,"content":" 读后感 text ➜ postgres git:(master) ✗ fd -e c -e h | xargs wc -l | tail -n 1 1562969 total PostgreSQL源码非常大，有150万行，本次课程任务也只是看到了其中冰山一角中的一角，许多内容由于能力有限精力有限，并没有深入研究。 它向我们展示了一个关系型数据库理论的丰富和深厚，以及一个大型开源项目的复杂性，这对我今后的学习和工作都有很大的帮助。 ","date":"2023-12-21","objectID":"/posts/postgresql_source/:2:0","series":null,"tags":["C/C++"],"title":"PostgreSQL源码阅读报告","uri":"/posts/postgresql_source/#读后感"},{"categories":null,"content":"这篇文章是完成docker的get started guide后的总结，见https://docs.docker.com/get-started/ ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#"},{"categories":null,"content":" 前置概念","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#前置概念"},{"categories":null,"content":" docker架构docker采用server-client架构，docker deamon（即dockerd）完成构建容器，运行容器等工作，docker client与docker deamon通过REST API或UNIX socket或网卡通信 docker client可以是 名为docker的cli（命令行接口） docker compose(也是cli) docker desktop（GUI） etc… ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#docker架构"},{"categories":null,"content":" image与containerimage和container的关系类似于类与对象，image可以从docker hub中下载，container是一个image的实例 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#image与container"},{"categories":null,"content":" docker的进程模型在启动容器时，会提供一个命令用于启动主进程，docker的默认一个容器只做一件事而且做到最好，所以一个容器一般只运行一个进程，docker的进程调度器也对此做过针对优化 主进程退出时，docker也会自动停止镜像 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:3:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#docker的进程模型"},{"categories":null,"content":" 安装首先用包管理器安装docker bash sudo pacma -S docker 然后启动dockerd bash sudo systemctl enable docker sudo systemctl start docker 可能出现非root用户无法运行dokcer的情况，可以将当前用户加入docker用户组 注意这实际上是不够安全的，可能会增加一个攻击面 bash sudo gpasswd -a ${USER} docker ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#安装"},{"categories":null,"content":" 使用docker有许多子命令，可以输入docker --help查询所有子命令 子命令也可以通过--help参数查询使用方法，例如docker image --help ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#使用"},{"categories":null,"content":" 工作流1——使用docker hub提供的镜像","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#工作流1使用docker-hub提供的镜像"},{"categories":null,"content":" 启动容器以ubuntu镜像为例 拉取一个镜像到本地 shell docker pull ubuntu 创建一个ubuntu的容器 shell docker create ubuntu docker会随机给这个容器随机生成一个名字，也可以指定名字 shell docker create --name mycontainer ubuntu 创建后，启动容器 shell docker start mycontainer docker提供了一个更简单的命令run来简化这个流程 shell docker run ubuntu # 同样可以通过--name指定容器名 run命令会自动拉取镜像（如果本地没有），创建容器，启动容器 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:1","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#启动容器"},{"categories":null,"content":" 查看容器状态启动ubutnu容器后，可以通过ps查看容器状态 shell docker ps 然而发现并没有结果，这是因为ps只输出运行中的容器 查看全部容器 shell docker ps -a 发现刚刚启动的容器的状态是Exited，这是dokcer的进程模型导致的，因为ubuntu容器的启动命令是/bin/bash，bash默认读取标准输入，而没有提供标准输入，所以bash读取到EOF后退出，主进程退出后容器也自动停止了 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#查看容器状态"},{"categories":null,"content":" 交互式操作前文提及，因为没有提供标准输入，ubutnu镜像立刻退出了，为了避免这种情况，或能够进入ubutnu容器的终端，可以提供标准输入 shell docker run -it ubuntu 进入ubuntu容器的终端后，按下Ctrl+D，bash退出，ubutnu容器也会被停止 -it参数中，-i表示即使没有连接到标准输入也不关闭，-t表示分配一个tty，有了-t，就能将当前终端连接到容器内bash的标准输入、标准输出、标准错误，有了-i，就能在退出容器后（标准输入deattach）后，再次启动（start命令）ubuntu容器后，容器不立刻退出（因为标准输入没有关闭，不会读取到EOF，只是在read系统调用上阻塞） ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:3","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#交互式操作"},{"categories":null,"content":" execexec命令可以在一个运行中的容器内执行命令 先创造出一个运行中的ubutnu容器 text docker run -it --name mycontainer ubuntu # 在容器的bash中按下Ctrl+D或exit docker start mycontainer 再使用exec shell docker exec -it mycontainer bash 又进入了bash，然而这个bash实际上是新开的bash进程，在容器内输入top，可以看到有两个bash，其中一个是通过run创建的，另一个是通过exec创建的 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:4","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#exec"},{"categories":null,"content":" attach如上，为了避免再创建一个bash进程，可以将当前终端的标准输入，标准输出，标准错误连接到容器内 shell docker attach mycontainer 在容器内执行top，发现只有一个bash进程 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:5","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#attach"},{"categories":null,"content":" 管理容器停止容器 shell docker stop mycontainer 删除容器 shell docker rm mycontainer ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:6","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#管理容器"},{"categories":null,"content":" 工作流2——通过镜像协同工作创建一个镜像后，可以分享给其他人，从而解决环境搭建、统一环境等问题 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#工作流2通过镜像协同工作"},{"categories":null,"content":" 创建镜像一个Dockerfile的示例 Dockerfile FROM node:18-alpine WORKDIR /app COPY . . RUN yarn install --production CMD [\"node\", \"src/index.js\"] EXPOSE 3000 随后通过当前目录下的Dockerfile的内容创建镜像 shell docker build -t myimage ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:1","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#创建镜像"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push \u003cmyname\u003e/\u003cmyimage\u003e 其他人可以得到你创建的容器 shell docker pull \u003cmyname\u003e/\u003cmyimage\u003e 或 shell docker run \u003cmyname\u003e/\u003cmyimage\u003e 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#分享给其他人"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push / 其他人可以得到你创建的容器 shell docker pull / 或 shell docker run / 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#使用docker-hub"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push / 其他人可以得到你创建的容器 shell docker pull / 或 shell docker run / 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#发送镜像文件"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push / 其他人可以得到你创建的容器 shell docker pull / 或 shell docker run / 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#第三方镜像托管服务"},{"categories":null,"content":" 分享给其他人 使用docker hub在docker hub注册帐号，然后将镜像上传置docker hub shell docker push / 其他人可以得到你创建的容器 shell docker pull / 或 shell docker run / 发送镜像文件导出镜像到文件 shell docker save -o path/to/image_file.tar myimage 随后将文件发送给其他人，其他人执行 shell docker load -i path/to/image_file.tar 即可得到镜像 第三方镜像托管服务本质和docker hub相同，不过docker hub在国内被墙，而且不同的服务商的商业策略不同，dokcer hub属于典型的freemium模式，即大部分用户免费使用基础功能，小部分用户为高级功能付费。如果使用dokcer开发，可能会遇到不得不向dokcer hub支付的情况。 此外，dokcer hub最流行的原因还是因为它是官方的镜像托管服务，生态最好 私有镜像仓库可以使用开源self-host方案自建私有仓库，不再受dokcer hub的限制，不过也要考虑自建的成本 这应该是企业常用的解决方案 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#私有镜像仓库"},{"categories":null,"content":" docker的其他功能","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#docker的其他功能"},{"categories":null,"content":" 数据持久化","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#数据持久化"},{"categories":null,"content":" volume","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:1","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#volume"},{"categories":null,"content":" bind","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:2","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#bind"},{"categories":null,"content":" dokcer的网络","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#dokcer的网络"},{"categories":null,"content":" 端口映射","date":"2023-12-16","objectID":"/posts/docker-tutorial/:2:1","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#端口映射"},{"categories":null,"content":" docker compose假设需要搭建一个前后端分离的web服务，前端页面由机器上已经安装好的nginx分发，后端服务使用docker部署，此外还需要一个mysql容器提供数据库服务。这需要多个容器协作。前文提到，一个容器只做一件事并做到最好，当需要多个容器协作时，使用docker-cli管理的难度就变大了，docker compose就是为了解决这种问题而出现的 docker compose需要额外安装 shell sudo pacman -S docker-compose dokcer compose使用compose.yaml文件描述每个容器的配置以及他们之间的依赖关系等等 一个compose.yaml实例 yaml services: app: image: node:18-alpine command: sh -c \"yarn install \u0026\u0026 yarn run dev\" ports: - 127.0.0.1:3000:3000 working_dir: /app volumes: - ./:/app environment: MYSQL_HOST: mysql MYSQL_USER: root MYSQL_PASSWORD: secret MYSQL_DB: todos mysql: image: mysql:8.0 volumes: - todo-mysql-data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: secret MYSQL_DATABASE: todos volumes: todo-mysql-data: ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#docker-compose"},{"categories":null,"content":" 一点技巧","date":"2023-12-16","objectID":"/posts/docker-tutorial/:0:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#一点技巧"},{"categories":null,"content":" 关于参数不同的命令行工具都有不同的传参风格，其中docker的参数只能在固定位置，例如dokcer run -it ubuntu的-it不能放到ubuntu后面 ","date":"2023-12-16","objectID":"/posts/docker-tutorial/:1:0","series":null,"tags":["Linux","docker"],"title":"docker 使用方法","uri":"/posts/docker-tutorial/#关于参数"},{"categories":null,"content":"主力使用Linux一段时间后，系统占用的空间总会越来越多。虽然linux的包复用率非常高，甚至有些时候更新，包的大小还会负增长，但这无法阻止用户数据的增长，所以清理 也主要是清理用户数据 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#"},{"categories":null,"content":" 查看磁盘使用率 shell df -h ","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#查看磁盘使用率"},{"categories":null,"content":" 清理包管理器的缓存pacman会自动缓存下载过的软件包，以支持快速重新安装，以及恢复到以前的版本 这样的设计大部分情况都是合理的，而缺点就是 一个软件包，安装了一份，又保留了一份安装包， pacman不会自动删除以前的包 所以archlinux wiki建议定期手动删除包缓存 shell sudo pacman -Sc ","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#清理包管理器的缓存"},{"categories":null,"content":" 清理开发环境的缓存","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#清理开发环境的缓存"},{"categories":null,"content":" jetbrains IDEjetbrains全家桶长期使用会产生不少缓存，可以使用jetbrains toolbox一键清除 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:1:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#jetbrains-ide"},{"categories":null,"content":" VScodeVScode的扩展可以把二进制也打包进去，导致有的扩展并不小，可以选择卸载短期不会使用的扩展 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:2:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#vscode"},{"categories":null,"content":" Python","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#python"},{"categories":null,"content":" anaconda 删除虚拟环境查看conda虚拟环境 shell conda env list 鉴于某些不留requirements.txt的项目的环境真不好装，可以先生成requirements.txt再删除，日后也能恢复 shell conda list -e \u003e requirements.txt 删除某个虚拟环境 shell conda remove --name xxx --all 删除conda缓存conda下载包后会保存tar或zst，下次安装时就不需要重复下载 删除conda包缓存 shell conda clean --all ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#anaconda"},{"categories":null,"content":" anaconda 删除虚拟环境查看conda虚拟环境 shell conda env list 鉴于某些不留requirements.txt的项目的环境真不好装，可以先生成requirements.txt再删除，日后也能恢复 shell conda list -e \u003e requirements.txt 删除某个虚拟环境 shell conda remove --name xxx --all 删除conda缓存conda下载包后会保存tar或zst，下次安装时就不需要重复下载 删除conda包缓存 shell conda clean --all ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#删除虚拟环境"},{"categories":null,"content":" anaconda 删除虚拟环境查看conda虚拟环境 shell conda env list 鉴于某些不留requirements.txt的项目的环境真不好装，可以先生成requirements.txt再删除，日后也能恢复 shell conda list -e \u003e requirements.txt 删除某个虚拟环境 shell conda remove --name xxx --all 删除conda缓存conda下载包后会保存tar或zst，下次安装时就不需要重复下载 删除conda包缓存 shell conda clean --all ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#删除conda缓存"},{"categories":null,"content":" pip缓存pip也会缓存下载过的包，可以手动删除 shell pip cache remove '*' 一般只有简单的项目或者系统解释器会使用pip，删除pip缓存时也要注意环境 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:2","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#pip缓存"},{"categories":null,"content":" 数据文件搞爬虫或者机器学习，经常会生成一些数据文件，有各种训练用的数据或者检查点 另外有些库自带下载数据集的功能，不指定路径就默认在用户的家，然而这些数据集可能之后都不会使用了 不需要的数据可以直接删除，需要的数据，可以选择压缩（对已经压缩过的数据格式，再压缩几乎不会减小大小，然而将零碎文件打包确实能减少大小） ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:3","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#数据文件"},{"categories":null,"content":" Java","date":"2023-12-15","objectID":"/posts/linux-space-release/:4:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#java"},{"categories":null,"content":" maven缓存maven也会缓存下载过的包，如果使用不同版本的JDK，最后缓存的包可能会占据一些空间 shell rm -r ~/.m2/repository 删除缓存后，下次运行maven时会重新下载依赖 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:4:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#maven缓存"},{"categories":null,"content":" gradle缓存gradle作为android官方指定构建工具，它的缓存可能比maven还要多 shell rm -r ~/.gradle/caches/ ","date":"2023-12-15","objectID":"/posts/linux-space-release/:4:2","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#gradle缓存"},{"categories":null,"content":" C/C++","date":"2023-12-15","objectID":"/posts/linux-space-release/:5:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#cc"},{"categories":null,"content":" 编译产物不管是使用autoconf + make还是cmake，最终的构建命令基本都是make 一个大型或者中型项目编译产物可能不小，为了加快构建速度make往往会缓存许多构建中间产物 进入构建目录执行 shell make clean ","date":"2023-12-15","objectID":"/posts/linux-space-release/:5:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#编译产物"},{"categories":null,"content":" 本地安装的软件C/C++的依赖确实很难搞，有些时候会在/usr/local下安装一些软件作为项目的依赖 这些软件往往是下载源码，编译安装的，进入对应的构建目录 shell make uninstall 然而，软件的作者可能没有写uninstall目标，甚至源码目录都被删掉了，这种时候只能手动卸载了 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:5:2","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#本地安装的软件"},{"categories":null,"content":" JS","date":"2023-12-15","objectID":"/posts/linux-space-release/:6:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#js"},{"categories":null,"content":" npmnpm利用包缓存实现自我修复的功能，因此不建议直接清除缓存，相反，npm提供了验证并压缩缓存的方法 text du -h --max-depth=0 ~/.npm npm cache verify du -h --max-depth=0 ~/.npm ","date":"2023-12-15","objectID":"/posts/linux-space-release/:6:1","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#npm"},{"categories":null,"content":" dockerdocker的镜像也会占用不少的空间而且平时很难注意到 查看容器 shell docker ps -a 删除容器 shell docker rm \u003ccontainer-name\u003e 查看本地的镜像 shell docker image list 删除本地的镜像 shell docker image rm \u003cimage-id\u003e ","date":"2023-12-15","objectID":"/posts/linux-space-release/:7:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#docker"},{"categories":null,"content":" 数据库数据库也属于一种死角了。爬取了一些数据，或者从网络下载并导入了一些数据，就会导致数据库占用增大很多 可以选择删除不需要的表，或者不需要的数据库 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:8:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#数据库"},{"categories":null,"content":" 普通软件","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#普通软件"},{"categories":null,"content":" 微信微信在linux并没有一个完美的解决方案，我曾经使用过运行在wine中的微信，时间一长，微信就会不知廉耻的膨胀到几十G，这其中很多是收到的文件 最好的方法是打开微信，删除指定聊天的数据 然而或许我们不需要直接使用微信这样的毒瘤软件，可以选择将微信的消息转发到telegram，telegram不会自动下载文件，文件能在服务器上保存很久， 使用3个月后telegram的占用也只有600M，完爆微信 如何部署微信转发telegrame见https://www.v2ex.com/t/908436 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:1:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#微信"},{"categories":null,"content":" 短期不需要的软件可以查看安装的AUR中的包，删除最近不会使用的（需要的时候总会想起来安装的） ","date":"2023-12-15","objectID":"/posts/linux-space-release/:2:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#短期不需要的软件"},{"categories":null,"content":" chrome网站可以使用localStorage，某些时候可能一个网站就会占用几百M的空间，根据我的实践，占用空间巨大的往往是不太需要的 进入chrome://settings/content/all，点击按照存储的数据大小排序 选择近期不需要的删除 注意也会删除cookie，导致登录的网站退出登录，而且某些网站删除缓存数据后下次进入还会重新生成，导致加载速度变慢 作为一个每天都使用的软件，chrome的缓存不应该删除太多，否则会降低网页加载速度 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#chrome"},{"categories":null,"content":" 一点技巧","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#一点技巧"},{"categories":null,"content":" Download目录Download目录全是用户数据，可以按照大小排序，然后删除比较大，又不需要的 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:1:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#download目录"},{"categories":null,"content":" 仓库盘很多没有的文件并不是没有价值，可以买一块机械硬盘当作仓库盘，全部扔里面 我曾经在国内国外众多网盘中挑选了很久，最终选择了机械硬盘，因此我并不推荐使用网盘作为第一备份措施 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:2:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#仓库盘"},{"categories":null,"content":" 打包与压缩根据文件系统的知识，磁盘是按块管理的，这就导致不可避免的出现存储空间的浪费，对于大量的小文件，这样的浪费更加明显 仓库盘中的文件就满足这种特征，可以打包然后压缩，减少存储占用 打包会减少很多因为按块管理造成的浪费，压缩的效果不确定，因为对文本文件，压缩效果显著，而对已经压缩过的文件，压缩后几乎不会减小大小 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:3:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#打包与压缩"},{"categories":null,"content":" 删除孤儿包 shell sudo pacman -Rns $(pacman -Qtdq) 大部分时候都没有孤儿包，偶尔删除一下即可 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:4:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#删除孤儿包"},{"categories":null,"content":" 关于缓存根据cache的定义，它的作用是加快存取速度，从前面提到的很多软件的缓存可以看出它的使用场景 在实践中cache（缓存）和buffer（缓冲）往往是混用的，缓冲的目地是缓解通过接口相连的两个系统之间速度不对等情况，实践中缓冲往往也能发挥缓存的作用 缓存删除后不可避免会造成速度变慢，一个软件正常运行中也会自动产生缓存，那么为什么要删除缓存呢？ 在我看来，可以套用操作系统的知识解释 在计算机中的缓存往往有两个限制，一个是失效时间，一个是缓存容量 例如TLB，绝大部分替换策略都会导致一个TLB表项无法永远保留在TLB中，而TLB作为硬件实现也一定是固定容量而且容量有限 然而，在软件层面的缓存就不太一样了，软件管理缓存，主要是通过指定缓存容量和缓存失效时间，策略大概有 放仍不管，仍其增长 提供管理缓存的接口供用户使用，但不主动操作缓存，将管理缓存的部分工作交给用户 通过定时任务或者后台进程定期清理 这三种方式都能找到对应的软件，很遗憾的是，采用第三种方式的软件很少，这也就导致了用户必须承担管理缓存的工作，否则他就需要承担购买更多存储器的工作 缓存替换策略完成的工作是保证在缓存中的是最常用的，而用户定期清理缓存与缓存替换策略完成的工作类似，在定期的删除中，那些低频使用或者短期内高频使用的缓存最终都被删除了 ","date":"2023-12-15","objectID":"/posts/linux-space-release/:0:0","series":null,"tags":["Linux"],"title":"Linux释放磁盘空间","uri":"/posts/linux-space-release/#关于缓存"},{"categories":null,"content":"最近在阅读coreutils，发现很多有意思的部分，比如哈希表的链表实现 ","date":"2023-10-14","objectID":"/posts/coreutils_hash/:0:0","series":null,"tags":["C/C++"],"title":"coreutils之hash table","uri":"/posts/coreutils_hash/#"},{"categories":null,"content":" 字符串哈希函数coreutils中内置了对字符串的哈希函数 c size_t hash_string (const char *string, size_t n_buckets) { size_t value = 0; unsigned char ch; for (; (ch = *string); string++) value = (value * 31 + ch) % n_buckets; return value; } 用法为 c char* str = \"a demo string\"; size_t hash_code = hash_string(str, 100); 可以看出计算哈希的部分就是 c for (; (ch = *string); string++) value = (value * 31 + ch) % n_buckets; 一个好的哈希函数，应该做到把输入数据均匀的映射到哈希表的所有槽，也就是每个槽的概率应该是接近的。 还可以说，一个好的哈希函数应该充分受到输入数据的每一位的影响，最好的情况就是，当输入数据的其中一位发生改变，计算出的哈希码中多位发生改变 31这个数字非常巧妙，因为 $$ 31 = 32 - 1 = 2^0 + 2^1 + 2^2 + 2^3 + 2^4 $$ 而计算机是二进制的，也就是说a * pow(2, x)等于a \u003c\u003c x 假设value==19，那么value * 31可以表示为 text 10011 10011 10011 10011 10011 —————————— 1001001101 可以看出value * 31每一位都会受到value中每一位的影响，value中任意一位发生变动，value * 31每一位也必须重新计算。然后value * 31 + ch会添加上ch造成的影响，(value * 31 + ch) % n_buckets约束结果的范围 取余操作肯定影响了哈希码的随机性，假设n_buckets==8，value * 31 + ch就只会保留低三位，大大降低了哈希码的随机性. 我的理解是，当哈希表长度小时，每个槽插入数据的概率也会增加。例如哈希表长为10，那么哈希表中每个槽的插入数据概率为$\\frac{1}{10}$，当插入两个数据时碰撞的概率为$\\frac{10}{10\\times10}=\\frac{1}{10}$，当哈希表长为11时， 插入两个数据碰撞的概率为$\\frac{11}{11\\times11}=\\frac{1}{11}$，当然当插入数据越多时，两者差距会越来越大。所以哈希表规模较小时碰撞本来就是很容易发生的。而我们关注的也只是规模较大时哈希表的性能，规模较小时哈希表和其他查询结构也没有明显优势 ","date":"2023-10-14","objectID":"/posts/coreutils_hash/:1:0","series":null,"tags":["C/C++"],"title":"coreutils之hash table","uri":"/posts/coreutils_hash/#字符串哈希函数"},{"categories":null,"content":"为了完成课程的任务，折腾了很久终于搞好了VMware。 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:0:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#"},{"categories":null,"content":" 安装VMwareVMware分为个人使用免费的player和商用付费的workstation，archlinux可以在aur中找到vmware并安装。 非archlinux可以在官网找到安装包 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:0:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#安装vmware"},{"categories":null,"content":" 配置VMware安装后还需要配置很多东西才能使用 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:0:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#配置vmware"},{"categories":null,"content":" 安装linux-headersarchlinux的更新是滚动更新，而更新了linux内核后需要重启才能完全生效。所以就会出现pacman能够查到已经安装了linux-headers包，但是仍然无法使用VMware的情况 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:1:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#安装linux-headers"},{"categories":null,"content":" 加载内核模块需要加载vmw_vmci和vmmon这两个模块 bash sudo modprobe -a vmw_vmci vmmon 然而很有可能无法加载，输出为找不到模块，这是因为对于比较新的内核，需要自己编译这两个模块 找到这个仓库，拉下来，根据INSTALL中的方法，首先根据workstation的版本，切换到对应分支 bash git clone https://github.com/mkubecek/vmware-host-modules cd vmware-host-modules git checkout workstation-17.0.2 然后开始编译，编译完成后安装 bash make sudo make install 然后重新加载模块 bash sudo modprobe -a vmw_vmci vmmon ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:2:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#加载内核模块"},{"categories":null,"content":" 设置网络执行 bash sudo systemctl start vmware-networks.service 有可能会失败，根据systemctl的日志，需要先配置网络 aur中的VMware workstation包将vmware-netcfg软链接到/usr/bin所以可以直接使用 bash sudo vmware-netcfg 在弹出的界面中配置网络 设置开机自启，再重启 bash sudo systemctl enable vmware-networks.service reboot 至此就完成了最基础的设置，已经可以在VMware虚拟机中连接网络了 参考： https://communities.vmware.com/t5/Workstation-2023-Tech-Preview/Linux-Kernel-6-5-rc-vmmon-compile-fails/td-p/2981003 https://github.com/mkubecek/vmware-host-modules/issues/11 https://aur.archlinux.org/packages/vmware-workstation https://segmentfault.com/a/1190000042268631 ","date":"2023-09-24","objectID":"/posts/linux-vmware-setup/:3:0","series":null,"tags":["Linux"],"title":"Linux使用VMware","uri":"/posts/linux-vmware-setup/#设置网络"},{"categories":null,"content":"IDEA更新后以前的项目不知道为什么不能直接运行了，新建项目后也不会自动创建运行配置了，为了解决这个问题踩了不少坑 声明一下所说的运行配置是指Run/Debug Configuration ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:0:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#"},{"categories":null,"content":" java项目的构建众所周知java一般是用maven或者gradle构建的，他们都能做到管理依赖、管理构建任务、编译等过程。 在idea的运行配置中，也可以选择gradle和maven，然后如果你选择了它们作为运行配置，多半会看到这个界面 然而一般来说希望看到的应该是这个 实际上，maven和gradle作为构建工具，命令行调用时可以传入不同参数作为task，构建工具不负责运行 ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:0:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#java项目的构建"},{"categories":null,"content":" 如何设置idea的运行配置首先我们要清楚idea支持三种方式 IDEA Build maven gradle 和idea定位相同的eclipse也有eclipse build，不推荐使用IDE特有的方式构建，因为他们往往是跟IDE绑定的，无法直接在命令行使用，不如专业的构建工具成熟 一个新的IDEA项目，需要首先指定java SDK版本 在设置中找到Project Structure，配置SDK 点击File-settings，找到Build,Execution, Deployment - Build Tools - Gradle 把Build and run using和Run test using改成IntelliJ IDEA 使用maven可以跳过这一步 创建一个’Run/Debug Configuration’，选择JDK、main方法入口，保存 到这一步已经能够实现这样的效果 ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:0:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#如何设置idea的运行配置"},{"categories":null,"content":" Tips在使用第三方库的时候又踩了一个坑，整理一下java项目使用第三方库的流程 在maven中心仓库上搜索想要的包 指定版本后，直接复制配置，粘贴到pom.xml或build.gradle即可 pom.xml或build.gradle改变后，IDEA会重新同步它们的更新，然后可以看到新加入的包出现在文件管理器的’External Libraries’中 至此就可以根据包名使用了。然而比较坑的一点就是包在maven中心仓库的坐标并不总是他们的包名，需要确定包名 按理来说，直接找到包的文档网站，能够看到一些代码片段有这样的语句 java import com.squareup.okhttp.OkHttpClient; 然而实际上，文档中的代码片段几乎不会有这样的语句 ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:0:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#tips"},{"categories":null,"content":" 如何确定包名首先已经知道了这个包的俗称，根据俗称可以在maven中心仓库搜索得到这个包的坐标，然后就能下载到这个包的jar文件。 根据jar的规范，解压jar包后，在META-INF/MANIFEST.MF中有这个jar包的元数据。例如okhttp包，META-INF/MANIFEST.MF内容为 text Manifest-Version: 1.0 Automatic-Module-Name: okhttp3 可以知道包名为okhttp3，而不是com.squareup.okhttp！ ","date":"2023-09-20","objectID":"/posts/idea-java-configuration/:1:0","series":null,"tags":["Java","Jetbrains IDE"],"title":"Idea配置java项目","uri":"/posts/idea-java-configuration/#如何确定包名"},{"categories":null,"content":"之前安装archlinux，随便配置的中文字体，显示中文时总有一些奇奇怪怪的字形，最近翻了archlinux的文档，把字体配置搞清楚了 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#"},{"categories":null,"content":" 字体是什么简单来说，字体告诉屏幕如何显示一个字，字体常见的格式有Bitmap和Outline，大致区别就是Bitmap直接指定了每一个像素，有点类似于字模，而Outline指定的是字的轮廓，至于具体怎么显示还需要根据屏幕分辨率，字号等信息来计算。很明显，Outline格式是更加现代的格式，所以此文就忽略Bitmap Outline格式有以下几种格式 PostScript fonts，由adobe发明 TrueType，由Apple和Microsoft发明，扩展名是ttf OpenType，由Microsoft发明，相当于TrueType的进阶版，扩展名是otf或ttf 实际使用中，TrueType是最常见的 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体是什么"},{"categories":null,"content":" 字体如何安装只需要把字体文件放到指定目录下，就完成了安装。 指定目录有哪些，可以查看/etc/fonts/fonts.conf 例如 xml \u003c!-- Font directory list --\u003e \u003cdir\u003e/usr/share/fonts\u003c/dir\u003e \u003cdir\u003e/usr/local/share/fonts\u003c/dir\u003e \u003cdir prefix=\"xdg\"\u003efonts\u003c/dir\u003e \u003c!-- the following element will be removed in the future --\u003e \u003cdir\u003e~/.fonts\u003c/dir\u003e 可见指定路径为/usr/share/fonts, /usr/local/share/fonts，$HOME/.local/share/fonts。不同的路径有不同的作用范围 安装字体后，为了快速生效，可以使用fc-cache --force强制刷新字体缓存 更好的办法是使用包管理器安装字体 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体如何安装"},{"categories":null,"content":" 字体模块字体模块分为匹配模块和配置模块 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体模块"},{"categories":null,"content":" 字体配置模块字体配置模块简单来说就是一堆xml文件，遵循特定的语法。 可以配置字体目录，字体配置的目录，字体缓存的目录，还能配置一些特殊的操作，例如 xml \u003c!-- Accept alternate 'system ui' spelling, replacing it with 'system-ui' --\u003e \u003cmatch target=\"pattern\"\u003e \u003ctest qual=\"any\" name=\"family\"\u003e \u003cstring\u003esystem ui\u003c/string\u003e \u003c/test\u003e \u003cedit name=\"family\" mode=\"assign\" binding=\"same\"\u003e \u003cstring\u003esystem-ui\u003c/string\u003e \u003c/edit\u003e \u003c/match\u003e \u003c!-- Load local system customization file --\u003e \u003cinclude ignore_missing=\"yes\"\u003econf.d\u003c/include\u003e \u003c!-- Font cache directory list --\u003e \u003ccachedir\u003e/var/cache/fontconfig\u003c/cachedir\u003e \u003ccachedir prefix=\"xdg\"\u003efontconfig\u003c/cachedir\u003e ","date":"2023-09-18","objectID":"/posts/linux-font/:1:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体配置模块"},{"categories":null,"content":" 字体匹配模块字体有很多属性，例如family，familylang，weight，spacing等等。字体匹配做的就是： 当请求一个字体时，计算请求的字体和所有已有字体的距离，返回距离最小的字体。 距离就是根据属性计算得出的。这样可以保证请求一个字体时，不管计算机上有没有这个字体，都能返回一个字体。 当计算机上有多个满足请求partten的字体时，仍然只有一个字体返回，这就可能导致返回的字体不是用户希望的字体。 例如，Noto Sans CJK有中文，日文，韩文。当请求Noto Sans CJK时，以下四个字体都满足请求pattern（假设locale设置为en_US） Noto Sans CJK SC Noto Sans CJK TC Noto Sans CJK JP Noto Sans CJK KR 然而因为Noto Sans CJK JP的地区代号JP在CN之前，导致某些字体使用Noto Sans CJK JP渲染。例如下图的关和门都使用了Noto Sans CJK JP字体 这种情况可以通过设置字体优先级解决,在~/.config/fontconfig/conf.d/perfer.conf写入 xml \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE fontconfig SYSTEM \"fonts.dtd\"\u003e \u003cfontconfig\u003e \u003calias\u003e \u003cfamily\u003esans-serif\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003calias\u003e \u003cfamily\u003emonospace\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans Mono CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003c/fontconfig\u003e 然后刷新字体缓存即可生效 需要注意的是，由于linux字体的配置是分布在不同地方的，配置可能有重复的情况发生。 例如假设我希望使用JetBrains Mono作为等宽字体，修改~/.config/fontconfig/conf.d/perfer.conf为 xml \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE fontconfig SYSTEM \"fonts.dtd\"\u003e \u003cfontconfig\u003e \u003calias\u003e \u003cfamily\u003esans-serif\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003calias\u003e \u003cfamily\u003emonospace\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eJetBrains Mono\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003c/fontconfig\u003e 并没有生效，因为在~/.config/fontconfig/fonts.conf中有这么一段 xml \u003calias\u003e \u003cfamily\u003esans-serif\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e \u003calias\u003e \u003cfamily\u003emonospace\u003c/family\u003e \u003cprefer\u003e \u003cfamily\u003eNoto Sans Mono CJK SC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK TC\u003c/family\u003e \u003cfamily\u003eNoto Sans Mono CJK JP\u003c/family\u003e \u003c/prefer\u003e \u003c/alias\u003e 所以修改linux配置文件时，应该遵循一个原则，就是先从/etc下的配置文件寻找。因为/etc下的配置文件是第一个被加载的， 这些配置文件做的事往往有 完成一些默认配置 include更多的配置文件 规定用户配置文件应该放在哪里 /etc下的配置文件的重要性非常高。因为在网上查阅有关配置文件的资料时，往往受限于版本、发行版的不同、软件来源等方式，网上的资料不一定管用。而/etc不仅仅是软件的配置文件，还能在一定程度上充当软件的说明书，它的作用有点类似于gcc的头文件，是编译器最高优先级的接口定义文档。 ","date":"2023-09-18","objectID":"/posts/linux-font/:1:1","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#字体匹配模块"},{"categories":null,"content":" 关于字体在字体非常多的属性中，有几个属性是最突出的 ","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#关于字体"},{"categories":null,"content":" 衬线与非衬线衬线就是serif，非衬线就是sans serif，衬线是字形笔画的起始段与末端的装饰细节部分。 从最近十几年来各大互联网公司的logo演变可以看出来，非衬线越来越受欢迎。推荐正文部分使用非衬线字体，能够缓解视觉压力 ","date":"2023-09-18","objectID":"/posts/linux-font/:1:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#衬线与非衬线"},{"categories":null,"content":" 等宽与比例所谓等宽，也就是每一个字符的宽度相等，在视觉上每一行能够对齐，这是一种编程友好字体，几乎所有IDE都默认使用等宽字体（如果有IDE默认使用非等宽字体，赶紧抛弃它吧！） 等宽字体往往指的是英文ASCII字符等宽，还有一种字体能够做到中文字符和英文等宽，这种字体在中英文混合排版的时候非常方便 ","date":"2023-09-18","objectID":"/posts/linux-font/:2:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#等宽与比例"},{"categories":null,"content":" CJKCJK就是Chinese Japan Korea的缩写，表示中日韩文字。作为一个archlinux中国用户，即使locale设置为en_US，也不可避免的要使用CJK字体 ","date":"2023-09-18","objectID":"/posts/linux-font/:3:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#cjk"},{"categories":null,"content":" Emoji众所周知，Unicode字符集是包括emoji的。网上下载的字体文件是一系列Unicode字符的字形的集合，也就是说，一个普通的字体很有可能是没有emoji的。linux在font fallback后会发现没有字体能够显示这个emoji，于是就是显示成一个方框。需要显示emoji只需要安装emoji字体即可 ","date":"2023-09-18","objectID":"/posts/linux-font/:4:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#emoji"},{"categories":null,"content":" Patched fontPatched font即为打了补丁的字体，有一些TUI(Textual User Interface)可能需要这些字体，用于显示一些特殊的符号 ","date":"2023-09-18","objectID":"/posts/linux-font/:5:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#patched-font"},{"categories":null,"content":" 小技巧","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#小技巧"},{"categories":null,"content":" 解决WPS Office打开文档时字体显示过粗 可以鼠标选中显示异常的字体，发现字体是微软雅黑，我的电脑上没有安装微软雅黑，所以fallback到了其他字体，然而使用其他字体显示微软雅黑多少有点瑕疵。例如字体加粗部分就会显得非常粗 解决办法有两个 如果安装了双系统，可以挂载windows分区，然后把windows的C:\\Windows\\Fonts\\目录软链接到/usr/share/fonts/WindowsFonts/ 安装windows字体 因为windows字体非常多，可能导致一句中文使用了不同字体渲染，非常丑，可以指定字体优先级来避免 office中文用户常常会有使用了各种字体的office文档，每个都下载不仅占用空间，而且往往只能知道字体的中文名而不知道它的英文名，不方便从AUR安装，手动安装也有点麻烦 解决方案见archlinux中文维基，将freetype2降级即可 ","date":"2023-09-18","objectID":"/posts/linux-font/:1:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#解决wps-office打开文档时字体显示过粗"},{"categories":null,"content":" 查看fallback到的字体使用Chrome浏览器查看，打开网页https://c.runoob.com/front-end/61/在线编辑HTML，在CSS中指定字体，然后F12打开浏览器开发者工具，选中元素，点击Computed，就能看到实际渲染使用的字体 ","date":"2023-09-18","objectID":"/posts/linux-font/:2:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#查看fallback到的字体"},{"categories":null,"content":" fc-*系列工具","date":"2023-09-18","objectID":"/posts/linux-font/:0:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#fc-系列工具"},{"categories":null,"content":" fc-list执行 shell fc-list 可以输出计算机上所有字体 bash fc-list :lang=zh 可以输出中文字体 bash fc-list :spacing=100 可以输出所有等宽字体 ","date":"2023-09-18","objectID":"/posts/linux-font/:1:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#fc-list"},{"categories":null,"content":" fc-match执行 bash fc-match mono 可以根据mono请求字体，这实际上是调用了字体匹配模块的功能。 bash fc-match -s mono 可以输出所有满足请求的字体并排序 需要debug时，可以设置FC_DEBUG环境变量 bash FC_DEBUG=1 fc-match mono FC_DEBUG的每个位都有约定的含义，见https://man.archlinux.org/man/fonts-conf.5 ","date":"2023-09-18","objectID":"/posts/linux-font/:2:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#fc-match"},{"categories":null,"content":" fc-cache bash fc-cache --force 强制重新生成字体缓存，在修改了字体配置或安装了新字体后执行，可以立即生效 ","date":"2023-09-18","objectID":"/posts/linux-font/:3:0","series":null,"tags":["Linux","Linux Desktop","Font"],"title":"Linux字体","uri":"/posts/linux-font/#fc-cache"},{"categories":null,"content":"这篇文章是wikipedia的recsys词条的翻译以及简化版本，原文见https://en.wikipedia.org/wiki/Recommender_system recsys(推荐系统)的种类 collaborative filtering（协同过滤）根据相似用户的行为为用户推荐内容，推荐理由是“与你相似的人都喜欢xx”， 缺点是需要大量用户行为数据，冷启动慢 content-based filtering（基于内容过滤）给物打上标签，推荐具有相似标签的物，推荐理由是“与你喜欢的xx有关”， 少量用户行为数据即可启动，但是只能推荐相似的物，无法推荐新物 knowledge-based systems ","date":"2023-08-04","objectID":"/posts/recsys-summary/:0:0","series":null,"tags":["Mechine Learning"],"title":"推荐系统简单介绍","uri":"/posts/recsys-summary/#"},{"categories":null,"content":" collaborative filtering协同过滤的假定是 过去相似的用户，在未来也是相似的 过去用户喜欢的物，在未来也是喜欢的 推荐系统只使用了不同用户对不同物的评分，通过使用评分，推荐系统定位用户和物，使用邻居生成推荐 协同推荐的分类 memory-based 基于内存的协同过滤，例子是user-based algorithm(基于用户的推荐算法) model-based，基于模型的协同过滤，例子是matrix factorization（矩阵分解） 优点是不需要机器分析内容（使用NLP分析文本并打上标签等等），能准确推荐复杂的物，缺点是需要大量用户行为数据，冷启动慢 判断用户的相似度使用的算法有 k-nearest neighbors(kNN算法) Pearson correlation coefficient(皮尔逊相关系数) approximate nearest neighbors(ANN,近似最近邻算法) 协同过滤的缺点 冷启动 新用户和新物缺少数据，无法推荐 可扩展性 随着用户和物的增加，计算量增加，大型推荐系统需要很高的算力 稀疏性 用户和物的数量都很大，但一个用户只会和极少的物交互，数据很稀疏 item-to-item collaborative filtering（基于物的协同过滤）也是协同过滤的一个例子，它的推荐理由是“喜欢x的人也喜欢y ” ","date":"2023-08-04","objectID":"/posts/recsys-summary/:0:0","series":null,"tags":["Mechine Learning"],"title":"推荐系统简单介绍","uri":"/posts/recsys-summary/#collaborative-filtering"},{"categories":null,"content":" Content-based filtering基于内容过滤的推荐系统使用的数据是物的特征（打的标签）和用户的偏好资料， 它将推荐问题转换成了将一群用户分为喜欢某特征和不喜欢某特征的分类问题 为了创建用户偏好资料，推荐系统集中于两种信息 xxxxxxxxxx fn(5); 118e: bf 05 00 00 00 mov $0x5,%edi 1193: e8 b1 ff ff ff call 1149 \u003c_Z2fni\u003etext 用户与推荐系统交互的历史 为了获取物的特征，推荐系统常用TF-IDF（又称向量空间表示）算法 推荐系统基于权重向量创建用户的偏好资料，权重向量中的每一个权重表达了每个特征对用户的重要性。计算权重向量的方法有： 取用户有关的物的权重向量的平均值，还有贝叶斯分类器，聚类分析，决策树，神经网络 基于内容过滤的一个关键问题是，推荐系统不能从一个内容源中学习到用户的偏好然后在其他类型的内容中使用学习到的用户偏好。例如 推荐系统从用户阅读新闻的行为中学习到了用户的偏好，但不能在推荐音乐，视频，产品等物时使用这些偏好。为了克服这个问题， 大多数基于内容过滤的系统都会使用混合式的系统 ","date":"2023-08-04","objectID":"/posts/recsys-summary/:0:0","series":null,"tags":["Mechine Learning"],"title":"推荐系统简单介绍","uri":"/posts/recsys-summary/#content-based-filtering"},{"categories":null,"content":" Hybrid recommender systems大多数推荐系统都采用混合式的方案，结合协同过滤、基于内容过滤等等。 混合式的方案有几种实现方法，可以让不同的推荐系统分别生成推荐然后将结果合并，也可以将协同过滤的能力加入到 基于内容过滤的系统中（或者相反） 混合式的推荐系统的准确度一般比单一的推荐系统高，而且能够克服单一推荐系统的缺点，例如冷启动和稀疏性问题 一些混合式的技术有 Weighted 将不同推荐系统给一个物的评分求加权平均值，仅仅通过数值的方法来结合不同的推荐系统 Switching 在不同的推荐系统中切换，采用所选的系统 Mixed 将不同推荐系统的结果合并 Feature Combination 将来自不同知识源的特征结合起来，输入给一个推荐系统 Feature Augmentation 计算一个或一组特征，其结果作为下一个推荐系统的输入 Cascade 不同推荐系统被赋予不同的优先级，当高优先级的推荐系统给一些物打分相同时，低优先级的推荐系统继续打分，改变评分相同的情况 Meta-level 一个推荐系统的输出作为另一个推荐系统的输入 reference: [1] wikipedia, Recommender system https://en.wikipedia.org/wiki/Recommender_system ","date":"2023-08-04","objectID":"/posts/recsys-summary/:0:0","series":null,"tags":["Mechine Learning"],"title":"推荐系统简单介绍","uri":"/posts/recsys-summary/#hybrid-recommender-systems"},{"categories":null,"content":" 需求我有两个外置屏幕，一个1K 23.8英寸，一个1K 21英寸，同时内置屏幕在1K和2K之间（2240x1400）但只有13英寸，所以需要这个配置： 内置屏幕：缩放比例150%，字体DPI 144 外置屏幕1：缩放比例100%，字体DPI 96 然后残念的是KDE并不支持同时连接不同显示器并设置不同的缩放比例和分辨率，所以我采用的设置是 接上外置屏幕时，关闭内置屏幕，设置缩放比例100%，字体DPI 96 断开外置屏幕时，设置缩放比例150%，字体DPI 144 然而每次设置，都需要打开KDE systemsetting，修改设置后注销，很麻烦，再加上我使用的主题问题（见末尾），需要在不同字体DPI下设置不同的window decoration，而设置window decoration只能修改配置文件。当接上或者断开外置屏幕时，需要改很多设置，非常麻烦！ 于是我就想，能不能写一个脚本，自动化这个过程呢？ ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:0:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#需求"},{"categories":null,"content":" 踩坑过程","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:0:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#踩坑过程"},{"categories":null,"content":" xrandr在google搜索 kde change scale command line，大部分内容都是xrandr，这东西并没有满足我的需求，使用xrandr --output DisplayPort-0 --scale 1.5x1.5后，发现它是将屏幕的帧缩放后输出，它会直接修改屏幕的逻辑分辨率，而我想要的是保持逻辑分辨率在物理分辨率（1K）的情况下，缩放显示内容 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:1:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#xrandr"},{"categories":null,"content":" kscreen-doctor又发现能够通过kscreen-doctor output.eDP.scale.1,5修改指定屏幕的缩放比例，然而并没有效果，查阅文档后发现这个命令只能对wayland起作用 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:2:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#kscreen-doctor"},{"categories":null,"content":" QT_SCREEN_SCALE_FACTORS仔细想了一下，可能缩放比例这个概念就不太正确，分辨率并没有问题，KDE只是一个桌面环境，在KDE修改了缩放比例后，它会以某种方式通知GUI程序，告诉他们应该采用什么样的缩放比例，然后GUI程序就能根据缩放比例调整按钮，文字，图标的大小，达到一个与屏幕大小观感协调的效果。查阅了archlinux wiki后，我发现了这个环境变量QT_SCREEN_SCALE_FACTORS bash ➜ ~ env | grep QT QT_AUTO_SCREEN_SCALE_FACTOR=0 QT_IM_MODULE=fcitx QT_SCREEN_SCALE_FACTORS=eDP=1;DisplayPort-0=1;DisplayPort-1=1; QT会遵循这个环境变量调整缩放比例，所以修改这个环境变量就能达到目的了，于是我把这个环境变量保存在~/.xprofile，但重新登录后发现没有起作用，发现环境变量并没有被修改 考虑了一下，应该是修改后，又被KDE修改了，因为缩放比例这个设置保存在KDE中，KDE会根据这个设置去修改底层的一些设置，所以还是要从KDE入手 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:3:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#qt_screen_scale_factors"},{"categories":null,"content":" 寻找KDE设置文件在网上搜索能知道KDE的配置文件都在~/.config/下，然而具体是哪一个，网上并不能搜索到。于是我先按照名字找到了~/.config/xsettingd/xsettingd.conf，我发现有一个选项在修改缩放比例后会改变 shell ➜ ~ cat ~/.config/xsettingsd/xsettingsd.conf Gdk/UnscaledDPI 147456 Gdk/WindowScalingFactor 1 Net/ThemeName \"Breeze\" Gtk/EnableAnimations 1 Gtk/DecorationLayout \"icon:minimize,maximize,close\" Gtk/PrimaryButtonWarpsSlider 0 Gtk/ToolbarStyle 3 Gtk/MenuImages 1 Gtk/ButtonImages 1 Gtk/CursorThemeSize 24 Gtk/CursorThemeName \"breeze_cursors\" Net/IconThemeName \"Win11\" Gtk/FontName \"Noto Sans, 8\" 我发现Gdk/UnscaledDPI这个选项，当缩放比例是100%时为98304，当缩放比例为150%时为147456，而Gdk/WindowScalingFactor这个选项并不会改变，猜测它就是xrandr中的scale选项，于是我尝试修改这个选项，发现也没有起作用。 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:4:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#寻找kde设置文件"},{"categories":null,"content":" 监控读写文件根据我的猜想，在KDE修改设置后，重新登录或者重启就能够生效，一定是把修改保存到了文件，然后启动的时候根据配置文件来设置一些选项，于是我就考虑监控文件读写，进而找到配置文件 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:5:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#监控读写文件"},{"categories":null,"content":" 通过文件修改时间监控文件写入文件写入后，文件的修改时间会更新，于是我利用find命令查找文件修改时间满足一个范围内的文件 shell ➜ ~ #!/bin/bash # 定义要监测的目录 directory=~/.config # 转换路径为绝对路径 directory=$(realpath \"$directory\") # 获取脚本启动时的时间戳 script_start_time=$(date +%s) # 创建一个关联数组来存储文件的修改时间 declare -A mod_times while true; do # 使用find命令查找目录下所有在脚本启动后被写入的文件 while IFS= read -rd '' file; do current_mod_time=$(stat -c %Y \"$file\") # 获取文件的修改时间是否在脚本启动之后 if [ \"$current_mod_time\" -gt \"$script_start_time\" ]; then # 如果文件在之前的记录中不存在或修改时间不同，则输出文件路径 if [[ ! \"${mod_times[$file]}\" || \"${mod_times[$file]}\" -ne \"$current_mod_time\" ]]; then echo \"文件已被修改：$file\" mod_times[\"$file\"]=$current_mod_time fi fi done \u003c \u003c(find \"$directory\" -type f -print0) sleep 1 # 每秒检查一次done 启动这个脚本，然后打开KDE systemsetting，修改缩放比例，找到一些文件被修改了，其中有~/.config/kcmfonts 它的内容如下 shell ➜ ~ cat ~/.config/kcmfonts [General] forceFontDPI=0 根据文件的修改时间，文件名的提示，还有文件内容的提示，只需要修改这个配置文件，就能达到修改字体DPI的目的 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:5:1","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#通过文件修改时间监控文件写入"},{"categories":null,"content":" 更简单的做法在reddit上看到了另一个做法，修改设置后按照修改时间对文件进行排序，找到最新修改的文件。这个方法确实很简单，我找到了~/.config/kdeglobals这个文件，而且非常巧妙的是，它有一段内容为 text [KScreen] ScaleFactor=1.5 ScreenScaleFactors=eDP=1;DisplayPort-0=1;DisplayPort-1=1; 根据这个group名和key名，可以确定ScaleFactor就是最终的答案了 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:5:2","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#更简单的做法"},{"categories":null,"content":" 修改配置文件最开始我使用sed修改文件，缺点就是 写sed很麻烦 担心改错，所以最开始不敢写回文件 保存修改很麻烦，需要写入一个临时文件，然后再把临时文件重命名为原文件 在reddit上看到有一个命令是kwriteconfig5，是KDE提供的用来修改那些’hidden’（没有提供GUI配置选项）的配置选项，它明显比直接修改文件要方便而且安全 要修改缩放比例，只需要kwriteconfig5 --file ~/.config/kdeglobals --group KScreen --key ScaleFactor 1.5 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:6:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#修改配置文件"},{"categories":null,"content":" 命令行注销也许是X11或者QT的缺陷，修改了缩放比例和字体DPI后，只能对新启动的应用生效，所以通常会注销然后重新登录，所以脚本修改这些设置后，也应该注销 然而这个注销就麻烦了，命令行，注销，一看到这两个词，我就在想，这不就是一个Ctrl+D或者exit就解决的问题吗。然而，这个是ssh会话中使用的，而我想要注销的应该是桌面会话 在网上找到了一些注销方法，有注销X会话的，直接让屏幕卡住了，我的猜想是，X是GUI的底层，而KDE作为桌面环境明显在它之上，也就是说应该注销KDE的会话 在网上找到了这个方法qdbus org.kde.ksmserver /KSMServer logout 0 0 0，非常有用，是通过类似进程间通信的方式通知KDE注销，跟手动注销的功能完全一模一样 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:7:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#命令行注销"},{"categories":null,"content":" 检测外置屏幕连接状态脚本需要检测现在使用的是什么屏幕，然后作出不同的设置 为了简单，我就只检测屏幕连接的数量，如果连接的屏幕数量为2，就认为外置屏幕已经连接，为1就认为外置屏幕已经断开 脚本如下 shell xrandr --listactivemonitors | awk '/Monitors:/ {print $2}' ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:8:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#检测外置屏幕连接状态"},{"categories":null,"content":" 最终成果 shell #!/usr/bin/bash SCALE=$(xrandr --listactivemonitors | awk '/Monitors:/ {print $2}') THEME_CONFIG=/home/arch/.local/share/aurorae/themes/Win11OS-dark/Win11OS-darkrc if [ \"$SCALE\" -eq 1 ]; then kwriteconfig5 --file /home/arch/.config/kdeglobals --group KScreen --key ScaleFactor 1.5 kwriteconfig5 --file /home/arch/.config/kcmfonts --group General --key forceFontDPI 144 cp \"$THEME_CONFIG-150\" \"$THEME_CONFIG\" echo \"one monitor connected, scaling to 150%\" elif [ \"$SCALE\" -eq 2 ]; then kwriteconfig5 --file /home/arch/.config/kdeglobals --group KScreen --key ScaleFactor 1 kwriteconfig5 --file /home/arch/.config/kcmfonts --group General --key forceFontDPI 96 cp \"$THEME_CONFIG-100\" \"$THEME_CONFIG\" echo \"two monitors connected, scaling to 100%\" fi sleep 1 # loginctl terminate-session $XDG_SESSION_ID # qdbus org.kde.KWin /Session org.kde.KWin.Session.quit qdbus org.kde.ksmserver /KSMServer logout 0 0 0 运行这个脚本，就能做到自动化设置了 KDE窗口超大外边距 参考reddit和github issue,这其实是主题在字体高DPI时的一个bug，解决办法就是修改主题的配置文件，我使用的win11 dark主题，配置文件在~/.local/share/aurorae/themes/Win11OS-dark/Win11OS-darkrc，修改 text PaddingTop=32 PaddingBottom=76 PaddingRight=47 PaddingLeft=47 这四个值，就能控制窗口的外边距 这个问题，最麻烦的就是，它并没有提供GUI的修改方式，只能通过配置文件来修改，所以定位问题相当麻烦 此外在150%缩放比例下修改主题配置后，切换到100%缩放比例下，发现窗口边距直接挤压到窗口内部了，非常难看。。。。 解决办法就是，分别在150%缩放比例和100%缩放比例下修改主题配置，然后在脚本中根据缩放比例来选择不同的配置文件，这样就能解决这个问题了 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:0:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#最终成果"},{"categories":null,"content":" 总结不得不说linux桌面真是够折腾的，也许搞了半天，只不过是实现一个windows早就有的功能。linux桌面真不适合个人用户使用。不过，linux是自由的，windows是商业的，专有的，这注定了大部分人会选择windows，而linux因为市场小，发展更慢，桌面体验肯定是不及windows的（如果商业软件体验都不如自由软件，那么商业软件怎么存活？）。虽然折腾桌面很麻烦，但确实方便了不少。使用linux是自由的，桌面哪里看不顺眼都能改，甚至还能换桌面环境和窗口管理器，还能自由选择X11和wayland，而用windows只能微软喂什么就吃什么。小小的自由的代价，还是能接受的 ","date":"2023-07-21","objectID":"/posts/kde-setting-cli/:0:0","series":null,"tags":["Linux","Linux Desktop"],"title":"KDE折腾之自动化设置","uri":"/posts/kde-setting-cli/#总结"},{"categories":null,"content":"箭头函数和普通函数中的this js const obj = { name: \"Alice\", ptr:this, sayName: function () { console.log(this) }, sayNameArrow: () =\u003e { console.log(this) } }; const sayName = obj.sayName; const sayNameArrow = obj.sayNameArrow; obj.sayName(); sayName(); obj.sayNameArrow(); sayNameArrow(); 输出为 text {name: 'Alice', ptr: Window, sayName: ƒ, sayNameArrow: ƒ} demo1.js:5 Window {window: Window, self: Window, document: document, name: '', location: Location, …} demo1.js:8 Window {window: Window, self: Window, document: document, name: '', location: Location, …} demo1.js:8 Window {window: Window, self: Window, document: document, name: '', location: Location, …} 可见： 普通函数的this指向调用它的对象，如果在obj上调用它，既obj.sayName()，那么this就指向obj，如何在全局作用域调用它，既sayName()，那么this就指向全局对象window 箭头函数不提供this，它的this是捕获外部的this，在此处就相当于是捕获了obj.ptr，而obj内的this指向的是obj所在的作用域，也就是全局作用域，所以obj.sayNameArrow()和sayNameArrow()的this都指向全局对象window 如果尝试打印obj.ptr，会发现它在浏览器中就是window，也就是全局对象 ","date":"2023-07-16","objectID":"/posts/this-in-js/:0:0","series":null,"tags":["JS"],"title":"JS中的this","uri":"/posts/this-in-js/#"},{"categories":null,"content":"C++11后引入了右值引用等特性，用来支持移动语义和完美转发，在了解右值引用前，需要了解一些前置的概念 左值(lvalue) 左值字面意义是在等号左边的值，左值是寻址的，具名的，有标识符的 有一个特点是，所有声明的变量都是左值 右值(rvalue) 右值字面意义是在等号右边的值，右值不可寻址，不具名 具体而言： 一个整数字面量是右值，因为它不对应一个内存存储位置，在汇编中，它存在于指令中的立即数字段 一个临时对象是右值，临时对象是为了写连续的表达式而被编译器支持的，当有例如func(obj())时，首先建立一个obj对象，这个对象没有名字，它实际上有一个对于的内存存储位置，但在这行代码执行完后就会被销毁，所以它叫做临时对象 cpp对临时对象有一个限制，因为临时对象是马上就会被销毁的，所以对临时对象的修会被抛弃 fn(int a) 可以用fn(a)和fn(1)调用，但是会造成复制 fn(int \u0026a)不可以用fn(1)调用，因为cpp认为int\u0026是允许修改的，而如果修改一个字面量，因为找不到它的内存存储位置，所以无法修改 fn(const int\u0026 a)可以用fn(1)调用，因为fn通过const关键字保证自己不会修改临时对象，所以允许传入字面量 ","date":"2023-05-29","objectID":"/posts/rvalue-reference/:0:0","series":null,"tags":["C/C++"],"title":"右值引用","uri":"/posts/rvalue-reference/#"},{"categories":null,"content":" 左值引用左值常常被称为是变量的别名，为什么呢？ 根据左值的概念，可以确定 cpp int a = 1; int\u0026 b = a; b = 2; std::cout \u003c\u003c a \u003c\u003c std::endl; a = 3; std::cout \u003c\u003c b \u003c\u003c std::endl; 从抽象的角度来看，a，b具有响应式的关系，修改一个，另一个也会改变 但实际上，a，b是对同一个地址的引用，换句话来说，a，b ‘underlying’ 的对象只有一个，这里的对象并不是面向对象的对象 反汇编的结果也能证实这一观点 text int a = 5; 1170: c7 45 e4 05 00 00 00 movl $0x5,-0x1c(%rbp) int \u0026b = a; 1177: 48 8d 45 e4 lea -0x1c(%rbp),%rax 117b: 48 89 45 e8 mov %rax,-0x18(%rbp) 可见，b其实跟*(\u0026a)是同义的，而我们知道，*和\u0026效果刚好是相反的，也就说，b和a是同一个东西，这代表”b是a的别名“，也可以得出\u0026b和\u0026a是同一个东西，这代表”b和a ‘underlying’的对象是同一个“ 当左值引用作为函数参数传递时，在汇编层面上，实际上传递的是地址 左值引用的初衷也是简化指针的使用，左值引用具有指针的优点：能在函数内修改外部的值，又规避了指针的缺点：错误的指针运算会导致野指针，也可以认为它是受约束的指针 ","date":"2023-05-29","objectID":"/posts/rvalue-reference/:0:0","series":null,"tags":["C/C++"],"title":"右值引用","uri":"/posts/rvalue-reference/#左值引用"},{"categories":null,"content":" 右值引用当自己动手实现一个栈类时，会遇到这个问题 cpp Object obj; vector.push(obj); 当push的定义为push(Obeject obj)时，会造成复制行为 当push的定义为push(Object\u0026 obj)时，虽然可以避免复制，但是又会产生一个新的问题 cpp void function(Vector\u0026 vector){ Object obj; vector.push(obj); return； } 这时，由于obj对象是分配在栈上的，当函数退出时，栈帧被清空，obj对象也就不存在了，然而vector还保留着对obj对象的引用 这种情况其实经常发生，它表现了资源移动时的矛盾：又要避免复制，又要避免引用的对象提前销毁 一个简单的方法是使用new，在堆上构造obj，这样obj的生命期就足够长，能够避免obj提前被销毁 然而new后还需要delete，而new和delete不在同一个上下文中，非常容易忘记delete 这时我们就会想，有没有一个方法能够适当延长obj对象的生命期，又能让他自动销毁呢？ 答案就是右值引用了，push定义为push(Object\u0026\u0026 obj)时，编译器会延长obj对象的生命期，在这个例子中，会采用返回值优化（Return Value Optimization, RVO）或命名的返回值优化（Named Return Value Optimization, NRVO），通过把obj这个对象构造在调用者的栈上，避免退出函数时obj对象被销毁，从而延长了obj对象的生命期 下面这个例子进一步说明了右值引用延长了临时对象的生命期 cpp #include \u003ciostream\u003e class Object { public: Object() { std::cout \u003c\u003c \"Object constructed\" \u003c\u003c std::endl; } ~Object() { std::cout \u003c\u003c \"Object destroyed\" \u003c\u003c std::endl; } }; void processObject(Object\u0026\u0026 obj) { std::cout \u003c\u003c \"Processing object\" \u003c\u003c std::endl; // 对临时对象进行处理，这里只是简单地输出信息} int main() { Object\u0026\u0026 ref = Object(); // 将临时对象绑定到右值引用 std::cout \u003c\u003c \"Before function call\" \u003c\u003c std::endl; processObject(std::move(ref)); // 通过右值引用传递临时对象 std::cout \u003c\u003c \"After function call\" \u003c\u003c std::endl; return 0; } 编译后输出为 text Object constructed Before function call Processing object After function call Object destroyed 右值引用会延长临时对象的生命期直到右值引用绑定的对象的生命期结束 回到之前的例子，如果一个函数又要接收左值作为参数，又要接受右值作为参数，可以用fn(int\u0026\u0026 a)，同时能够在函数里修改a，但是对a作出的修改最终都会被抛弃 为什么对a作出的修改都会被抛弃呢？ 因为右值是不具名的，即使它被改变了，也没有任何方法能够访问到它 cpp #include \u003ciostream\u003e using namespace std; void fn(int \u0026\u0026 a){ while(a\u003e0){ cout \u003c\u003c a \u003c\u003c endl; a--; } } int main(){ fn(5); return 0; } 输出为 text 5 4 3 2 1 这个例子可能非常反直觉，当执行a--时，肯定有一个内存存储位置被赋值了，但是这个位置在哪里？ 反汇编后结果如下 text int main(){ ... fn(5); 11c4: c7 45 f4 05 00 00 00 movl $0x5,-0xc(%rbp) 11cb: 48 8d 45 f4 lea -0xc(%rbp),%rax 11cf: 48 89 c7 mov %rax,%rdi 11d2: e8 82 ff ff ff call 1159 \u003c_Z2fnOi\u003e 编译器居然为我们分配了一个变量！ 汇编代码等效为 cpp int x = 5; fn(x); 如果把fn修改为void fn(int a)，相应的反汇编结果为 text fn(5); 118e: bf 05 00 00 00 mov $0x5,%edi 1193: e8 b1 ff ff ff call 1149 \u003c_Z2fni\u003e ","date":"2023-05-29","objectID":"/posts/rvalue-reference/:0:0","series":null,"tags":["C/C++"],"title":"右值引用","uri":"/posts/rvalue-reference/#右值引用"},{"categories":null,"content":" MATLAB数值求解微分方程所谓数值求解，也就是无法获得解的方程，只能获得y(x)函数在x取值范围内的近似值 所有MATALB的DOE solver都可以解决形如$\\frac{\\mathrm{d}y}{\\mathrm{d}t}=f(t,y)$的微分方程，所以很多时候需要把待求解微分方程化成这种形式，这种形式有几种特点 导数在等号左边 只有两个变量 导数只有一阶 不过实际上，一些不满足这种形式的微分方程也可化成这种形式 ","date":"2023-05-26","objectID":"/posts/matlab-calculus/:1:0","series":null,"tags":["科学计算"],"title":"MATLAB微积分","uri":"/posts/matlab-calculus/#matlab数值求解微分方程"},{"categories":null,"content":" 一阶微分方程数值求解$$ y^{’} = \\frac{x\\sin x}{\\cos y} $$ 这个微分方程形式非常好，可以直接拿来求解 使用ode45函数，x的取值范围为$[0,1]$，$y(0)=0$,取初值为0 先定义微分函数 matlab function ydot = fn(x, y) ydot = x * sin(x) / cos(y); end 然后使用ode45求解 matlab [x, y] = ode45(@fn, [0,1], 0); x向量的每一列都对应y向量的每一列 然后用这个微分方程的解析解与数值解做比较 matlab [x, y] = ode45(@fn, [0,1], 0); subplot(1,2,1); plot(x, y); x = 0:0.01:1; y = asin(sin(x)-x.*cos(x)); subplot(1,2,2) plot(x, y); function ydot = fn(x, y) ydot = x * sin(x) / cos(y); end 结果如下 ","date":"2023-05-26","objectID":"/posts/matlab-calculus/:1:1","series":null,"tags":["科学计算"],"title":"MATLAB微积分","uri":"/posts/matlab-calculus/#一阶微分方程数值求解"},{"categories":null,"content":"ranger是linux的一个终端文件管理器 ，它的feature有 vi按键绑定 与shell环境完美结合，可以使用各种shell工具 在tty上也能工作 像vim一样的可扩展性 本文是为了帮助我记忆一些ranger常用的功能而写的 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#"},{"categories":null,"content":" 文件树中导航h,j,k,l同vi按键绑定 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#文件树中导航"},{"categories":null,"content":" 删除dD 删除 dT 移动到回收站 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#删除"},{"categories":null,"content":" 重命名a或A重命名，自动移动光标到扩展名前，默认行为是不修改扩展名 cw也可以重命名，这个按键在vim中代表改变单词（change word）,与a的区别是，a修改文件名是在原文件名的基础上修改的，而cw要输入完整的文件名 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#重命名"},{"categories":null,"content":" 历史导航一般的文件管理器往往有一个左右的箭头，代表回到之前的目录/回到之前离开的目录，或者更简单点，类似于浏览器的历史导航功能 H或L在历史中导航，同vi按键绑定 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#历史导航"},{"categories":null,"content":" 复制y，按键绑定同vi，表示yank 复制，接下一个按键才能表示一个具体操作 yy 复制文件，如同vim的yy表示复制一行 yn 复制文件名，即yank name y. 复制不带扩展名的文件名，即 yank name before . yp 复制文件路径 即yank path 另外， dd代表剪贴，也有复制的功能 与其他文件管理器不同的是，ranger维护一个复制缓冲区，当已经复制一些文件后，可以向复制缓冲区中添加或删除文件 ya 向缓冲区中添加文件 yr 将文件从缓冲区中删除 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#复制"},{"categories":null,"content":" 粘贴pp 粘贴一个已经复制的文件到当前目录，同vim按键绑定 po 粘贴并覆盖，即paste and overwrite 当出现重名文件时，会自动修改文件名 使用shell复制时，往往会遇到这种情况：复制大文件时，会阻塞终端，花费时间很长，而且没有进度条 而ranger可以在后台复制大文件，不阻塞当前操作，并且会在底栏显示任务进度 可以输入w查看ranger在后台进行的任务 pP和pO对应pp和po，但是会在后台完成 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#粘贴"},{"categories":null,"content":" 多tab众所周知有一个操作系统的默认文件管理系统在过去一直没有tab栏的功能，跨目录复制文件时，常常需要打开两个窗口 alt+$i 表示打开第$i个tab，$i可以是数字1-9，还有两个特殊的按键 alt+l 表示移动到上一个tab 即 left tab alt+r 表示移动到下一个tab 即 right tab ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#多tab"},{"categories":null,"content":" 查看文件元数据一般的文件管理器常常有查看文件创建日期，大小的功能，但是往往还有所不足，例如 目录的大小往往不显示（需要花费时间统计） 文件的权限，所有者往往隐藏在属性一栏里 文件的种类往往要通过扩展名判断 ranger作为一个神级文件管理器，这些功能自然都是有的 对于文件，会在文件名的右侧显示出大小，对于文件，默认显示4K（因为linux的目录是一个抽象的文件，它占用一个block，一个block大小是4K，用来存储目录的元数据） 可以用du命令统计文件大小，等效于执行du --max-depth=1，也可以用dU，会将du的输出按照大小排序 ranger的底栏会显示当前文件的权限（rwx），所有者/组，大小，上次的修改日期，当前目录的所有文件大小总和，当前文件所在的磁盘的剩余空间，当前屏幕占所有内容的进度（类似于vim显示光标在文本中的百分比位置） 类似于shell，文件会被高亮显示，可以根据颜色快速区分目录，图片，压缩包，适配，可执行，软链接等等 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#查看文件元数据"},{"categories":null,"content":" 快速导航一般的文件管理器往往在左侧有一些常用的位置，可以快速到达，ranger也可以快速到达一些常用的位置 g即go，可以用来快速到达一个位置 gh 即go home 相当于执行cd ~，这应该是linux用户最常用的功能 gp 即go /tmp，快速到达/tmp目录 gi 相当于执行 fm.cd('/run/media/' + os.getenv('USER'))，这个目录是用来mount用户的外接存储设备的，U盘，机械硬盘都会被mount到这里 gg和 G 类似与vim的按键绑定，快速到达当前目录的开头和结尾 还有g/,ge,go等等，但是使用次数比较少，没有必要记忆 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#快速导航"},{"categories":null,"content":" 打开shell在图形化的文件管理器中寻找文件时，往往需要打开shell输入命令，一般的文件管理器都有打开shell的功能，例如Windows的Explore可以Shift+右键可以在右键菜单中看到Open in Terminal，而KDE的dolphin甚至可以在下方打开一个pannel，随时使用shell 要快速执行一个shell命令，可以输入!或s在底栏输入shell命令，但是这种方式不会返回任何输出（实际上，当退出ranger后就能看到之前shell命令的输出） 为了获得输出，可以输入S，会打开一个shell，要退出这个shell只需要像一般的终端一样输入exit或按下Ctrl+D，会返回到ranger ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#打开shell"},{"categories":null,"content":" 打开文件很多文件管理器都有一个功能，就是打开文件，比如在Windows上双击一个扩展名为txt的文件，就会用记事本打开它，但是一般的文件管理器提供的这种功能往往有所不足，比如 文件无法预览 文件类型未知 要用其他方式打开文件，往往需要打开一个二级菜单 而ranger利用linux的生态巧妙地解决了这三个问题 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#打开文件"},{"categories":null,"content":" 文件预览预览就是在不打开文件的情况下（不使用默认软件打开它）快速查看文件内容 在windows上实现文件预览，可以打开Explore的预览功能，但是这种功能实际使用中比较鸡肋，因为它只能预览极少类型的文件（例如txt），而且还会占用窗口很大的空间 实际上，日常使用中遇到的文件类型是非常复杂的，比如说纯文本的文件 txt 各种语言的源文件，例如c,cpp,h,py,java,js,html,css,cs… 数据交换文件，例如json, xml, scv… 配置文件,例如conf, ini, cfg, yaml… 日志文件，例如log,out等 没有扩展名的纯文本 各种各样编码方式的纯文本 可见纯文本文件的类型就有非常多种，而不同纯文本文件的用途不同，期望的显示方式也不同，比如说 大部分文件都只需要开头十几行，不需要读取完整的文件造成过多的磁盘访问浪费性能 各种语言的源文件、配置文件、数据交换文件最好能有语法高亮，并使用等宽字体显示 日志文件，最好高亮显示Warning等信息 即使没有扩展名，也最好能够识别出它是纯文本并预览 另外，还有很多各种各样的文件类型需要使用不同的预览方式，例如 office的doc/docx, ppt/pptx, xls/xlsx文件快速预览 图片jpg, png, svg等等的预览 html，md文件的预览 最特殊的，二进制文件，类型非常多，常见的有 各种平台上的可执行 各种平台上的动态库，静态库 数据文件（数据格式有约定） 压缩文件，存档文件 … 可见种类实在是太多了，很多文件管理器往往只能做到预览一部分的文件 ranger通过简单的配置就能做到识别文件并预览大部分的文件，可以通过修改%rangerdir/data/scope.sh来启用纯文本文件以外的预览（预览二进制） scope.sh会自动寻找已经安装的其他软件并使用它，比如说 file 用于检测文件类型 chardet 一个python的模块，用于检测文件编码方式 python-bidi 用于显示从右到左书写的文字，例如阿拉伯语 img2txt 用于显示图片的ASCII字符画 w3mimgdisplay / ueberzug / mpv / iTerm2 / kitty / Terminology等等，用于图片预览 convert 是imagemagick工具的一部分，用来自动旋转图片并预览svg图片 ffmpegthumbnailer 用于显示视频的封面（缩略图） highlight / bat / pygmentize 用于代码的语法高亮 atoll / bsdtar / unrar / unzip / zipinfo / sed / tar / 7z 用来预览存档和压缩文件 lynx / w3m / elinks 用来预览html文件（渲染html） pdftotext / mutool预览pdf的文本，pdftoppm把pdf转成图片预览 djvutxt 预览文本类型的DjVu文件, ddjvu把DjVu文件转成图片预览 calibre / epub-thumbnailer 预览epub文件（电子书文件格式）的图片 transmission-show 预览BitTorrent文件（种子文件）的信息 mediainfo / exiftool 预览媒体文件 odt2txt 预览Open Document（开放文档格式，是文档格式的标准，office的word, ppt, excel也支持这些格式所以能预览） python / jq 预览json文件 fontimage 预览字体文件 这种机制的优点就是，只要有可以用的工具，ranger就会使用它来预览，而不需要任何额外配置，如果没有，ranger也能正常工作，只是少一个功能 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:1:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#文件预览"},{"categories":null,"content":" 打开文件当光标在一个文件时，可以输入l使用默认的方式打开一个文件，这个操作很符合vim的操作的直觉 也可以输入r，它会弹出一个打开方式的列表，可以输入数字选择打开的方式，也可以直接回车代表默认方式 此外，当光标处于目录时，输入l会进入这个目录，而输入r可以选择一个方式打开这个目录此时可以选择用dolphin打开这个目录 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:2:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#打开文件-1"},{"categories":null,"content":" 高级功能","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#高级功能"},{"categories":null,"content":" 过滤linux的shell在文件系统中导航时，使用tab进行补全是很方便的，比如说一个文件特别长，我不想完整输入，只需要输入前面几个字符，再按tab，就能自动补全了，这也是shell好用的一个重要原因 类似地，ranger也有根据文件名的前几个字符快速确定文件的功能 输入f，开始查找文件，只需要输入文件的一部分字符，ranger会自动把光标移动到搜索到的文件上，如果能够唯一确定文件，ranger会直接打开它（打开文件或目录），熟练使用这个功能，可以快速在文件树中导航！ 如果f查找的结果不唯一，可以用n到达下一个搜索结果，用N到达上一个搜索结果 如果f搜索的结果有很多，跳转起来也是相当麻烦的，而且有些情况下，需要查看一类文件，例如 找到同一扩展名的文件 找到命名具有同一规律的文件 这种时候可以输入zz，开启模糊查找模式，它跟f的区别就是，会过滤掉不匹配的结果，而且不会自动进入目录 有了zz和f这两个命令，就能快速在一个十分复杂的文件系统中导航 此外，shell还可以在任何一个地方使用cd命令快速到达另一个地方，而不管这两个地方相隔多远，ranger也可以直接输入cd，然后输入路径，就能到达指定的路径，这个功能就像g这个按键一样，可以迅速离开当前位置而不经过它的上级目录 ","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:1:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#过滤"},{"categories":null,"content":" 占坑","date":"2023-04-13","objectID":"/posts/file-manager-ranger/:2:0","series":null,"tags":["Linux","Shell"],"title":"Linux 神级文件管理器ranger","uri":"/posts/file-manager-ranger/#占坑"},{"categories":null,"content":"最近遇到了一个函数传参造成的问题，于是来稍微研究一下这个东西 什么是函数传参顺序？ 一个简单例子 c bar(foo(1), foo(2)); 为了准备bar函数需要的参数，需要先执行foo函数，但是有两个foo函数，应该先执行哪个？ 在一般情况下，先执行哪一个并没有什么影响，然而在一些特殊情况下，我们可能非常在意foo函数执行的顺序 比如说 foo函数内部做出了访问文件系统，发起网络请求等对外界造成影响的操作 foo函数内部有状态变量（类似状态机），每次执行foo函数时，会改变内部状态，foo函数的输出也取决于内部状态 ，一个最简单的例子就是foo函数表示弹栈操作 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:0:0","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#"},{"categories":null,"content":" 为了研究函数传参的顺序到底是从左到右还是从右到左，我做了以下实验首先考虑到函数传参的顺序实际上是调用者与被调用者约定的一种数据交换格式，函数的参数可以借由寄存器传递， 也可以把参数埋在调用者的栈内，也可以复制到被调用者的栈内，所以不必分析哪一个foo函数先执行，只需要 分析机器指令准备参数的顺序 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:1:0","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#为了研究函数传参的顺序到底是从左到右还是从右到左我做了以下实验"},{"categories":null,"content":" C首先新建文件test.c，内容如下 c #include \u003cstdio.h\u003e void fn(int x, int y) { printf(\"%d %d\", x, y); } int main() { fn(1, 2); return 0; } 用gcc编译，然后查看反汇编代码 shell gcc -g ./test.c objdump -S ./a.out main函数的反汇编代码如下 text 0000000000001166 \u003cmain\u003e: 1166: 55 push %rbp 1167: 48 89 e5 mov %rsp,%rbp 116a: be 02 00 00 00 mov $0x2,%esi 116f: bf 01 00 00 00 mov $0x1,%edi 1174: e8 c0 ff ff ff call 1139 \u003cfn\u003e 1179: b8 00 00 00 00 mov $0x0,%eax 117e: 5d pop %rbp 117f: c3 ret 可见自定义的fn函数的传参顺序是从右到左 还可以看出，2被放入了esi，1被放入了edi fn函数的反汇编代码如下 text 0000000000001139 \u003cfn\u003e: 1139: 55 push %rbp 113a: 48 89 e5 mov %rsp,%rbp 113d: 48 83 ec 10 sub $0x10,%rsp 1141: 89 7d fc mov %edi,-0x4(%rbp) 1144: 89 75 f8 mov %esi,-0x8(%rbp) 1147: 8b 55 f8 mov -0x8(%rbp),%edx 114a: 8b 45 fc mov -0x4(%rbp),%eax 114d: 89 c6 mov %eax,%esi 114f: 48 8d 05 ae 0e 00 00 lea 0xeae(%rip),%rax # 2004 \u003c_IO_stdin_used+0x4\u003e 1156: 48 89 c7 mov %rax,%rdi 1159: b8 00 00 00 00 mov $0x0,%eax 115e: e8 cd fe ff ff call 1030 \u003cprintf@plt\u003e 1163: 90 nop 1164: c9 leave 1165: c3 ret fn函数把edi和esi的值复制到栈帧中，然后再复制到寄存器中，可以确定先准备了2，再准备了1 猜测0xeae(%rip)存放着字符串\"%d %d\"的值，进入gdb查看这个地址的值 text (gdb) si 0x0000555555555156 3 void fn(int x, int y) { printf(\"%d %d\", x, y); } (gdb) p (char*)($rip+0xeae) $22 = 0x555555556004 \"%d %d\" 所以可以确定，printf函数的字符串是最后一个被传入的，所以这个printf函数也是从右到左 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:1:1","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#c"},{"categories":null,"content":" Python新建一个test.py，内容如下 python import dis def fn(x, y): print(x, y) def main(): fn(1, \"2\") dis.dis(main) 在终端执行脚本 shell python ./test.py 结果如下 text 9 0 LOAD_GLOBAL 0 (fn) 2 LOAD_CONST 1 (1) 4 LOAD_CONST 2 ('2') 6 CALL_FUNCTION 2 8 POP_TOP 10 LOAD_CONST 0 (None) 12 RETURN_VALUE 可以看出自定义的fn函数是从左到右传参的 但是，python的函数传参实际上相当复杂，涉及到位置参数，默认参数，可变参数，关键字参数等等，具体传参顺序 还得看python解释器的实现 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:1:2","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#python"},{"categories":null,"content":" 占坑","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:1:3","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#占坑"},{"categories":null,"content":" 总结汇编的函数调用约定，占坑 ","date":"2023-04-06","objectID":"/posts/function-parameters-push-stack-order/:2:0","series":null,"tags":["Coding","assemble"],"title":"函数传参的入栈顺序造成的一些细微影响","uri":"/posts/function-parameters-push-stack-order/#总结"},{"categories":null,"content":"在linux使用shell时常常会遇到一些使用场景需要大量重复敲击按键，带来了一些麻烦，所以学会一些快捷键是 必备的，但是有些快捷键几乎没用，也没用记忆的必要 首先声明一点，重点是记住快捷键的功能，而不是快捷键的按键绑定，因为对于不同的终端模拟程序，这些功能基本都是 提供的，但是按键绑定可能有所不同(说的就是PowerShell)，另外有些终端是支持修改按键绑定的 以下的快捷键按键绑定都是标准的linux shell按键绑定，在Konsole上测试通过 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#实用的快捷键"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#快速跳转到命令的开头"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#发送eof"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#打断前台程序"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#暂停前台程序"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#控制屏幕输出"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#历史回溯"},{"categories":null,"content":" 实用的快捷键 快速跳转到命令的开头Ctrl+A，这个命令会将光标移动到命令的开头，在执行某些命令发现权限不够时，可以用这个命令快速跳转到开头 然后添加sudo 发送EOFCtrl+D即发送EOF EOF是End Of File，它表示文件的结束，当一个程序读取标准输入时，它相当于是在读取一个 叫做标准输入的文件， EOF告诉程序，文件已经读取完了，在任何读取输入的程序中发送EOF都能直接退出，例如python的终端交互式界面， ssh远程登录的环境，甚至可以用这个关闭终端模拟器 实际上Ctrl+D这个功能准确来说应该不是快捷键，因为几乎没有其他操作能完成一样的功能 （补上一点，有些IDE在debug时可能会屏蔽掉一些按键绑定，可以尝试Ctrl+Shift+D) 打断前台程序Ctrl+C，基本是每一个初学者第一个学会的快捷键 暂停前台程序如果执行一个命令发现要花非常多的时间，想暂停先去干别的事情，直接Ctrl+C会直接发送SIGKILL信号，强制 进程结束，还有一种做法是暂停前台程序，按下Ctrl+Z即可，进程的各种资源都会被保留，但是不会分到时间片， 也就是不会被执行，可以通过fg或bg命令重新运行，fg即foreground，让暂停的后台进程在前台执行 bg即background，让暂停的后台进程在后台运行，还可以通过jobs -l寻找被暂停的进程，如果不需要这个 进程了，可以用kill \u003c进程号\u003e杀死进程 控制屏幕输出如果屏幕输出太多，可以用Ctrl+S阻止屏幕输出，要恢复屏幕输出用Ctrl+Q 历史回溯按下Ctrl+R后会进入一个历史命令回溯的程序，可以用这个功能快速搜索已经输入过的命令 按上下箭头也可以逐条回溯历史命令 清空屏幕Ctrl+L可以清空屏幕上的输出，这个快捷键功能同clear命令 然而clear命令实际上是一个可执行，所以它清空输出的功能是如何实现的，现在成了未知 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#清空屏幕"},{"categories":null,"content":" 用处不大的快捷键 快速删除当输入一个很长的命令，突然发现需要先执行另外一个命令，这时有两个做法 Ctrl+C打断 Ctrl+U删除光标左边的全部字符串 Ctrl+U虽然可以根据光标删除，但是实际使用场景常常可以被Ctrl+C替代 移动光标的高级方式除了Ctrl+A，这些移动光标的方式基本都不常用 Ctrl+A 移动到命令行首 Ctrl+E 移动到命令行尾（end） Ctrl+F 前移一个字符（forward） Ctrl+B 后移一个字符（backward） … 还有很多这种命令，就不一一列举了 实际上Ctrl+左右箭头就能实现在词间移动，而且更加直观 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:2","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#用处不大的快捷键"},{"categories":null,"content":" 用处不大的快捷键 快速删除当输入一个很长的命令，突然发现需要先执行另外一个命令，这时有两个做法 Ctrl+C打断 Ctrl+U删除光标左边的全部字符串 Ctrl+U虽然可以根据光标删除，但是实际使用场景常常可以被Ctrl+C替代 移动光标的高级方式除了Ctrl+A，这些移动光标的方式基本都不常用 Ctrl+A 移动到命令行首 Ctrl+E 移动到命令行尾（end） Ctrl+F 前移一个字符（forward） Ctrl+B 后移一个字符（backward） … 还有很多这种命令，就不一一列举了 实际上Ctrl+左右箭头就能实现在词间移动，而且更加直观 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:2","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#快速删除"},{"categories":null,"content":" 用处不大的快捷键 快速删除当输入一个很长的命令，突然发现需要先执行另外一个命令，这时有两个做法 Ctrl+C打断 Ctrl+U删除光标左边的全部字符串 Ctrl+U虽然可以根据光标删除，但是实际使用场景常常可以被Ctrl+C替代 移动光标的高级方式除了Ctrl+A，这些移动光标的方式基本都不常用 Ctrl+A 移动到命令行首 Ctrl+E 移动到命令行尾（end） Ctrl+F 前移一个字符（forward） Ctrl+B 后移一个字符（backward） … 还有很多这种命令，就不一一列举了 实际上Ctrl+左右箭头就能实现在词间移动，而且更加直观 ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:2","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#移动光标的高级方式"},{"categories":null,"content":" 关于复制因为Ctrl+C被拿去打断进程了，复制粘贴就变成了Ctrl+Shift+C和Ctrl+Shift+V，这确实带来了麻烦！ 但是考虑到这是linux的默认设置，如果修改了这个配置，在新机器上可能会不习惯，最终还是慢慢适应了 但是这个快捷键在跨应用复制的时候会带来不少困扰！（尤其是Ctrl+Shift+C在edge上也许表示复制元素，一旦按下 这个按键就会打开浏览器开发者工具） ","date":"2023-04-04","objectID":"/posts/linux-terminal-shortcut/:0:3","series":null,"tags":["Linux","Shell"],"title":"Linux shell常用快捷键","uri":"/posts/linux-terminal-shortcut/#关于复制"},{"categories":null,"content":"matplotlib 是python的可视化库，但是如果在matplotlib的图表中使用了中文， 会找不到中文字体而显示乱码，网上有很多教程解决这个问题，但是在我的linux上都不管用 经过不断尝试和google，终于找到了方法 可以随便选择能够选择中文的字体，但是要注意font family和字体名称的问题，以下以微软 雅黑为例 把msyh.ttc放到matplotlib的字体目录下 shell mv /path/to/msyh.ttc /path/to/matplotlib/mpl-data/fonts/ttf/ 其中第一个路径是微软雅黑字体文件的路径，对于linux来说，这个字体可以从网上下载 如果安装了这个字体可以在/usr/fonts下找到（用locate命令搜索, 见linux文件搜索神器 第二个路径是matplotlib安装的目录，可以执行以下代码找到这个目录 python import matplotlib print(matplotlib.matplotlib_fname()) 修改matplotlib配置文件 打开matplotlib的全局配置文件，会看到这段话 text ## This is a sample Matplotlib configuration file - you can find a copy ## of it on your system in site-packages/matplotlib/mpl-data/matplotlibrc ## (relative to your Python installation location). ## DO NOT EDIT IT! ## ## If you wish to change your default style, copy this file to one of the ## following locations: ## Unix/Linux: ## $HOME/.config/matplotlib/matplotlibrc OR ## $XDG_CONFIG_HOME/matplotlib/matplotlibrc (if $XDG_CONFIG_HOME is set) ## Other platforms: ## $HOME/.matplotlib/matplotlibrc ## and edit that copy. 这句话的意思就是，为了不污染全局配置，可以把这个配置文件复制到用户的配置目录下，单独为一个用户配置 shell cp /path/to/matplotlibrc ~/.config/matplotlib/matplotlibrc 然后用vim打开matplotlibrc，找到以下两行，取消注释改成这样 text font.family: Microsoft YaHei, sans-serif font.serif: Microsoft YaHei, DejaVu Serif # 此处把微软雅黑放到第一个位置 最关键的步骤，移除缓存 网上很多教程都有这一步：执行python代码 python from matplotlib.font_manager import _rebuild _rebuild() 但是我执行这个代码的时候出现了Import Error，也许是版本问题 为了强制重新生成字体缓存，可以删掉matplotlib的缓存 shell rm -rf ~/.cache/matplotlib rm -rf ~/.matplotlib/*.cache 搞定，至此可以放心的使用matplotlib了 ","date":"2023-04-02","objectID":"/posts/matplotlib-chinese-font/:0:0","series":null,"tags":["Linux","科学计算"],"title":"matplotlib在linux平台上显示中文的解决方案","uri":"/posts/matplotlib-chinese-font/#"},{"categories":null,"content":"使用Linux时，常常需要在文件系统中快速搜索到内容，比如说 在一个项目中需要快速找到一个文件的路径，需要按照文件名搜索出路径 想找某个文件，但是完全不知道它在哪里，需要全局搜索 在一个项目中想要搜索一个特定字符串的出现 ","date":"2023-04-01","objectID":"/posts/linux-file-search/:0:0","series":null,"tags":["Linux","Shell"],"title":"Linux搜索神器","uri":"/posts/linux-file-search/#"},{"categories":null,"content":" 需求1: 根据文件名搜索路径–find可以使用find命令，它是linux大多数发行版都自带的命令 shell find . -name \"filename\" 这个命令会在当前目录下递归搜索叫做filename的文件，但是这个文件名必须是完全匹配 如果只是知道文件名的大概，或者无法保证文件名完全一致，可以用正则匹配 shell find . -name \"filename.*\" 这个命令会搜索所有满足正则表达式filename.*的文件，但是注意，由于bash会将*解释为匹配的文件，必 须用双引号把括起来 至此这个命令足够日常使用了，但是有些情景就不好用了，例如完全不知道这个文件的路径，只知道它的名字，或许可 以这样 shell find / -name \"filename\" 这个命令会在根目录递归搜索所有文件，似乎能达到目的，但是它会去尝试读取一些系统文件和权限不足以访问的 文件 ，导致输出一大堆错误信息 ，为了避免错误输出淹没了查找结果的输出，可以给予高权限 shell sudo find / -name \"filename\" 但是这个命令其实相当危险！，作为超级用户，不应该给予它如此高的权限，这是没必要的，还可能有风险 而且由于linux实现的的文件系统是VFS(虚拟文件系统)，并不是所有文件的open和read操作都会在硬盘上生效， 比如说，访问/proc下的文件实际上是从内存中读取进程的相关信息，访问/dev下的文件实际上是尝试从 设备中读取数据，另外实际上你也会发现，即使给了最高的权限，还是有些文件无法被读取 很明显，我们想要搜索的文件常常都是用户文件，它的权限不高，所以没必要用这种方式，另外为了防止错误信息 淹没了查找结果，可以把错误信息丢掉 shell find / -name \"filename\" 2\u003e/dev/null 在shell中，2代表标准错误，同理0代表标准输入，1代表标准输出，\u003e代表重定向输出，/dev/null 是linux的空设备，它相当于一个无底洞，输出到/dev/null就相当于丢弃输出 虽然find命令很强大，但是如你所见，用它搜索文件有时候还是不好用 ","date":"2023-04-01","objectID":"/posts/linux-file-search/:0:1","series":null,"tags":["Linux","Shell"],"title":"Linux搜索神器","uri":"/posts/linux-file-search/#需求1-根据文件名搜索路径find"},{"categories":null,"content":" 需求2:全局搜索文件–locatelocate可能需要自己安装，如 archwiki所说，locate命令是在预先建立好的文件系统 索引数据库中搜索，这可以大大加快速度（当用find全局搜索或者在机械硬盘中搜索时往往能体会到find的速度） locate的工作原理有点类似于Windows平台的everything， 但实际上locate可能胜过everything 第一次使用locate命令前需要先建立索引(需要root权限) shell sudo updatedb 然后直接搜索 shell locate \"filename\" 可以在全局查找文件，另外locate会考虑权限控制，只会显示用户可访问的文件，就不会出现在/proc和/dev 下搜索的情况 这个命令用来全局模糊搜索非常好用，因为locate默认把参数解释为正则匹配的partten 在日常使用的过程中可能会出现这个问题，locate输出的结果太多了，例如 shell locate python | wc 411629 411761 48329698 如上，用wc统计出有411629行，也就是有411629个匹配结果！ 让我们来看看为什么会有这么多结果，首先可以发现，如果一个目录名包括了python字符串，那么这个目录下所有文件 都会命中正则匹配！例如/home/arch/.cache/JetBrains/CLion2022.3/python_stubs/-548636620/PySide6 另外有些目录下的匹配结果是不需要的，比如说我只想看看我的电脑上有多少个python解释器， 那么~/.cache很有可能就是不需要的,那么如何避免这些情况呢？ 更加准确的描述方式 如果我只想找到python解释器的位置，那么python-stub还有python-websockets就是不满足的，可以 扩展正则语法的否定预查更加精准的匹配，然而这个情景下，用准确的文件名匹配更好 shell locate \"*/python\" 这个命令的意思是*匹配前的路径，python匹配文件名，这样就能精准匹配到名为python的文件 过滤不需要的信息 执行过一遍locate后我已经知道某些路径下的搜索结果是不需要的，例如我想过滤~/.cache下的所有结果 shell locate \"python\" | grep -v \".cache\" 这里用到了grep的反向匹配过滤掉~/.cache下的所有匹配结果，但是这么过滤后可能还是太多了，需要 进一步过滤，例如想要过滤python-websockets下的所有结果，通过查看grep的手册发现并没有反向匹配两种pattern的方法，这里可以利用linux shell的 强大之处 shell locate \"python\" | grep -v \".cache\" | grep -v \"python-websockets\" 利用最简单的概念和最简单的操作就能组合出非常复杂的流程，这体现出linux设计的优点，也体现了 最小惊讶原理，说实话 我第一次看到这种用法只吃惊了1秒！ ","date":"2023-04-01","objectID":"/posts/linux-file-search/:0:2","series":null,"tags":["Linux","Shell"],"title":"Linux搜索神器","uri":"/posts/linux-file-search/#需求2全局搜索文件locate"},{"categories":null,"content":" 需求3:搜索文件内容–grep,ag,ack在VScode和jetbrain系IDE中都可以通过Ctrl+Sift+F在整个项目中搜索文件内容，linux的命令行也有对应的 工具grep和ag，但是grep的命令太长，所以这里暂时略过grep(因为我也不会) ag是The Silver Searcher的指代，tldr对ag的介绍是 {% blockquote %} Recursively search for PATTERN in PATH. Like grep or ack, but faster. {% endblockquote %} ag大多数发行版都没有自带，需要自己安装 shell sudo pacman -S the_silver_searcher 假设我想看一个python项目引入了哪些库，可以用ag搜索import语句 shell ag \"import\" ag默认使用正则表达式搜索，而且搜索速度非常快！ 搜索非常快的原因见github仓库 ","date":"2023-04-01","objectID":"/posts/linux-file-search/:0:3","series":null,"tags":["Linux","Shell"],"title":"Linux搜索神器","uri":"/posts/linux-file-search/#需求3搜索文件内容grepagack"}]